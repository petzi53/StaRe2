{
  "hash": "d29c66f079704cb17e90584fe3ae7a6a",
  "result": {
    "markdown": "# 3a: Sampling the Imaginary\n\n**Medical Test Scenario with Bayes theorem**\n\n1.  Suppose there is a blood test that correctly detects vampirism 95%\n    of the time.$Pr(positivetest|vampire) = 0.95$.\n2.  It's a very accurate test, nearly always catching real vampires. It\n    also make mistakes, though, in the form of false positives. One\n    percent of the time, it incorrectly diagnoses normal people as\n    vampires, $Pr(positive test result| mortal) = 0.01$.\n3.  The final bit of information we are told is that vampires are rather\n    rare, being only 0.1% of the population, implying\n    $Pr(vampire) = 0.001$.\n\nSuppose now that someone tests positive for vampirism. What's the\nprobability that he or she is a bloodsucking immortal?\n\n\n\n::: {.cell}\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: scenario-bayes-theorem-a\n## R code 3.1\n\nPr_Positive_Vampire_a <- 0.95\nPr_Positive_Mortal_a <- 0.01\nPr_Vampire_a <- 0.001\nPr_Positive_a <- Pr_Positive_Vampire_a * Pr_Vampire_a +\n  Pr_Positive_Mortal_a * (1 - Pr_Vampire_a)\n(Pr_Vampire_Positive_a <- Pr_Positive_Vampire_a * Pr_Vampire_a / Pr_Positive_a)\n```\n````\n\n```\n#> [1] 0.08683729\n```\n:::\n\n\n\n**Medical test scenario with natural frequencies**\n\n```         \n(1)  In a population of 100,000 people, 100 of them are vampires.\n(2)  Of the 100 who are vampires, 95 of them will test positive for vampirism.\n(3)  Of the 99,900 mortals, 999 of them will test positive for vampirism.\n```\n\nThere are 999 + 95 = 1094 people tested positive. But from these\npeople only 95 / (999 + 95) = 8.6837294 % vampires.\n\n## 3.1a Sampling from Grid\n\n::: callout-note\n## prob_data & prob_p\n\nI have `prob_data` and `prob_p` not changed to the `_a`-version because\nthese two variable names are not used in the `_b`-version. In the\n`_b`-version `prob_p` was named to `prior` and `prob_data` to\n`likelihood`.\n:::\n\n\n\n::: {.cell}\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: sampling-grid-a\n\n## R code 3.2\np_grid_a <- seq(from = 0, to = 1, length.out = 1000)\nprob_p <- rep(1, 1000) # = prior, assumed as uniform distribution\nprob_data <- dbinom(6, size = 9, prob = p_grid_a) # = likelihood\nposterior_a <- prob_data * prob_p\nposterior_a <- posterior_a / sum(posterior_a)\n\n## R code 3.3\nsamples_a <- sample(p_grid_a, prob = posterior_a, size = 1e4, replace = TRUE)\n\n# display start of results to compare with variant b\nhead(p_grid_a)\nhead(posterior_a)\nhead(samples_a)\n\n## R code 3.4\nplot(samples_a)\n\n## R code 3.5\nlibrary(rethinking)\n```\n````\n\n```\n#> Loading required package: rstan\n#> Loading required package: StanHeaders\n#> \n#> rstan version 2.26.22 (Stan version 2.26.1)\n#> For execution on a local, multicore CPU with excess RAM we recommend calling\n#> options(mc.cores = parallel::detectCores()).\n#> To avoid recompilation of unchanged Stan programs, we recommend calling\n#> rstan_options(auto_write = TRUE)\n#> For within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\n#> change `threads_per_chain` option:\n#> rstan_options(threads_per_chain = 1)\n#> Loading required package: cmdstanr\n#> This is cmdstanr version 0.5.3\n#> - CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n#> - CmdStan path: /Users/petzi/.cmdstan/cmdstan-2.32.2\n#> - CmdStan version: 2.32.2\n#> Loading required package: parallel\n#> rethinking (Version 2.31)\n#> \n#> Attaching package: 'rethinking'\n#> The following object is masked from 'package:rstan':\n#> \n#>     stan\n#> The following object is masked from 'package:stats':\n#> \n#>     rstudent\n```\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: sampling-grid-a\n\ndens(samples_a)\n```\n````\n\n```\n#> [1] 0.000000000 0.001001001 0.002002002 0.003003003 0.004004004 0.005005005\n#> [1] 0.000000e+00 8.433659e-19 5.381333e-17 6.111249e-16 3.423368e-15\n#> [6] 1.301978e-14\n#> [1] 0.5965966 0.6986987 0.4444444 0.6346346 0.8478478 0.5605606\n```\n\n::: {.cell-output-display}\n![](03a-sampling-the-imaginary_files/figure-pdf/sampling-grid-a-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](03a-sampling-the-imaginary_files/figure-pdf/sampling-grid-a-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n## 3.2a Sampling to Summarize\n\nAfter you have gotten the posterior distribution the model's work is\ndone. But now you have to interpret and summarize this posterior\ndistribution. There are three kind of questions you may ask:\n\n1.  Questions about intervals of defined boundaries.\n2.  Questions about intervals of defined probability mass.\n3.  Questions about point estimates.\n\n### 3.2.1a Intervals of Defined Boundaries\n\nFor instance: What is the probability that the proportion of water is\nless than 0.5?\n\n\n\n::: {.cell}\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: grid-boundaries-a\n## R code 3.6\n# add up posterior probability where p < 0.5\nsum(posterior_a[p_grid_a < 0.5])\n```\n````\n\n```\n#> [1] 0.1718746\n```\n:::\n\n\n\nThe posterior probability that the proportion of water\\< 0.5 (50%) is\nrelatively low, just about 17%. Remember: The true proportion is around\n0.7 or 70%.\n\nBut this easy calculation based on grid approximation is often not\npractical when there are more parameters. So let's try the sampling\napproach:\n\nTo use the samples from the posterior you have to add up all of the\nsamples below 0.5, but also divide the resulting count by the total\nnumber of samples. In other words, find the frequency of parameter\nvalues below 0.5:\n\n\n\n::: {.cell}\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: sample-boundaries-a\n## R code 3.7\n(p_a <- sum(samples_a < 0.5) / 1e4)\n```\n````\n\n```\n#> [1] 0.1749\n```\n:::\n\n\n\nUsing the same approach, you can ask how much posterior probability lies\nbetween 0.5 and 0.75:\n\n\n\n::: {.cell}\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: sample-boundaries2-a\n## R code 3.8\n(p_a2 <- sum(samples_a > 0.5 & samples_a < 0.75) / 1e4)\n```\n````\n\n```\n#> [1] 0.5993\n```\n:::\n\n\n\nIn contrast to the analytical grid calculation my values in the sampling\napproach 0.5993 are slightly different from the values of McElreath\n(0.6059). McElreath didn't use the `set.seed()` command so that I could\nnot produce the exactly same sample values.\n\n### 3.2.2a Intervals of Defined Probability Mass\n\nReporting an interval of defined mass is usually known as a **CONFIDENCE\nINTERVAL**. An interval of posterior probability, such as the ones we\nare working with, may instead be called a **CREDIBLE INTERVAL**.\n\nWe're going to call it a **COMPATIBILITY INTERVAL** instead, in order to\navoid the unwarranted implications of \"confidence\" and \"credibility.\"\nWhat the interval indicates is a range of parameter values compatible\nwith the model and data. The model and data themselves may not inspire\nconfidence, in which case the interval will not either.\n\nThe difference between intervals of defined boundaries and intervals of\ndefined probability mass is that in the first case we ask for a\n**probability of frequencies** whereas in the second case we calculate a\nspecified **amount of posterior probability**. As result from the first\nquestion we get the percentage of the probability whereas the result of\nthe second question is the probability value of the percentage of\nfrequencies looked for.\n\nFor this type of interval, it is easier to find the answer by using\nsamples from the posterior than by using a grid approximation. Suppose\nfor example you want to know the boundaries of the lower 80% posterior\nprobability. You know this interval starts at $p = 0$. To find out where\nit stops, think of the samples as data and ask where the 80th percentile\nlies:\n\n\n\n::: {.cell}\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: sample-quantile-a\n## R code 3.9\nquantile(samples_a, 0.8)\n```\n````\n\n```\n#>       80% \n#> 0.7617618\n```\n:::\n\n\n\nSimilarly, the middle 80% interval lies between the 10th percentile and\nthe 90th percentile. These boundaries are found using the same approach:\n\n\n\n::: {.cell}\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: sample-quantile2-a\n## R code 3.10\nquantile(samples_a, c(0.1, 0.9))\n```\n````\n\n```\n#>       10%       90% \n#> 0.4454454 0.8138138\n```\n:::\n\n\n\nIntervals of this sort, which assign equal probability mass to each\ntail, are very common in the scientific literature. We'll call them\n**PERCENTILE INTERVALS** (PI). These intervals do a good job of\ncommunicating the shape of a distribution, as long as the distribution\nisn't too asymmetrical. But in terms of describing the shape of the\nposterior distribution---which is really all these intervals are asked\nto do---the percentile interval can be misleading.\n\n\n\n::: {.cell}\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: pi-skewed-a\n\nlibrary(rethinking)\n\n## R code 3.11\np_grid_a <- seq(from = 0, to = 1, length.out = 1000)\nprior_a <- rep(1, 1000)\nlikelihood_a <- dbinom(3, size = 3, prob = p_grid_a)\nposterior_a <- likelihood_a * prior_a\nposterior_a <- posterior_a / sum(posterior_a)\nsamples_a <- sample(p_grid_a, size = 1e4, replace = TRUE, prob = posterior_a)\n\n## R code 3.12\nPI(samples_a, prob = 0.5)\n\n## R code 3.13\nHPDI(samples_a, prob = 0.5)\n```\n````\n\n```\n#>       25%       75% \n#> 0.7077077 0.9299299 \n#>      |0.5      0.5| \n#> 0.8408408 1.0000000\n```\n:::\n\n\n\n### 3.2.3a Point Estimates\n\n\n\n::: {.cell}\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: point-estimates-a\n\n## R code 3.14\np_grid_a[which.max(posterior_a)]\n\n## R code 3.15\nrethinking::chainmode(samples_a, adj = 0.01)\n\n## R code 3.16\nmean(samples_a)\nmedian(samples_a)\n\n```\n````\n\n```\n#> [1] 1\n#> [1] 0.9654239\n#> [1] 0.799886\n#> [1] 0.8408408\n```\n:::\n\n::: {.cell}\n\n````{.cell-code  code-line-numbers=\"false\"}\n```{{r}}\n#| label: loss-function-a\n\n## R code 3.17\nsum(posterior_a * abs(0.5 - p_grid_a))\n\n## R code 3.18\nloss <- sapply(p_grid_a, function(d) sum(posterior_a * abs(d - p_grid_a)))\n\n## R code 3.19\np_grid_a[which.min(loss)]\n\nmedian(samples_a)\n```\n````\n\n```\n#> [1] 0.3128752\n#> [1] 0.8408408\n#> [1] 0.8408408\n```\n:::\n",
    "supporting": [
      "03a-sampling-the-imaginary_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}