{
  "hash": "365a0d24e5f963872e4af6d2c2606599",
  "result": {
    "markdown": "# Geocentric Models\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: setup\n\nlibrary(tidyverse)\n```\n````\n\n```\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n\n## Why normal distributions are normal?\n\nWhy are there so many distribution approximately normal, resulting in a\nGaussian curve? Because there will be more combinations of outcomes that\nsum up to a \"central\" value, rather than to some extreme value.\n\n::: callout-tip\nAny process that adds together random values from the same distribution\nconverges to a normal.\n:::\n\n### Normal by addition\n\nWhatever the average value of the source distribution, each sample from\nit can be thought of as a fluctuation from that average value. When we\nbegin to add these fluctuations together, they also begin to cancel one\nanother out. A large positive fluctuation will cancel a large negative\none. The more terms in the sum, the more chances for each fluctuation to\nbe canceled by another, or by a series of smaller ones in the opposite\ndirection. So eventually the most likely sum, in the sense that there\nare the most ways to realize it, will be a sum in which every\nfluctuation is canceled by another, a sum of zero (relative to the\nmean).\n\nIt doesn't matter what shape the underlying distribution possesses. It\ncould be uniform, like in our example above, or it could be (nearly)\nanything else. Depending upon the underlying distribution, the\nconvergence might be slow, but it will be inevitable.\n\nSee the excellent article [Why is normal distribution so\nubiquitous?](https://ekamperi.github.io/mathematics/2021/01/29/why-is-normal-distribution-so-ubiquitous.html)\nwhich also explains the example of random walks from SR2. See also the\nscientific paper [Why are normal distribution\nnormal?](https://www.journals.uchicago.edu/doi/pdf/10.1093/bjps/axs046)\nof the The British Journal for the Philosophy of Science.\n\n### Normal by multiplication\n\nThis is not only valid for addition but also for multiplication of small\nvalues: Multiplying small numbers is approximately the same as addition.\n\n### Normal by log-multipliation\n\nBut even the multiplication of large values tend to produce Gaussian\ndistributions on the log scale.\n\n### Using Gaussian distribution\n\nThe justifications for using the Gaussian distribution fall into two\nbroad categories:\n\n1.  **Ontological justification**: The world is full of Gaussian\n    distributions, approximately. We're never going to experience a\n    perfect Gaussian distribution. But it is a widespread pattern,\n    appearing again and again at different scales and in different\n    domains. Measurement errors, variations in growth, and the\n    velocities of molecules all tend towards Gaussian distributions.\n\nThere are many other patterns in nature, so make no mistake in assuming\nthat the Gaussian pattern is universal. In later chapters, we'll see how\nother useful and common patterns, like the exponential and gamma and\nPoisson, also arise from natural processes. The Gaussian is a member of\na family of fundamental natural distributions known as the **Exponential\nfamily**. All of the members of this family are important for working\nscience, because they populate our world.\n\n2.  **Epistemological justification**: The Gaussian represents a\n    particular state of ignorance. When all we know or are willing to\n    say about a distribution of measures (measures are continuous values\n    on the real number line) is their mean and variance, then the\n    Gaussian distribution arises as the most consistent with our\n    assumptions. It is the least surprising and least informative\n    assumption to make. --- If you don't think the distribution should\n    be Gaussian, then that implies that you know something else that you\n    should tell your golem about, something that would improve\n    inference.\n\n::: callout-caution\nAlthough the Gaussian distribution is common in nature and has some nice\nproperties, there are some risks in using it as a default data model.\nThe Gaussian distribution has some very thin tails---there is very\nlittle probability in them. Instead most of the mass in the Gaussian\nlies within one standard deviation of the mean. Many natural (and\nunnatural) processes have much heavier tails.\n:::\n\nThe Gaussian is a continuous distribution, unlike the discrete\ndistributions of earlier chapters. Probability distributions with only\ndiscrete outcomes, like the binomial, are called *probability mass*\nfunctions and denoted `Pr`. Continuous ones like the Gaussian are called\n*probability density* functions, denoted with *`p`* or just plain old\n*`f`*, depending upon author and tradition. For mathematical reasons,\nprobability densities can be greater than 1. Try `dnorm(0,0,0.1)`\", for\nexample, which is the way to make R calculate *`p`*`(0|0, 0.1)`. The\nanswer, about 4, is no mistake. Probability *density* is the rate of\nchange in cumulative probability. So where cumulative probability is\nincreasing rapidly, density can easily exceed 1. But if we calculate the\narea under the density function, it will never exceed 1. Such areas are\nalso called *probability mass*.\n\n## A language describing models\n\n1.  First, we recognize a set of variables to work with. Some of these\n    variables are observable. We call these data. Others are\n    unobservable things like rates and averages. We call these\n    parameters.\n2.  We define each variable either in terms of the other variables or in\n    terms of a probability distribution.\n3.  The combination of variables and their probability distributions\n    defines a joint generative model that can be used both to simulate\n    hypothetical observations as well as analyze real ones.\n\nModels are mappings of one set of variables through a probability\ndistribution onto another set of variables. Fundamentally, these models\ndefine the ways values of some variables can arise, given values of\nother variables.\n\n### Re-describing the globe tossing model\n\nRecall the proportion of the water problem from previous chapters. The\nmodel in that case was always:\n\n------------------------------------------------------------------------\n\n::: {#def-glob-tossing-model}\nDescribe the globe tossing model from previous chapter\n\n$$\n\\begin{align*}\nW \\sim \\operatorname{Binomial}(N, p) \\space \\space (1)\\\\\np \\sim \\operatorname{Uniform}(0, 1)  \\space \\space (2)\n\\end{align*}\n$$ {#eq-globe-tossing-model}\n\n-   `W`: observed count of water\n-   `N`: total number of tosses\n-   `p`: proportion of water on the globe\n\nRead the above statement as:\n\n1.  **First line**: The count W is distributed binomially with sample\n    size `N` and probability `p`.\n2.  **Second line**: The prior for `p` is assumed to be uniform between\n    zero and one.\n:::\n\n------------------------------------------------------------------------\n\nThe first line in these kind of models always defines the likelihood\nfunction used in Bayes' theorem. The other lines define priors.\n\nBoth of the lines in the model of @eq-globe-tossing-model are\n**stochastic**, as indicated by the `~` symbol. A stochastic\nrelationship is just a mapping of a variable or parameter onto a\ndistribution. It is stochastic because no single instance of the\nvariable on the left is known with certainty. Instead, the mapping is\nprobabilistic: Some values are more plausible than others, but very many\ndifferent values are plausible under any model. Later, we'll have models\nwith deterministic definitions in them.\n\n## Gaussian model of height {#sec-gaussian-model-of-height}\n\nThere are an infinite number of possible Gaussian distributions. Some\nhave small means. Others have large means. Some are wide, with a large\n`σ`. Others are narrow. We want our Bayesian machine to consider every\npossible distribution, each defined by a combination of `μ` and `σ`, and\nrank them by posterior plausibility. Posterior plausibility provides a\nmeasure of the logical compatibility of each possible distribution with\nthe data and model.\n\n### The data\n\n#### Original\n\nThe data contained in `data(Howell1)` are partial census data for the\nDobe area !Kung San, compiled from interviews conducted by Nancy Howell\nin the late 1960s. Much more raw data is available for download from\nhttps://tspace.library.utoronto.ca/handle/1807/10395.\n\nFor the non-anthropologists reading along, the !Kung San are the most\nfamous foraging population of the twentieth century, largely because of\ndetailed quantitative studies by people like Howell.\n\n::: callout-caution\nLoading data from a package with `data()` is only possible if you have\nalready loaded the package. In our example:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: loading-data-from-package1_a\n#| eval: false\n\n\n## R code 4.7 #######################\nlibrary(rethinking)\ndata(Howell1)\nd_a <- Howell1\n```\n````\n:::\n\n\nBecause of many function name conflicts with {**brms**} I do not want to\nload {**rethinking**} and will call the function of these conflicted\npackages with `<package name>::<function name>()` Therefore I have to\nuse another, not so usual loading strategy of the data set:\n\n\n::: {.cell}\n\n````{.cell-code #lst-loading-data-from-package2_a lst-cap=\"Load data `Howell1` from the {**rethinking**} package without loading the package and assign the data to an object. Rethinking\"}\n```{{r}}\n#| label: loading-data-from-package2_a\n#| attr-source: '#lst-loading-data-from-package2_a lst-cap=\"Load data `Howell1` from the {**rethinking**} package without loading the package and assign the data to an object. Rethinking\"'\n\ndata(package = \"rethinking\", list = \"Howell1\")\nd_a <- Howell1\n```\n````\n:::\n\n\nThe advantage of this strategy is that I have not always to detach the\n{**rethinking**} package and to make sure {**rethinking**} is detached\nbefore using {**brms**} as it is necessary in the Kurz's {**tidyverse**}\n/ {**brms**} version.\n:::\n\n##### Show the data\n\n\n::: {.cell}\n\n````{.cell-code #lst-show-howell-data-a lst-cap=\"Show and inspect the data: rethinking\"}\n```{{r}}\n#| label: show-howell-data-a\n#| attr-source: '#lst-show-howell-data-a lst-cap=\"Show and inspect the data: rethinking\"'\n\n## R code 4.8 ####################\nstr(d_a)\n\n## R code 4.9 ###################\nrethinking::precis(d_a)\n```\n````\n\n```\n#> 'data.frame':\t544 obs. of  4 variables:\n#>  $ height: num  152 140 137 157 145 ...\n#>  $ weight: num  47.8 36.5 31.9 53 41.3 ...\n#>  $ age   : num  63 63 65 41 51 35 32 27 19 54 ...\n#>  $ male  : int  1 0 0 1 0 1 0 1 0 1 ...\n#>               mean         sd      5.5%     94.5%     histogram\n#> height 138.2635963 27.6024476 81.108550 165.73500 ▁▁▁▁▁▁▁▂▁▇▇▅▁\n#> weight  35.6106176 14.7191782  9.360721  54.50289 ▁▂▃▂▂▂▂▅▇▇▃▂▁\n#> age     29.3443934 20.7468882  1.000000  66.13500     ▇▅▅▃▅▂▂▁▁\n#> male     0.4724265  0.4996986  0.000000   1.00000    ▇▁▁▁▁▁▁▁▁▇\n```\n:::\n\n\nThis data frame contains four columns. Each column has 544 entries, so\nthere are 544 individuals in these data. Each individual has a recorded\nheight (centimeters), weight (kilograms), age (years), and \"maleness\" (0\nindicating female and 1 indicating male).\n\n##### Select the height data of adults\n\nWe're going to work with just the height column, for the moment. All we\nwant for now are heights of adults in the sample. The reason to filter\nout non-adults for now is that height is strongly correlated with age,\nbefore adulthood.\n\n\n::: {.cell}\n\n````{.cell-code #lst-select-height-adults-a lst-cap=\"Select the height data of adults (individuals older or equal than 18 years): base R version\"}\n```{{r}}\n#| label: select-height-adults-a\n#| attr-source: '#lst-select-height-adults-a lst-cap=\"Select the height data of adults (individuals older or equal than 18 years): base R version\"'\n\n## R code 4.10 ###################\nhead(d_a$height)\n \n## R code 4.11 ###################\nd2_a <- d_a[d_a$age >= 18, ]\n```\n````\n\n```\n#> [1] 151.765 139.700 136.525 156.845 145.415 163.830\n```\n:::\n\n\nWe'll be working with the data frame d2 now. It should have 352 rows\n(individuals) in it. We will check this with `nrow(d2_a)` =\n352.\n\n#### Tidyverse\n\n##### Show the data\n\n\n::: {.cell}\n\n````{.cell-code #lst-loading-data-from-package_b lst-cap=\"Load data `Howell1` from the {**rethinking**} package without loading the package and assign the data to an object. Tidyverse\"}\n```{{r}}\n#| label: loading-data-from-package_b\n#| attr-source: '#lst-loading-data-from-package_b lst-cap=\"Load data `Howell1` from the {**rethinking**} package without loading the package and assign the data to an object. Tidyverse\"'\n\ndata(package = \"rethinking\", list = \"Howell1\")\nd_b <- Howell1\n```\n````\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: show-howell-data1-b\n\nd_b |>\n    glimpse()\n```\n````\n\n```\n#> Rows: 544\n#> Columns: 4\n#> $ height <dbl> 151.7650, 139.7000, 136.5250, 156.8450, 145.4150, 163.8300, 149…\n#> $ weight <dbl> 47.82561, 36.48581, 31.86484, 53.04191, 41.27687, 62.99259, 38.…\n#> $ age    <dbl> 63.0, 63.0, 65.0, 41.0, 51.0, 35.0, 32.0, 27.0, 19.0, 54.0, 47.…\n#> $ male   <int> 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, …\n```\n:::\n\n\n`glimpse()` is the tidyverse analogue for `str()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: show-howell-data2-b\nd_b |> \n    summary()\n```\n````\n\n```\n#>      height           weight            age             male       \n#>  Min.   : 53.98   Min.   : 4.252   Min.   : 0.00   Min.   :0.0000  \n#>  1st Qu.:125.09   1st Qu.:22.008   1st Qu.:12.00   1st Qu.:0.0000  \n#>  Median :148.59   Median :40.058   Median :27.00   Median :0.0000  \n#>  Mean   :138.26   Mean   :35.611   Mean   :29.34   Mean   :0.4724  \n#>  3rd Qu.:157.48   3rd Qu.:47.209   3rd Qu.:43.00   3rd Qu.:1.0000  \n#>  Max.   :179.07   Max.   :62.993   Max.   :88.00   Max.   :1.0000\n```\n:::\n\n\nKurz tells us that the {**brms**} package does not have a function that\nworks like `rethinking::precis()` for providing numeric and graphical\nsummaries of variables, as in the second part of\n@lst-show-howell-data-a. Kurz suggests `base::summary()` to get some of\nthe information from `rethinking::precis()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: show-howell-data3-b\nd_b |>            \n    skimr::skim() \n```\n````\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |d_b  |\n|Number of rows           |544  |\n|Number of columns        |4    |\n|_______________________  |     |\n|Column type frequency:   |     |\n|numeric                  |4    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|    sd|    p0|    p25|    p50|    p75|   p100|hist  |\n|:-------------|---------:|-------------:|------:|-----:|-----:|------:|------:|------:|------:|:-----|\n|height        |         0|             1| 138.26| 27.60| 53.98| 125.10| 148.59| 157.48| 179.07|▁▂▂▇▇ |\n|weight        |         0|             1|  35.61| 14.72|  4.25|  22.01|  40.06|  47.21|  62.99|▃▂▃▇▂ |\n|age           |         0|             1|  29.34| 20.75|  0.00|  12.00|  27.00|  43.00|  88.00|▇▆▅▂▁ |\n|male          |         0|             1|   0.47|  0.50|  0.00|   0.00|   0.00|   1.00|   1.00|▇▁▁▁▇ |\n:::\n:::\n\n\nI think `skimr::skim()` is a better option as an alternative to\n`rethinking::precis()` as `base::summary()` because it also has a\ngraphical summary of the variables. {**skimr**} has many other useful\nfunctions and is very adaptable. I propose to install and to try it out.\n\n##### Select the height data of adults\n\nWith {**tidyverse**} we can isolate height values with the\n`dplyr::select()` function and we are using the `dplyr::filter()`\nfunction to make an adults-only data frame.\n\n\n::: {.cell}\n\n````{.cell-code #lst-select-height-adults-b lst-cap=\"Select the height data of adults (individuals older or equal than 18 years): tidyverse version\"}\n```{{r}}\n#| label: select-height-adults-b\n#| attr-source: '#lst-select-height-adults-b lst-cap=\"Select the height data of adults (individuals older or equal than 18 years): tidyverse version\"'\n\nd_b %>%\n  select(height) %>% \n  glimpse()\n\nd2_b <- \n  d_b %>%\n  filter(age >= 18) \n \nglimpse(d2_b)\n```\n````\n\n```\n#> Rows: 544\n#> Columns: 1\n#> $ height <dbl> 151.7650, 139.7000, 136.5250, 156.8450, 145.4150, 163.8300, 149…\n#> Rows: 352\n#> Columns: 4\n#> $ height <dbl> 151.7650, 139.7000, 136.5250, 156.8450, 145.4150, 163.8300, 149…\n#> $ weight <dbl> 47.82561, 36.48581, 31.86484, 53.04191, 41.27687, 62.99259, 38.…\n#> $ age    <dbl> 63.0, 63.0, 65.0, 41.0, 51.0, 35.0, 32.0, 27.0, 19.0, 54.0, 47.…\n#> $ male   <int> 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, …\n```\n:::\n\n\nThe two functions of @lst-select-height-adults-b are much more readable\nand understandable as the weird base R syntax in\n@lst-select-height-adults-a.\n\n### The model\n\n#### Original\n\nOur goal is to model the data in `d2_a` using a Gaussian distribution.\n\nPlot the distribution of heights\n\n\n::: {.cell}\n\n````{.cell-code #lst-fig-dist-heights-a lst-cap=\"Plot the distribution of the heights of adults: rethinking version\"}\n```{{r}}\n#| label: fig-dist-heights-a\n#| fig-cap: \"The distribution of the heights data,overlaid by an ideal Gaussian distribution: rethinking version\"\n#| attr-source: '#lst-fig-dist-heights-a lst-cap=\"Plot the distribution of the heights of adults: rethinking version\"'\n\nrethinking::dens(d2_a$height, norm.comp = TRUE)\n```\n````\n\n::: {.cell-output-display}\n![The distribution of the heights data,overlaid by an ideal Gaussian distribution: rethinking version](04-geocentric-models_files/figure-html/fig-dist-heights-a-1.png){#fig-dist-heights-a width=672}\n:::\n:::\n\n\nWith the option `norm.comp = TRUE` I have overlaid a Gaussian\ndistribution to see the differences to the actual data. There are some\ndifferences locally, especially on the peak of the distribution. But the\ntails looks nice and we can say that the overall impression of the curve\nis Gaussian.\n\n::: callout-caution\n###### Decisions how to model the data\n\nGawking at the raw data, to try to decide how to model them, is usually\nnot a good idea. The data could be, for example, a mixture of different\nGaussian distributions. Furthermore, the empirical distribution need not\nbe actually Gaussian in order to justify using a Gaussian probability\ndistribution.\n:::\n\nDefine the heights as normally distributed with a mean `μ` and standard\ndeviation `σ`\n\n------------------------------------------------------------------------\n\n::: {#def-height-normal-dist}\nHeights normally distributed\n\n$$\nh_{i} \\sim \\operatorname{Normal}(σ, μ) \n$$ {#eq-height-normal-dist}\n:::\n\n------------------------------------------------------------------------\n\nThe symbol `h` refers to the list of heights, and the subscript `i`\nmeans each individual element of this list. It is conventional to use\n`i` because it stands for index. The index `i` takes on row numbers, and\nso in this example can take any value from 1 to 352 (the number of\nheights in `d2_a$height`). As such, the model above is saying that all\nthe golem knows about each height measurement is defined by the same\nnormal distribution, with mean `μ` and standard deviation `σ`.\n\nThe short model in @def-height-normal-dist assumes that the values\n$h_{i}$ are *independent and identically distributed*, abbreviated\n`i.i.d.`, `iid`, or `IID`.\n\nTo complete the model, we're going to need some priors. The parameters\nto be estimated are both `μ` and `σ`, so we need a prior `Pr(μ, σ)`, the\njoint prior probability for all parameters. In most cases, priors are\nspecified independently for each parameter, which amounts to assuming\n$Pr(μ,σ) = Pr(μ)Pr(σ)$.\n\n------------------------------------------------------------------------\n\n::: {#def-prior-height-model}\nPriors for heights model\n\n$$\n\\begin{align*}\nh_{i} \\sim \\operatorname{Normal}(μ, σ) \\space \\space (1) \\\\ \nμ \\sim \\operatorname{Normal}(178, 20)  \\space \\space (2) \\\\ \nμ \\sim \\operatorname{Uniform}(0, 50)   \\space \\space (3)      \n\\end{align*}\n$$ {#eq-prior-height-model}\n\n1.  First line represents the likelihood.\n2.  Second line is the chosen `μ`(mu, mean) prior.\n3.  Third line is the chosen `σ` (sigma, standard deviation) prior.\n:::\n\n------------------------------------------------------------------------\n\nLet's think about the chosen value for the priors more in detail:\n\nThe prior for `μ` is a broad Gaussian prior, centered on 178 cm, with\n95% of probability between 178 ± 40 cm.\n\nWhy 178 cm? Your author is 178 cm tall. And the range from 138 cm to 218\ncm encompasses a huge range of plausible mean heights for human\npopulations. So domain-specific information has gone into this prior.\nEveryone knows something about human height and can set a reasonable and\nvague prior of this kind. But in many regression problems, as you'll see\nlater, using prior information is more subtle, because parameters don't\nalways have such clear physical meaning.\n\nWhatever the prior, it's a very good idea to plot your priors, so you\nhave a sense of the assumption they build into the model.\n\n**Plot the mu prior (mean)**\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-mean-prior-a\n#| fig-cap: \"Plot of the chosen mean prior: base R version\"\n\n## R code 4.12 ###############################\ncurve(dnorm(x, 178, 20), from = 100, to = 250)\n```\n````\n\n::: {.cell-output-display}\n![Plot of the chosen mean prior: base R version](04-geocentric-models_files/figure-html/fig-mean-prior-a-1.png){#fig-mean-prior-a width=672}\n:::\n:::\n\n\nYou can see that the golem is assuming that the average height (not each\nindividual height) is almost certainly between 140 cm and 220 cm. So\nthis prior carries a little information, but not a lot.\n\n**Plot the sigma prior (standard deviation)**\n\nA standard deviation like `σ` must be positive, so bounding it at zero\nmakes sense. How should we pick the upper bound? In this case, a\nstandard deviation of 50 cm would imply that 95% of individual heights\nlie within 100 cm of the average height. That's a very large range.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-sd-prior-a\n#| fig-cap: \"Plot the chosen prior for the standard deviation: base R version\"\n\n## R code 4.13 ###########################\ncurve(dunif(x, 0, 50), from = -10, to = 60)\n```\n````\n\n::: {.cell-output-display}\n![Plot the chosen prior for the standard deviation: base R version](04-geocentric-models_files/figure-html/fig-sd-prior-a-1.png){#fig-sd-prior-a width=672}\n:::\n:::\n\n\n**Prior predictive simulation**\n\n> Once you've chosen priors for *h, μ*, and *σ*, these imply a joint\n> prior distribution of individual heights. By simulating from this\n> distribution, you can see what your choices imply about observable\n> height. This helps you diagnose bad choices.\n\nOkay, so how to do this? You can quickly simulate heights by sampling\nfrom the prior, like you sampled from the posterior back in\n@sec-sampling-the-imaginary. Remember, every posterior is also\npotentially a prior for a subsequent analysis, so you can process priors\njust like posteriors.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-prior-predictive-sim-a\n#| fig-cap: \"Simulate heights by sampling from the prior: rethinking version\"\n\nset.seed(4) # to make example reproducible\n## R code 4.14 #######################################\nsample_mu_a <- rnorm(1e4, 178, 20)\nsample_sigma_a <- runif(1e4, 0, 50)\nprior_h_a <- rnorm(1e4, sample_mu_a, sample_sigma_a)\nrethinking::dens(prior_h_a, norm.comp = TRUE)\n```\n````\n\n::: {.cell-output-display}\n![Simulate heights by sampling from the prior: rethinking version](04-geocentric-models_files/figure-html/fig-prior-predictive-sim-a-1.png){#fig-prior-predictive-sim-a width=672}\n:::\n:::\n\n\n> It displays a vaguely bell-shaped density with thick tails. It is the\n> expected distribution of heights, averaged over the prior. Notice that\n> the prior probability distribution of height is not itself Gaussian.\n> This is okay. The distribution you see is not an empirical\n> expectation, but rather the distribution of relative plausibilities of\n> different heights, before seeing the data.\n\nThis comment is strange for me as in my point of view the distribution\n*is* Gaussian. It is true that the tails are (a little bit?) thicker\nthan in the standard Gaussian distribution. But in my view\n@fig-prior-predictive-sim-a is more Gaussian than @fig-dist-heights-a.\nOK, in @fig-dist-heights-a we have just 352 data and in\n@fig-prior-predictive-sim-a we sampled 10,000 times. But this is not a\ncounter argument for @fig-prior-predictive-sim-a not being a a bell\nshaped distribution.\n\n**Simulate heights from priors with large sd**\n\nPrior predictive simulation is very useful for assigning sensible\npriors, because it can be quite hard to anticipate how priors influence\nthe observable variables. As an example, consider a much flatter and\nless informative prior for `μ`, like $μ \\sim Normal(178, 100)$. Priors\nwith such large standard deviations are quite common in Bayesian models,\nbut they are hardly ever sensible.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-prior-predictive-sim2-a\n#| fig-cap: \"Simulate heights from priors with a large standard deviation: rethinking version\"\n\nset.seed(4) # to make example reproducible\n## R code 4.15 ############################\nsample_mu2_a <- rnorm(1e4, 178, 100)\nprior_h2_a <- rnorm(1e4, sample_mu2_a, sample_sigma_a)\nrethinking::dens(prior_h2_a)\n```\n````\n\n::: {.cell-output-display}\n![Simulate heights from priors with a large standard deviation: rethinking version](04-geocentric-models_files/figure-html/fig-prior-predictive-sim2-a-1.png){#fig-prior-predictive-sim2-a width=672}\n:::\n:::\n\n\nThe results of @fig-prior-predictive-sim2-a contradicts our scientific\nknowledge --- but also our common sense --- about possible height values\nof humans. Now the model, before seeing the data, expects people to have\nnegative height. It also expects some giants. One of the tallest people\nin recorded history, [Robert Pershing\nWadlow](https://en.wikipedia.org/wiki/Robert_Wadlow) (1918--1940) stood\n272 cm tall. In our prior predictive simulation many people are taller\nthan this.\n\nDoes this matter? In this case, we have so much data that the silly\nprior is harmless. But that won't always be the case. There are plenty\nof inference problems for which the data alone are not sufficient, no\nmatter how numerous. Bayes lets us proceed in these cases. But only if\nwe use our scientific knowledge to construct sensible priors. Using\nscientific knowledge to build priors is not cheating. The important\nthing is that your prior not be based on the values in the data, but\nonly on what you know about the data before you see it.\n\n#### Tidyverse\n\nThe plot of the heights distribution compared with the standard Gaussian\ndistribution is missing in Kurz's version. I added this plot by using\nthe last example of [How to Plot a Normal Distribution in\nR](https://www.statology.org/plot-normal-distribution-r/).\n\n\n::: {.cell}\n\n````{.cell-code #lst-fig-dist-heights-b lst-cap=\"Plot the distribution of the heights of adults: tidyverse version\"}\n```{{r}}\n#| label: fig-dist-heights-b\n#| fig-cap: \"The distribution of the heights data, overlaid by an ideal Gaussian distribution: tidyverse version\"\n#| attr-source: '#lst-fig-dist-heights-b lst-cap=\"Plot the distribution of the heights of adults: tidyverse version\"'\n\np0 <- \n    d2_b |> \n    ggplot(aes(height)) +\n    geom_density() +\n\n    stat_function(\n        fun = dnorm,\n        args = with(d2_b, c(mean = mean(height), sd = sd(height)))\n        ) +\n    scale_x_continuous(\"Height in cm\")\n\np0\n```\n````\n\n::: {.cell-output-display}\n![The distribution of the heights data, overlaid by an ideal Gaussian distribution: tidyverse version](04-geocentric-models_files/figure-html/fig-dist-heights-b-1.png){#fig-dist-heights-b width=672}\n:::\n:::\n\n\nHere is the shape for the prior $μ \\sim Normal(178, 20)$.\n\n\n::: {.cell}\n\n````{.cell-code #lst-fig-mean-prior-b lst-cap=\"Plot of the chosen mean prior: tidyverse version\"}\n```{{r}}\n#| label: fig-mean-prior-b\n#| fig-cap: \"Plot of the chosen mean prior: tidyverse version\"\n#| attr-source: '#lst-fig-mean-prior-b lst-cap=\"Plot of the chosen mean prior: tidyverse version\"'\n\np1 <-\n  tibble(x = seq(from = 100, to = 250, by = .1)) %>% \n    \n  ggplot(aes(x = x, y = dnorm(x, mean = 178, sd = 20))) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(from = 100, to = 250, by = 75)) +\n  labs(title = \"mu ~ dnorm(178, 20)\",\n       y = \"density\")\n\np1\n```\n````\n\n::: {.cell-output-display}\n![Plot of the chosen mean prior: tidyverse version](04-geocentric-models_files/figure-html/fig-mean-prior-b-1.png){#fig-mean-prior-b width=672}\n:::\n:::\n\n\nAnd here's the ggplot2 code for our prior for `σ`, a uniform\ndistribution with a minimum value of 0 and a maximum value of 50. We\ndon't really need the `y`-axis when looking at the shapes of a density,\nso we'll just remove it with `scale_y_continuous()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-sd-prior-b\n#| fig-cap: \"Plot the chosen prior for the standard deviation: tidyverse version\"\n\np2 <-\n  tibble(x = seq(from = -10, to = 60, by = .1)) %>%\n  \n  ggplot(aes(x = x, y = dunif(x, min = 0, max = 50))) +\n  geom_line() +\n  scale_x_continuous(breaks = c(0, 50)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  ggtitle(\"sigma ~ dunif(0, 50)\")\n\np2\n```\n````\n\n::: {.cell-output-display}\n![Plot the chosen prior for the standard deviation: tidyverse version](04-geocentric-models_files/figure-html/fig-sd-prior-b-1.png){#fig-sd-prior-b width=672}\n:::\n:::\n\n\nWe can simulate from both priors at once to get a prior probability\ndistribution of `height`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-prior-predictive-sim-b\n#| fig-cap: \"Simulate heights by sampling from the prior: tidyverse version\"\n\nn <- 1e4\nset.seed(4)\n\nsim <-\n  tibble(sample_mu_b    = rnorm(n, mean = 178, sd  = 20),\n         sample_sigma_b = runif(n, min = 0, max = 50)) %>% \n  mutate(height = rnorm(n, mean = sample_mu_b, sd = sample_sigma_b))\n  \np3 <- sim %>% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"deepskyblue\") +\n  scale_x_continuous(breaks = c(0, 73, 178, 283)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  ggtitle(\"height ~ dnorm(mu, sigma)\") +\n  theme(panel.grid = element_blank())\n\np3\n```\n````\n\n::: {.cell-output-display}\n![Simulate heights by sampling from the prior: tidyverse version](04-geocentric-models_files/figure-html/fig-prior-predictive-sim-b-1.png){#fig-prior-predictive-sim-b width=672}\n:::\n:::\n\n\nIf you look at the `x`-axis breaks on the plot in McElreath's lower left\npanel in Figure 4.3, you'll notice they're intentional. To compute the\nmean and 3 standard deviations above and below, you might do this.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: compute-mean-3sd-b\nsim %>% \n  summarise(ll   = mean(height) - sd(height) * 3,\n            mean = mean(height),\n            ul   = mean(height) + sd(height) * 3) %>% \n  mutate_all(round, digits = 1)\n```\n````\n\n```\n#> # A tibble: 1 × 3\n#>      ll  mean    ul\n#>   <dbl> <dbl> <dbl>\n#> 1  73.9  177.  281.\n```\n:::\n\n\nHere's the work to make the lower right panel of Figure 4.3.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-reproduce-4.3-low-right\n#| fig-cap: \"Reproduce lower right panels of Figure 4.3\"\n\n\n# simulate\nset.seed(4)\n\nsim <-\n  tibble(sample_mu_b    = rnorm(n, mean = 178, sd = 100),\n         sample_sigma_b = runif(n, min = 0, max = 50)) %>% \n  mutate(height = rnorm(n, mean = sample_mu_b, sd = sample_sigma_b))\n\n# compute the values we'll use to break on our x axis\nbreaks <-\n  c(mean(sim$height) - 3 * sd(sim$height), 0, mean(sim$height), mean(sim$height) + 3 * sd(sim$height)) %>% \n  round(digits = 0)\n\n# this is just for aesthetics\ntext <-\n  tibble(height = 272 - 25,\n         y      = .0013,\n         label  = \"tallest man\",\n         angle  = 90)\n\n# plot\np4 <-\n  sim %>% \n  ggplot(aes(x = height)) +\n  geom_density(fill = \"deepskyblue\", color = \"black\") +\n  geom_vline(xintercept = 0, color = \"black\") +\n  geom_vline(xintercept = 272, color = \"black\", linetype = 3) +\n  geom_text(data = text,\n            aes(y = y, label = label, angle = angle),\n            color = \"black\") +\n  scale_x_continuous(breaks = breaks) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  ggtitle(\"height ~ dnorm(mu, sigma)\\nmu ~ dnorm(178, 100)\") +\n  theme(panel.grid = element_blank())\n\np4\n```\n````\n\n::: {.cell-output-display}\n![Reproduce lower right panels of Figure 4.3](04-geocentric-models_files/figure-html/fig-reproduce-4.3-low-right-1.png){#fig-reproduce-4.3-low-right width=672}\n:::\n:::\n\n\nLet's combine the four to make our version of McElreath's Figure 4.3.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-reproduce-3.4\n#| fig-cap: \"Reproduction of Figure 3.4\"\n\nlibrary(patchwork)\n(p1 + xlab(\"mu\") | p2 + xlab(\"sigma\")) / (p3 | p4)\n```\n````\n\n::: {.cell-output-display}\n![Reproduction of Figure 3.4](04-geocentric-models_files/figure-html/fig-reproduce-3.4-1.png){#fig-reproduce-3.4 width=672}\n:::\n:::\n\n\nOn page 84, McElreath said his prior simulation indicated 4% of the\nheights would be below zero. He also drew the break down compared to the\ntallest man on record, [Robert Pershing\nWadlow](https://en.wikipedia.org/wiki/Robert_Wadlow) (1918--1940).\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: calc-breaks-b\n\nsim %>% \n  count(height < 0) %>% \n  mutate(percent = 100 * n / sum(n))\n\nsim %>% \n  count(height < 272) %>% \n  mutate(percent = 100 * n / sum(n))\n```\n````\n\n```\n#> # A tibble: 2 × 3\n#>   `height < 0`     n percent\n#>   <lgl>        <int>   <dbl>\n#> 1 FALSE         9571   95.7 \n#> 2 TRUE           429    4.29\n#> # A tibble: 2 × 3\n#>   `height < 272`     n percent\n#>   <lgl>          <int>   <dbl>\n#> 1 FALSE           1761    17.6\n#> 2 TRUE            8239    82.4\n```\n:::\n\n\n### Grid approximation of the posterior distribution\n\n#### Original\n\nWe are going to map out the posterior distribution through brute force\ncalculations.\n\nThis is not recommended because it is\n\n-   laborious and computationally expensive\n-   usually so impractical as to be essentially impossible.\n\nTherefor the grid approximation technique has limited relevance. Later\non we will use the quadratic approximation with `rethinking::quap()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: grid-approx-posterior-a\n\n## R code 4.16 ##################################\n\n# establish range of μ and σ values, respectively, to calculate over \n# as well as how many points to calculate in-between. \nmu.list_a <- seq(from = 150, to = 160, length.out = 100)\nsigma.list_a <- seq(from = 7, to = 9, length.out = 100)\n\n# expands μ & σ values into a matrix of all of the combinations\npost_a <- expand.grid(mu_a = mu.list_a, sigma_a = sigma.list_a)\n\n# compute the log-likelihood at each combination of μ and σ\npost_a$LL <- sapply(1:nrow(post_a), function(i) {\n  sum(\n    dnorm(d2_a$height, post_a$mu[i], post_a$sigma[i], log = TRUE)\n  )\n})\n\n# multiply the prior by the likelihood\n# as the priors are on the log scale adding = multiplying\npost_a$prod <- post_a$LL + dnorm(post_a$mu_a, 178, 20, TRUE) +\n  dunif(post_a$sigma_a, 0, 50, TRUE)\n\n# getting back on the probability scale without rounding error \npost_a$prob <- exp(post_a$prod - max(post_a$prod))\n```\n````\n:::\n\n\n> **Comment to the last line**: the obstacle for getting back on the\n> probability scale is that rounding error is always a threat when\n> moving from log-probability to probability. If you use the obvious\n> approach, like `exp( post$prod )`, you'll get a vector full of zeros,\n> which isn't very helpful. This is a result of R's rounding very small\n> probabilities to zero.\n\n**Plot contour lines**\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-contour-plot-a\n#| fig-cap: \"Draw a contour plot: rethinking version\"\n\n## R code 4.17 ##################################\nrethinking::contour_xyz(post_a$mu_a, post_a$sigma_a, post_a$prob)\n```\n````\n\n::: {.cell-output-display}\n![Draw a contour plot: rethinking version](04-geocentric-models_files/figure-html/fig-contour-plot-a-1.png){#fig-contour-plot-a width=672}\n:::\n:::\n\n\nYou can inspect this posterior distribution, now residing in\n`post_a$prob`, using a variety of plotting commands.\n\n**Plot heat map**\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-heat-map-a\n#| fig-cap: \"Draw a heat map: rethinking version\"\n\n## R code 4.18 ##################################\nrethinking::image_xyz(post_a$mu_a, post_a$sigma_a, post_a$prob)\n```\n````\n\n::: {.cell-output-display}\n![Draw a heat map: rethinking version](04-geocentric-models_files/figure-html/fig-heat-map-a-1.png){#fig-heat-map-a width=672}\n:::\n:::\n\n\n#### Tidyverse\n\nWith grid approximation we are going to use the brute force method for\nthe calculation of the posterior distribution. This technique has\nlimited relevance. Later on we will use the quadratic approximation with\n`brms::brm()`.\n\nIt is the same technique we have use in\n@sec-sampling-from-a-grid-approximate-posterior respectively in the\ntidyverse version in @sec-grid-approximation-b. As there is no\nconceptually new information to learn, I am not going into the details\nof the following code. (It combines several code chunk from Kurz's\nversion.) But I am going to foreshadow the most important differences in\nthe tidyverse approach of the grid approximation technique:\n\nInstead of `base::grid_expand()` we will use `tidyr::crossing()` Instead\nof `base::sapply()` we will use `purr::map2()`\n\nThe produced tibble contains data frames in its cells, so that we have\nto use the `tidyr::unnest()` function to expand the list-column\ncontaining data frames into rows and columns.\n\nReferring to the plots:\n\n-   Instead of `rethinking::contour_xyz()` we will use\n    `ggplot2::geom_contour()`\n-   Instead of `rethinking::image_xyz()` we will use\n    `ggplot2::geom_raster()`\n\n\n::: {.cell}\n\n````{.cell-code #lst-grid-approx-posterior-b lst-cap=\"Grid Approximation of the posterior distribution: tidyverse version\"}\n```{{r}}\n#| label: grid-approx-posterior-b\n#| attr-source: '#lst-grid-approx-posterior-b lst-cap=\"Grid Approximation of the posterior distribution: tidyverse version\"'\n\nn <- 200\n\nd_grid_b <-\n  # we'll accomplish with `tidyr::crossing()` what McElreath did with base R `expand.grid()`\n  crossing(mu_b    = seq(from = 140, to = 160, length.out = n),\n           sigma_b = seq(from = 4, to = 9, length.out = n))\n\nglimpse(d_grid_b)\n\ngrid_function <- function(mu, sigma) {\n  \n  dnorm(d2_b$height, mean = mu, sd = sigma, log = TRUE) %>% \n    sum()\n  \n}\n\nd_grid2_b <-\n  d_grid_b %>% \n  mutate(log_likelihood_b = map2(mu_b, sigma_b, grid_function)) %>%\n  unnest(log_likelihood_b) %>% \n  mutate(prior_mu_b    = dnorm(mu_b, mean = 178, sd = 20, log = T),\n         prior_sigma_b = dunif(sigma_b, min = 0, max = 50, log = T)) %>% \n  mutate(product_b = log_likelihood_b + prior_mu_b + prior_sigma_b) %>% \n  mutate(probability_b = exp(product_b - max(product_b)))\n  \nhead(d_grid2_b)\n```\n````\n\n```\n#> Rows: 40,000\n#> Columns: 2\n#> $ mu_b    <dbl> 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 14…\n#> $ sigma_b <dbl> 4.000000, 4.025126, 4.050251, 4.075377, 4.100503, 4.125628, 4.…\n#> # A tibble: 6 × 7\n#>    mu_b sigma_b log_likelihood_b prior_mu_b prior_sigma_b product_b\n#>   <dbl>   <dbl>            <dbl>      <dbl>         <dbl>     <dbl>\n#> 1   140    4              -3813.      -5.72         -3.91    -3822.\n#> 2   140    4.03           -3778.      -5.72         -3.91    -3787.\n#> 3   140    4.05           -3743.      -5.72         -3.91    -3753.\n#> 4   140    4.08           -3709.      -5.72         -3.91    -3719.\n#> 5   140    4.10           -3676.      -5.72         -3.91    -3686.\n#> 6   140    4.13           -3644.      -5.72         -3.91    -3653.\n#> # ℹ 1 more variable: probability_b <dbl>\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-contour-b\n#| fig-cap: \"Draw 2D contours of a 3D surface\"\n\nd_grid2_b %>% \n  ggplot(aes(x = mu_b, y = sigma_b, z = probability_b)) + \n  geom_contour() +\n  labs(x = expression(mu),\n       y = expression(sigma)) +\n  coord_cartesian(xlim = range(d_grid2_b$mu_b),\n                  ylim = range(d_grid2_b$sigma_b)) +\n  theme(panel.grid = element_blank())\n```\n````\n\n::: {.cell-output-display}\n![Draw 2D contours of a 3D surface](04-geocentric-models_files/figure-html/fig-contour-b-1.png){#fig-contour-b width=672}\n:::\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-heatmap-b\n#| fig-cap: \"Draw heat map\"\n\nd_grid2_b %>% \n  ggplot(aes(x = mu_b, y = sigma_b, fill = probability_b)) + \n  geom_raster(interpolate = TRUE) +\n  scale_fill_viridis_c(option = \"B\") +\n  labs(x = expression(mu),\n       y = expression(sigma)) +\n  theme(panel.grid = element_blank())\n```\n````\n\n::: {.cell-output-display}\n![Draw heat map](04-geocentric-models_files/figure-html/fig-heatmap-b-1.png){#fig-heatmap-b width=672}\n:::\n:::\n\n\n### Sampling from the posterior\n\n#### Original\n\nTo study this posterior distribution in more detail, again I'll push the\nflexible approach of sampling parameter values from it. This works just\nlike it did in @sec-sampling-to-summarize, when you sampled values of\n`p` from the posterior distribution for the globe tossing example. The\nonly new trick is that since there are two parameters, and we want to\nsample combinations of them, we first randomly sample row numbers in\npost in proportion to the values in \\`post_a\\$prob´. Then we pull out\nthe parameter values on those randomly sampled rows.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-posterior-sample-a\n#| fig-cap: \"Samples from the posterior distribution for the heights data. The density of points is highest in the center, reflecting the most plausible combinations of μ and σ. There are many more ways for these parameter values to produce the data, conditional on the model. (rethinking version)\"\n\n## R code 4.19 ###########################\n\n# randomly sample row numbers in post_a \n# in proportion to the values in post_a$prob. \nsample.rows <- sample(1:nrow(post_a),\n  size = 1e4, replace = TRUE,\n  prob = post_a$prob\n)\n\n# pull out the parameter values\nsample.mu_a <- post_a$mu[sample.rows]\nsample.sigma_a <- post_a$sigma[sample.rows]\n\n## R code 4.20 ###########################\nplot(sample.mu_a, sample.sigma_a, cex = 0.8, pch = 21, col = rethinking::col.alpha(rethinking:::rangi2, 0.1))\n```\n````\n\n::: {.cell-output-display}\n![Samples from the posterior distribution for the heights data. The density of points is highest in the center, reflecting the most plausible combinations of μ and σ. There are many more ways for these parameter values to produce the data, conditional on the model. (rethinking version)](04-geocentric-models_files/figure-html/fig-posterior-sample-a-1.png){#fig-posterior-sample-a width=672}\n:::\n:::\n\n\nThe function `col.alpha()` is part of the {**rethinking**} R package.\nAll it does is make colors transparent, which helps the plot in FIGURE\n4.4 (here: @fig-posterior-sample-a) more easily show density, where\nsamples overlap. Adjust the plot to your tastes by playing around with\n`cex` (character expansion, the size of the points), `pch` (plot\ncharacter), and the 0.1 transparency value.\n\n**Marginal Posterior Density**\n\nNow that you have these samples, you can describe the distribution of\nconfidence in each combination of `μ` and `σ` by summarizing the\nsamples. Think of them like data and describe them, just like in\n@sec-sampling-to-summarize. For example, to characterize the shapes of\nthe marginal posterior densities of `μ` and `σ`, all we need to do is:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-marg-post-density-a\n#| fig-cap: \"Shapes of the marginal posterior densities of μ and σ: rethinking version\"\n\n## R code 4.21 #########################\nrethinking::dens(sample.mu_a)\nrethinking::dens(sample.sigma_a)\n```\n````\n\n::: {.cell-output-display}\n![Shapes of the marginal posterior densities of μ and σ: rethinking version](04-geocentric-models_files/figure-html/fig-marg-post-density-a-1.png){#fig-marg-post-density-a-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Shapes of the marginal posterior densities of μ and σ: rethinking version](04-geocentric-models_files/figure-html/fig-marg-post-density-a-2.png){#fig-marg-post-density-a-2 width=672}\n:::\n:::\n\n\nThe jargon \"marginal\" here means \"averaging over the other parameters.\"\nExecute the above code and inspect the plots. These densities are very\nclose to being normal distributions. And this is quite typical. As\nsample size increases, posterior densities approach the normal\ndistribution. If you look closely, though, you'll notice that the\ndensity for σ has a longer right-hand tail. I'll exaggerate this\ntendency a bit later, to show you that this condition is very common for\nstandard deviation parameters.\n\n**Posterior Compatibility Intervals (PIs)**\n\nTo summarize the widths of these densities with posterior compatibility\nintervals we use:\n\n\n::: {.cell}\n\n````{.cell-code #lst-post-comp-intervals-a lst-cap=\"Posterior Compatibility Intervals (PIs): rethinking version\"}\n```{{r}}\n#| label: post-comp-intervals-a\n#| attr-source: '#lst-post-comp-intervals-a lst-cap=\"Posterior Compatibility Intervals (PIs): rethinking version\"'\n\n## R code 4.22 ####################\nrethinking::PI(sample.mu_a)\nrethinking::PI(sample.sigma_a)\n```\n````\n\n```\n#>       5%      94% \n#> 153.9394 155.2525 \n#>       5%      94% \n#> 7.323232 8.252525\n```\n:::\n\n\nSince these samples are just vectors of numbers, you can compute any\nstatistic from them that you could from ordinary data: `mean`, `median`,\nor `quantile`, for example.\n\n**Sample size and the normality of sigmas posterior**\n\nBefore moving on to using quadratic approximation `rethinking::quap()`\nas shortcut to all of this inference, it is worth repeating the analysis\nof the height data above, but now with only a fraction of the original\ndata. The reason to do this is to demonstrate that, in principle, the\nposterior is not always so Gaussian in shape. There's no trouble with\nthe mean, `μ`. For a Gaussian likelihood and a Gaussian prior on `μ`,\nthe posterior distribution is always Gaussian as well, regardless of\nsample size. It is the standard deviation `σ` that causes problems. So\nif you care about `σ`---often people do not---you do need to be careful\nof abusing the quadratic approximation.\n\nThe deep reasons for the posterior of `σ` tending to have a long\nright-hand tail are complex. But a useful way to conceive of the problem\nis that variances must be positive. As a result, there must be more\nuncertainty about how big the variance (or standard deviation) is than\nabout how small it is. For example, if the variance is estimated to be\nnear zero, then you know for sure that it can't be much smaller. But it\ncould be a lot bigger.\n\nLet's quickly analyze only 20 of the heights from the height data to\nreveal this issue. To sample 20 random heights from the original list:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-sample-only-20-a\n#| fig-cap: \"Sample 20 heights: rethinking version\"\n\n## R code 4.23 ######################################\nd3_a <- sample(d2_a$height, size = 20)\n\n## R code 4.24 ######################################\nmu2_a.list <- seq(from = 150, to = 170, length.out = 200)\nsigma2_a.list <- seq(from = 4, to = 20, length.out = 200)\npost2_a <- expand.grid(mu = mu2_a.list, sigma = sigma2_a.list)\npost2_a$LL <- sapply(1:nrow(post2_a), function(i) {\n  sum(dnorm(d3_a,\n    mean = post2_a$mu[i], sd = post2_a$sigma[i],\n    log = TRUE\n  ))\n})\npost2_a$prod <- post2_a$LL + dnorm(post2_a$mu, 178, 20, TRUE) +\n  dunif(post2_a$sigma, 0, 50, TRUE)\npost2_a$prob <- exp(post2_a$prod - max(post2_a$prod))\nsample2_a.rows <- sample(1:nrow(post2_a),\n  size = 1e4, replace = TRUE,\n  prob = post2_a$prob\n)\nsample2_a.mu <- post2_a$mu[sample2_a.rows]\nsample2_a.sigma <- post2_a$sigma[sample2_a.rows]\nplot(sample2_a.mu, sample2_a.sigma,\n  cex = 0.5,\n  col = rethinking::col.alpha(rethinking:::rangi2, 0.1),\n  xlab = \"mu\", ylab = \"sigma\", pch = 16\n)\n```\n````\n\n::: {.cell-output-display}\n![Sample 20 heights: rethinking version](04-geocentric-models_files/figure-html/fig-sample-only-20-a-1.png){#fig-sample-only-20-a width=672}\n:::\n:::\n\n\nyou'll see another scatter plot of the samples from the posterior\ndensity, but this time you'll notice a distinctly longer tail at the top\nof the cloud of points.\n\n**Marginal Posterior Density with only 20 rows**\n\nYou should also inspect the marginal posterior density for σ, averaging\nover μ, produced with:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-marg-post-density-a2\n#| fig-cap: \"Marginal posterior density for σ, averaging over μ: rethinking version\"\n\n## R code 4.25\nrethinking::dens(sample2_a.sigma, norm.comp = TRUE)\n```\n````\n\n::: {.cell-output-display}\n![Marginal posterior density for σ, averaging over μ: rethinking version](04-geocentric-models_files/figure-html/fig-marg-post-density-a2-1.png){#fig-marg-post-density-a2 width=672}\n:::\n:::\n\n\n#### Tidyverse\n\nWe can use `dplyr::sample_n()` to sample rows, with replacement, from\n`d_grid2_b`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-posterior-sample-b\n#| fig-cap: \"Samples from the posterior distribution for the heights data. The density of points is highest in the center, reflecting the most plausible combinations of μ and σ. There are many more ways for these parameter values to produce the data, conditional on the model. (tidyverse version)\"\n\n\nset.seed(4)\n\nd_grid_samples_b <- \n  d_grid2_b %>% \n  sample_n(size = 1e4, replace = T, weight = probability_b)\n\nd_grid_samples_b %>% \n  ggplot(aes(x = mu_b, y = sigma_b)) + \n  geom_point(size = .9, alpha = 1/15) +\n  scale_fill_viridis_c() +\n  labs(x = expression(mu[samples]),\n       y = expression(sigma[samples])) +\n  theme(panel.grid = element_blank())\n```\n````\n\n::: {.cell-output-display}\n![Samples from the posterior distribution for the heights data. The density of points is highest in the center, reflecting the most plausible combinations of μ and σ. There are many more ways for these parameter values to produce the data, conditional on the model. (tidyverse version)](04-geocentric-models_files/figure-html/fig-posterior-sample-b-1.png){#fig-posterior-sample-b width=672}\n:::\n:::\n\n\nWe can use `tidyr::pivot_longer()` and then `ggplot2::facet_wrap()` to\nplot the densities for both `mu` and `sigma` at once.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-densities-mu-sigma\n#| fig-cap: \"Shapes of the marginal posterior densities of μ and σ: tidyverse version\"\n\nd_grid_samples_b %>% \n  pivot_longer(mu_b:sigma_b) %>% \n\n  ggplot(aes(x = value)) + \n  geom_density(fill = \"deepskyblue\", color = \"black\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(NULL) +\n  theme(panel.grid = element_blank()) +\n  facet_wrap(~ name, scales = \"free\", labeller = label_parsed)\n```\n````\n\n::: {.cell-output-display}\n![Shapes of the marginal posterior densities of μ and σ: tidyverse version](04-geocentric-models_files/figure-html/fig-densities-mu-sigma-1.png){#fig-densities-mu-sigma width=672}\n:::\n:::\n\n\nWe'll use the {**tidybayes**} package to compute their posterior modes\nand 95% HDIs.\n\n::: {.callout-important}\nThere is a companion package {**ggdist**} which is imported by {**tidybayes**}. Whenever you cannot find the function in {**tidybayes**} then look at the documentation of {**ggdist**}. This is also the case for the `tidybayes::mode_hdi()` function. In the help files of {**tidybayes**} you will just find notes about a deprecated `tidybayes::mode_hdih()` function but not the arguments of its new version without the last `h` (for horizontal) `tidybayes::mode_hdi()`. But you can look up these details in the {**ggdist**} documentation. This observation is valid for many families of deprecated functions.\n\nThere is a division of functionality between {**tidybayes**} and {**ggdist**}:\n\n- {**tidybayes**}: Tidy Data and 'Geoms' for Bayesian Models: Compose data for and extract, manipulate, and visualize posterior draws from Bayesian models in a tidy data format. Functions are provided to help extract tidy data frames of draws from Bayesian models and that generate point summaries and intervals in a tidy format.\n- {**ggdist**}: Visualizations of Distributions and Uncertainty: Provides primitives for visualizing distributions using {**ggplot2**} that are particularly tuned for visualizing uncertainty in either a frequentist or Bayesian mode. Both analytical distributions (such as frequentist confidence distributions or Bayesian priors) and distributions represented as samples (such as bootstrap distributions or Bayesian posterior samples) are easily visualized.\n:::\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: post-mode-hdi95-b\n\nd_grid_samples_b %>% \n  pivot_longer(mu_b:sigma_b) %>% \n  group_by(name) %>% \n  tidybayes::mode_hdi(value) \n```\n````\n\n```\n#> # A tibble: 2 × 7\n#>   name     value .lower .upper .width .point .interval\n#>   <chr>    <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1 mu_b    155.   154.   155.     0.95 mode   hdi      \n#> 2 sigma_b   7.82   7.19   8.35   0.95 mode   hdi\n```\n:::\n\n\nLet's say you wanted their posterior medians and 50% quantile-based\nintervals, instead. Just switch out the last line for\n`tidybayes::median_qi(value, .width = .5)`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: post-median-qi90-b\n\nd_grid_samples_b %>% \n  pivot_longer(mu_b:sigma_b) %>% \n  group_by(name) %>% \n  tidybayes::median_qi(value, .width = .5)\n```\n````\n\n```\n#> # A tibble: 2 × 7\n#>   name     value .lower .upper .width .point .interval\n#>   <chr>    <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1 mu_b    155.   154.   155.      0.5 median qi       \n#> 2 sigma_b   7.77   7.57   7.97    0.5 median qi\n```\n:::\n\n\n**Sample size and the normality of σ's posterior**\n\nI will skip this part as there is nothing conceptually new in this\nsection.\n\n### Finding the posterior distribution with `quap()` resp. `brms()`\n\n#### Original\n\n> To build the **quadratic approximation**, we'll use quap, a command in\n> the `rethinking` package. The `quap` function works by using the model\n> definition you were introduced to earlier in this chapter. Each line\n> in the definition has a corresponding definition in the form of R\n> code. The engine inside quap then uses these definitions to define the\n> posterior probability at each combination of parameter values. Then it\n> can climb the posterior distribution and find the peak, its MAP\n> (**Maximum A Posteriori** estimate). Finally, it estimates the\n> quadratic curvature at the MAP to produce an approximation of the\n> posterior distribution. (parenthesis and emphasis are mine)\n\n::: callout-note\nThe procedure used by `rethinking:quap()` is very similar to what many\nnon-Bayesian procedures do, just without any priors.\n:::\n\n1.  We start with the Howell1 data frame for adults `d2_a` (age \\>= 18).\n    We will place the R code equivalents into an `alist()` We are going\n    to use the @def-prior-height-model. (Code 4.27).\n2.  Then we fit the model with `rethinking::quap()` to the data in the\n    data frame `d2_a` (Code 4.28) to `m4.1`.\n3.  Now we can have a look with `rethinking::precis()` at the posterior\n    distribution (Code 4.29).\n\n\n::: {.cell}\n\n````{.cell-code #lst-post-dist-quap-m4-1-a lst-cap=\"Finding the posterior distribution with rethinking::quap()\"}\n```{{r}}\n#| label: post-dist-quap-m4-1-a\n#| attr-source: '#lst-post-dist-quap-m4-1-a lst-cap=\"Finding the posterior distribution with rethinking::quap()\"'\n\n## R code 4.27 ######################\nflist <- alist(\n  height ~ dnorm(mu, sigma),\n  mu ~ dnorm(178, 20),\n  sigma ~ dunif(0, 50)\n)\n\n## R code 4.28 ######################\nm4.1 <- rethinking::quap(flist, data = d2_a)\n\n## R code 4.29 ######################\nrethinking::precis(m4.1)\n```\n````\n\n```\n#>             mean        sd       5.5%     94.5%\n#> mu    154.607022 0.4119945 153.948575 155.26547\n#> sigma   7.731329 0.2913857   7.265638   8.19702\n```\n:::\n\n\n> These numbers provide Gaussian approximations for each parameter's\n> *marginal* distribution. This means the plausibility of each value of\n> `_μ_`, after averaging over the plausibilities of each value of `_σ_`,\n> is given by a Gaussian distribution with mean 154.6 and standard\n> deviation 0.4.\n>\n> The 5.5% and 94.5% quantiles are percentile interval boundaries,\n> corresponding to an 89% compatibility interval. Why 89%? It's just the\n> default. It displays a quite wide interval, so it shows a\n> high-probability range of parameter values. If you want another\n> interval, such as the conventional and mindless 95%, you can use\n> `precis(m4.1, prob=0.95)`. But I don't recommend 95% intervals,\n> because readers will have a hard time not viewing them as significance\n> tests. 89 is also a prime number, so if someone asks you to justify\n> it, you can stare at them meaningfully and incant, \"Because it is\n> prime.\" That's no worse justification than the conventional\n> justification for 95%.\n\nI encourage you to compare these 89% boundaries to the compatibility\nintervals from the grid approximation in @lst-post-comp-intervals-a\nearlier. You'll find that they are almost identical. When the posterior\nis approximately Gaussian, then this is what you should expect.\n\n##### Start values for `rethinking::quap()` {#sec-start-values-rethinking}\n\nMean and standard deviation are good values to start values for hill\nclimbing. If you don't specify `rethinking::quap()` will use a random\nvalue.\n\n\n::: {.cell}\n\n````{.cell-code #start-values-quap lst-cap=\"Define start values for rethinking::quap()\"}\n```{{r}}\n#| label: start-values-quap\n#| attr-source: '#start-values-quap lst-cap=\"Define start values for rethinking::quap()\"'\n\n## R code 4.30 ######################\nstart <- list(\n  mu = mean(d2_a$height),\n  sigma = sd(d2_a$height)\n)\nm4.1_2 <- rethinking::quap(flist, data = d2_a, start = start)\nrethinking::precis(m4.1_2)\n```\n````\n\n```\n#>             mean        sd       5.5%      94.5%\n#> mu    154.607024 0.4119947 153.948576 155.265471\n#> sigma   7.731333 0.2913860   7.265642   8.197024\n```\n:::\n\n\n::: callout-note\n###### list() and alist()\n\nNote that the list of start values is a regular `list`, not an `alist`\nlike the formula list is. The two functions `alist` and `list` do the\nsame basic thing: allow you to make a collection of arbitrary R objects.\nThey differ in one important respect: `list` evaluates the code you\nembed inside it, while `alist` does not. So when you define a list of\nformulas, you should use `alist`, so the code isn't executed. But when\nyou define a list of start values for parameters, you should use `list`,\nso that code like `mean(d2_a$height)` will be evaluated to a numeric\nvalue.\n:::\n\n**Slicing in more information**\n\n> The priors we used before are very weak, both because they are nearly\n> flat and because there is so much data. So I'll splice in a more\n> informative prior for `*μ*`, so you can see the effect. All I'm going\n> to do is change the standard deviation of the prior to 0.1, so it's a\n> very narrow prior. I'll also build the formula right into the call to\n> `quap` this time.\n\n\n::: {.cell}\n\n````{.cell-code #lst-post-dist-quap-m4.2 lst-cap=\"Finding the posterior distribution with a narrower prior rethinking::quap()\"}\n```{{r}}\n#| label: post-dist-quap-m4.2\n#| attr-source: '#lst-post-dist-quap-m4.2 lst-cap=\"Finding the posterior distribution with a narrower prior rethinking::quap()\"'\n\n## R code 4.31 ###########################\nm4.2 <- rethinking::quap(\n  alist(\n    height ~ dnorm(mu, sigma),\n    mu ~ dnorm(178, 0.1),\n    sigma ~ dunif(0, 50)\n  ),\n  data = d2_a\n)\nrethinking::precis(m4.2)\n```\n````\n\n```\n#>            mean        sd      5.5%     94.5%\n#> mu    177.86375 0.1002354 177.70356 178.02395\n#> sigma  24.51757 0.9289236  23.03297  26.00216\n```\n:::\n\n\n> Notice that the estimate for `*μ*` has hardly moved off the prior. The\n> prior was very concentrated around 178. So this is not surprising. But\n> also notice that the estimate for `*σ*` has changed quite a lot, even\n> though we didn't change its prior at all. Once the golem is certain\n> that the mean is near 178---as the prior insists---then the golem has\n> to estimate `*σ*` conditional on that fact. This results in a\n> different posterior for `*σ*`, even though all we changed is prior\n> information about the other parameter.\n\n::: callout-caution\n###### `μ` has hardly moved off the prior\n\nAt first I did not understand \"that the estimate for `*μ*` has hardly\nmoved off the prior\". I thought this assertion refers to the value of\n`*μ*` in both calculation. *μ* has changed considerably from 154.61 to\n177.86 and under that assumption the above quote does not make sense.\n\nBut in contrast to my wrong assumption the assertion refers to the\ndifference between the chosen prior (178) and the resulting value of\n`*μ*` (177.86).\n:::\n\n#### Tidyverse\n\n> In the text, McElreath indexed his models with names like `m4.1`. I\n> will largely follow that convention, but will replace the *m* with a\n> *b* to stand for the **`brms`** package.\n\nHere's how to fit the first model for this chapter.\n\n\n::: {.cell att-source='#lst-post-dist-brms-b4.1 lst-cap=\"Finding the posterior distribution with brms::brm()\"'}\n\n````{.cell-code}\n```{{r}}\n#| label: post-dist-brms-b4.1\n#| att-source: '#lst-post-dist-brms-b4.1 lst-cap=\"Finding the posterior distribution with brms::brm()\"'\n\nb4.1 <- \n  brms::brm(data = d2_b, \n      family = gaussian,\n      height ~ 1,\n      prior = c(brms::prior(normal(178, 20), class = Intercept),\n                brms::prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4,\n      file = \"fits/b04.01\")\n\nbrms:::plot.brmsfit(b4.1)\n```\n````\n\n::: {.cell-output-display}\n![](04-geocentric-models_files/figure-html/post-dist-brms-b4.1-1.png){width=672}\n:::\n:::\n\n\nIf you want detailed diagnostics for the HMC chains, call\n`brms::launch_shinystan(b4.1)`. That'll keep you busy for a while. See\nthe [ShinyStan website](https://mc-stan.org/users/interfaces/shinystan)\nfor more information.\n\n::: callout-caution\n###### Launch of shinystan turned off\n\nI turned off the evaluation of the following chunk. It took some time\nand the it referred to a local page `http://127.0.0.1:6367/`\\`where I\ncould inspect many details of the model. But this is at the moment too\ncomplex to me: I do not understand all the parameters and the many\nconfigurable options programmed with a {**shiny**) interface.\n:::\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: detailled-diganostic-chains-brms-b4.1\n#| eval: false\n\nbrms::launch_shinystan(b4.1)\n\n```\n````\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: print-summary-brms-b4.1\n\nbrms:::print.brmsfit(b4.1)\n```\n````\n\n```\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 \n#>    Data: d2_b (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   154.60      0.41   153.81   155.42 1.00     2763     2635\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     7.77      0.29     7.21     8.39 1.00     3400     2561\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: print-stan-like-summary-brms-b4.1\n\nb4.1$fit\n```\n````\n\n```\n#> Inference for Stan model: anon_model.\n#> 4 chains, each with iter=2000; warmup=1000; thin=1; \n#> post-warmup draws per chain=1000, total post-warmup draws=4000.\n#> \n#>                 mean se_mean   sd     2.5%      25%      50%      75%    97.5%\n#> b_Intercept   154.60    0.01 0.41   153.81   154.31   154.59   154.88   155.42\n#> sigma           7.77    0.01 0.29     7.21     7.57     7.76     7.97     8.39\n#> lprior         -8.51    0.00 0.02    -8.56    -8.53    -8.51    -8.50    -8.46\n#> lp__        -1227.04    0.02 0.97 -1229.63 -1227.44 -1226.75 -1226.33 -1226.06\n#>             n_eff Rhat\n#> b_Intercept  2778    1\n#> sigma        3404    1\n#> lprior       2773    1\n#> lp__         1798    1\n#> \n#> Samples were drawn using NUTS(diag_e) at Sat Aug  5 13:01:11 2023.\n#> For each parameter, n_eff is a crude measure of effective sample size,\n#> and Rhat is the potential scale reduction factor on split chains (at \n#> convergence, Rhat=1).\n```\n:::\n\n\nWhereas rethinking defaults to 89% intervals, using `print()` or\n`summary()` with {**brms**} models defaults to 95% intervals.\n\n::: callout-note\nAs I have learned shortly: `print()` or `summary()` are generic\nfunctions where one can add new printing methods with new classes. In\nthis case `class(b4.1)` = brmsfit. This means I do not need to\nadd `brms::` to secure that I will get the {**brms**} printing or\nsummary method as I didn't load the {**brms**} package. Quite the\ncontrary: Adding `brms::` would result into the message: \"Error:\n'summary' is not an exported object from 'namespace:brms'\".\n\nAs I really want to specify explicitly the method these generic\nfunctions should use, I need to use the syntax `brms:::print.brmsfit()`\nor `brms:::summary.brmsfit()` respectively.\n\nIn this respect I have to learn more about S3 classes. There are many\nimportant web resources about this subject that I have found with the\nsearch string \"r what is s3 class\". Maybe I should start with the [S3\nchapter in Advanced R](https://adv-r.hadley.nz/s3.html).\n:::\n\nUnless otherwise specified, Kurz will stick with 95% intervals\nthroughout. To get those 89% intervals or McElreath approach, one could\nuse the `prob` argument within `summary()` or `print()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: summary-interval-.89-brms-b4.1\n\nbrms:::summary.brmsfit(b4.1, prob = .89)\n```\n````\n\n```\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 \n#>    Data: d2_b (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   154.60      0.41   153.94   155.25 1.00     2763     2635\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     7.77      0.29     7.33     8.26 1.00     3400     2561\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nHere's the `brms::brm()` code for the model with the very narrow `_μ_`\nprior corresponding to the `rethinking::quap()` code in\n@lst-post-dist-quap-m4.2.\n\n\n::: {.cell att-source='#lst-post-dist-brms-b4.2 lst-cap=\"Finding the posterior distribution with a narrower prior using brms::brm()\"'}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-post-dist-brms-b4.2\n#| fig-cap: \"Finding the posterior distribution with a narrower prior using brms::brm()\"\n#| att-source: '#lst-post-dist-brms-b4.2 lst-cap=\"Finding the posterior distribution with a narrower prior using brms::brm()\"'\n\nb4.2 <- \n  brms::brm(data = d2_b, \n      family = gaussian,\n      height ~ 1,\n      prior = c(brms::prior(normal(178, 0.1), class = Intercept),\n                brms::prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4,\n      file = \"fits/b04.02\")\n\nbrms:::plot.brmsfit(b4.2, widths = c(1, 2))\n```\n````\n\n::: {.cell-output-display}\n![Finding the posterior distribution with a narrower prior using brms::brm()](04-geocentric-models_files/figure-html/fig-post-dist-brms-b4.2-1.png){#fig-post-dist-brms-b4.2 width=672}\n:::\n:::\n\n\nAnd here's the model `summary()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: summary-narrow-prior\n\nbrms:::summary.brmsfit(b4.2)\n```\n````\n\n```\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 \n#>    Data: d2_b (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   177.86      0.11   177.66   178.07 1.00     2721     2586\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma    24.60      0.91    22.87    26.47 1.00     3400     2729\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nSubsetting the `summary()` output with `$fixed` provides a convenient\nway to compare the Intercept summaries between `b4.1` and `b4.2`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: compare-summaries-b4.1-b4.2\n\nrbind(brms:::summary.brmsfit(b4.1)$fixed,\n      brms:::summary.brmsfit(b4.2)$fixed)\n```\n````\n\n```\n#>            Estimate Est.Error l-95% CI u-95% CI     Rhat Bulk_ESS Tail_ESS\n#> Intercept  154.5959 0.4144632 153.8123 155.4221 1.000708 2762.982 2635.159\n#> Intercept1 177.8647 0.1052528 177.6577 178.0705 1.001224 2720.796 2586.491\n```\n:::\n\n\n### Sampling from a quap\n\n#### Original\n\nThe above explains how to get a quadratic approximation of the\nposterior, using `rethinking::quap()`. But how do we then get samples\nfrom the quadratic approximate posterior distribution? --- When R\nconstructs a quadratic approximation, it calculates not only standard\ndeviations for all parameters, but also the covariances among all pairs\nof parameters. Just like a mean and standard deviation (or its square, a\nvariance) are sufficient to describe a one-dimensional Gaussian\ndistribution, a list of means and a matrix of variances and covariances\nare sufficient to describe a multi-dimensional Gaussian distribution.\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-var-cov-m4.1-a lst-cap=\"Calculation of the variance-covariance matrix: rethinking version\"}\n```{{r}}\n#| label: calc-var-cov-m4.1-a\n#| attr-source: '#lst-calc-var-cov-m4.1-a lst-cap=\"Calculation of the variance-covariance matrix: rethinking version\"'\n\n## R code 4.32 ###################\nrethinking::vcov(m4.1)\n```\n````\n\n```\n#>                 mu        sigma\n#> mu    0.1697394338 0.0002179886\n#> sigma 0.0002179886 0.0849055981\n```\n:::\n\n\n`vcov()` returns the variance-covariance matrix of the main parameters\nof a fitted model object. In the above {**rethinking**} version is uses\nthe class `map2stan` for a fitted Stan model as `m4.1` is of class\n`map`.\n\n::: callout-caution\n###### rethinking::vcov\n\nIn @lst-calc-var-cov-m4.1-a I am explicitly using the package\n{**rethinking**} for the `vcov()` function. The same function is also\navailable as a base R function with `stats::vcov()`. But this generates\nan error because there is no method known for an object of class `map`\nfrom the rethinking package. The help file for `stats::vcov()` only says\nthat the `vcov` object is an S3 method for classes `lm`, `glm`, `mlm`\nand `aov` but not for `map`.\n\n> Error in UseMethod(\"vcov\") : no applicable method for 'vcov' applied\n> to an object of class \"map\"\n\nI could have used only `vcov()`. But this only works when the\n{**rethinking**} package is already loaded. In that case R knows because\nof the class of the object which `vcov()` version to use. In this case:\nclass of object = `class(m4.1)` map.\n:::\n\n@lst-calc-var-cov-m4.1-a results in a variance-covariance matrix. It is\nthe multi-dimensional glue of a quadratic approximation, because it\ntells us how each parameter relates to every other parameter in the\nposterior distribution. A variance-covariance matrix can be factored\ninto two elements: (1) a vector of variances for the parameters and (2)\na correlation matrix that tells us how changes in any parameter lead to\ncorrelated changes in the others.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: vcov-decomp-m4.1-a\n\n## R code 4.33 #######################\nbase::diag(rethinking::vcov(m4.1))      # <1>\nstats::cov2cor(rethinking::vcov(m4.1))  # <2>\n```\n````\n\n```\n#>        mu     sigma \n#> 0.1697394 0.0849056 \n#>                mu       sigma\n#> mu    1.000000000 0.001815826\n#> sigma 0.001815826 1.000000000\n```\n:::\n\n\n1.  `base::diag()` extracts the diagonal of the (variance-covariance)\n    matrix. The two-element vector in the output is the list of\n    variances. If you take the square root of this vector, you get the\n    standard deviations that are shown in `rethinking::precis()` output.\n2.  `stats::cov2cor()` scales a covariance matrix into the corresponding\n    correlation matrix. The two-by-two matrix in the output is this\n    correlation matrix. Each entry shows the correlation, bounded\n    between −1 and +1, for each pair of parameters. The 1's indicate a\n    parameter's correlation with itself. If these values were anything\n    except 1, we would be worried. The other entries are typically\n    closer to zero, and they are very close to zero in this example.\n    This indicates that learning μ tells us nothing about σ and likewise\n    that learning σ tells us nothing about μ. This is typical of simple\n    Gaussian models of this kind. But it is quite rare more generally,\n    as you'll see in later chapters.\n\nOkay, so how do we get samples from this multi-dimensional posterior?\nNow instead of sampling single values from a simple Gaussian\ndistribution, we sample vectors of values from a multi-dimensional\nGaussian distribution.\n\n\n::: {.cell}\n\n````{.cell-code #lst-extract-samples-m4.1-a lst-cap=\"Extract sample vectors of values from the multi-dimensional Gaussian distribution of m4.1: rethinking version\"}\n```{{r}}\n#| label: extract-samples-m4.1-a\n#| attr-source: '#lst-extract-samples-m4.1-a lst-cap=\"Extract sample vectors of values from the multi-dimensional Gaussian distribution of m4.1: rethinking version\"'\n\n\n## R code 4.34 #######################\npost3_a <- rethinking::extract.samples(m4.1, n = 1e4)\nhead(post3_a)\n```\n````\n\n```\n#>         mu    sigma\n#> 1 154.1191 7.722540\n#> 2 154.9340 7.560591\n#> 3 154.8558 8.023537\n#> 4 153.5471 7.733505\n#> 5 154.6297 7.327114\n#> 6 154.6631 8.316943\n```\n:::\n\n\nYou end up with a data frame, post, with 10,000 (1e4) rows and two\ncolumns, one column for `_μ_` and one for `_σ_`. Each value is a sample\nfrom the posterior, so the mean and standard deviation of each column\nwill be very close to the MAP values from before. You can confirm this\nby summarizing the samples:\n\n\n::: {.cell}\n\n````{.cell-code #lst-summary-samples-m4.1-a lst-cap=\"Summary the extracted samples: rethinking version\"}\n```{{r}}\n#| label: summary-samples-m4.1-a\n#| attr-source: '#lst-summary-samples-m4.1-a lst-cap=\"Summary the extracted samples: rethinking version\"'\n\n## R code 4.35 ##################\nrethinking::precis(post3_a)\n```\n````\n\n```\n#>             mean        sd      5.5%     94.5%   histogram\n#> mu    154.606881 0.4077628 153.96082 155.26492     ▁▁▅▇▂▁▁\n#> sigma   7.731493 0.2884440   7.26373   8.19481 ▁▁▁▂▅▇▇▃▁▁▁\n```\n:::\n\n\nCompare these values to the output from @lst-post-dist-quap-m4-1-a. And\nyou can use `plot(post)` to see how much they resemble the samples from\nthe grid approximation in FIGURE 4.4 (here @fig-posterior-sample-a).\nThese samples also preserve the covariance between `_μ_` and `_σ_`. This\nhardly matters right now, because `_μ_` and `_σ_` don't co-vary at all\nin this model. But once you add a predictor variable to your model,\ncovariance will matter a lot.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-posterior-sample-vectors-a\n#| fig-cap: \"Samples from the vectors of values from a multi-dimensional Gaussian distribution. The density of points is highest in the center, reflecting the most plausible combinations of μ and σ. It is very similar to @fig-posterior-sample-a (rethinking version)\"\n\nbase::plot(post3_a)\n```\n````\n\n::: {.cell-output-display}\n![Samples from the vectors of values from a multi-dimensional Gaussian distribution. The density of points is highest in the center, reflecting the most plausible combinations of μ and σ. It is very similar to @fig-posterior-sample-a (rethinking version)](04-geocentric-models_files/figure-html/fig-posterior-sample-vectors-a-1.png){#fig-posterior-sample-vectors-a width=672}\n:::\n:::\n\n\n##### Under the hood with multivariate sampling {#sec-under-the-hood-multivariate-sampling}\n\nThe function `rethinking::extract.samples()` is for convenience. It is\njust running a simple simulation of the sort you conducted near the end\nof @sec-sampling-the-imaginary with @lst-sim-pred-samples-a. Here's a\npeak at the motor. The work is done by a multi-dimensional version of\n`stats::rnorm()`, `MASS::mvrnorm()`. The function `stats::rnorm()`\nsimulates random Gaussian values, while `MASS::mvrnorm()` simulates\nrandom vectors of multivariate Gaussian values. Here's how to use it the\n{**MASS**} function to do what `rethinking::extract.samples()` does:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-posterior-sample-vectors-MASS-a\n#| fig-cap: \"Extract samples from the vectors of values from a multi-dimensional Gaussian distribution using the {**MASS**} package. It is same calculation as in @fig-posterior-sample-a (rethinking version)\"\n\n\n## R code 4.36 ######################\npost4_a <- MASS::mvrnorm(n = 1e4, mu = rethinking::coef(m4.1), \n                      Sigma = rethinking::vcov(m4.1))\nplot(post4_a)\n```\n````\n\n::: {.cell-output-display}\n![Extract samples from the vectors of values from a multi-dimensional Gaussian distribution using the {**MASS**} package. It is same calculation as in @fig-posterior-sample-a (rethinking version)](04-geocentric-models_files/figure-html/fig-posterior-sample-vectors-MASS-a-1.png){#fig-posterior-sample-vectors-MASS-a width=672}\n:::\n:::\n\n\n#### Tidyverse\n\n{**brms**} doesn't seem to have a convenience function that works the\nway `vcov()` does for {**rethinking**}.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#|label: calc-var-cov-m4.1-b\n#|attr-source: '#lst-calc-var-cov-m4.1-b lst-cap=\"Calculation of vcov(): tidyverse version.\"'\n\nbrms:::vcov.brmsfit(b4.1)\n```\n````\n\n```\n#>           Intercept\n#> Intercept 0.1717797\n```\n:::\n\n\nThis only returns the first element in the matrix it did for\n{**rethinking**}. That is, it appears `brms::vcov()` only returns the\nvariance/covariance matrix for the single-level `_β_` parameters.\n\n::: callout-caution\n###### brms::vcov()\n\nReferring to a similar situation with `rethinking::vcov()` in\n@lst-calc-var-cov-m4.1-a I cannot write `brms::vcov()`, but have to use\neither `brms:::vcov.brmsfit(b4.1)` or just `vcov(b4.1)`. The weird thing\nis that the first time it also works with `brms::vcov()` but only the\nfirst time!\n:::\n\nHowever, if you really wanted this information, you could get it after\nputting the Hamilton Monte Carlo (HMC) chains in a data frame. We do\nthat with the `brms::as_draws_df()` function:\n\n\n::: {.cell}\n\n````{.cell-code #lst-put-hmc-into-df-b lst-cap=\"Extract the iteration of the Hamiliton Monte Carlo (HMC) chains into a data frame\"}\n```{{r}}\n#| label: put-hmc-into-df-b\n#| attr-source: '#lst-put-hmc-into-df-b lst-cap=\"Extract the iteration of the Hamiliton Monte Carlo (HMC) chains into a data frame\"'\n\npost_b <- brms::as_draws_df(b4.1)\n\nhead(post_b)\n```\n````\n\n```\n#> # A draws_df: 6 iterations, 1 chains, and 4 variables\n#>   b_Intercept sigma lprior  lp__\n#> 1         155   7.5   -8.5 -1227\n#> 2         155   7.0   -8.5 -1230\n#> 3         154   7.6   -8.5 -1226\n#> 4         154   8.0   -8.5 -1226\n#> 5         155   7.6   -8.5 -1226\n#> 6         155   7.4   -8.5 -1227\n#> # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n```\n:::\n\n\n::: callout-tip\n###### draws object\n\nThe functions of the family `as_draws()` transform `brmsfit` objects to\n`draws` objects, a format supported by the {**posterior**} package.\n{brms} currently imports the family of `as_draws()`functions from the\n{**posterior**} package, a tool for working with posterior\ndistributions.\n\n@lst-put-hmc-into-df-b produced the {**brms**} version of what McElreath\nachieved with `extract.samples()` in @lst-extract-samples-m4.1-a.\nHowever, what happened under the hood was different. Whereas rethinking\nused the `mvnorm()` function from the {**MASS**} package, with\n{**brms**} we just extracted the iterations of the HMC chains and put\nthem in a data frame.\n:::\n\nNow `select()` the columns containing the draws from the desired\nparameters `b_Intercept` and `sigma` and feed them into `cov()`.\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-cov-post-b lst-cap=\"Calculate the vector of variances and correlation matrix for b_Intercept and sigma\"}\n```{{r}}\n#| label: calc-cov-post-b\n#| attr-source: '#lst-calc-cov-post-b lst-cap=\"Calculate the vector of variances and correlation matrix for b_Intercept and sigma\"'\n\nselect(post_b, b_Intercept:sigma) %>% \n  stats::cov()\n```\n````\n\n```\n#> Warning: Dropping 'draws_df' class as required metadata was removed.\n#>               b_Intercept         sigma\n#> b_Intercept  0.1717797087 -0.0005450089\n#> sigma       -0.0005450089  0.0868161627\n```\n:::\n\n\n@lst-calc-cov-post-b displays \"(1) a vector of variances for the\nparameters and (2) a correlation matrix\" for them (p. 90). Here are just\nthe variances (i.e., the diagonal elements) and the correlation matrix.\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-var-post-b lst-cap=\"Calculate only variances (the diagonal values)\"}\n```{{r}}\n#| label: calc-var-post-b\n#| attr-source: '#lst-calc-var-post-b lst-cap=\"Calculate only variances (the diagonal values)\"'\n\nselect(post_b, b_Intercept:sigma) %>%\n  stats::cov() %>%\n  base::diag()\n```\n````\n\n```\n#> Warning: Dropping 'draws_df' class as required metadata was removed.\n#> b_Intercept       sigma \n#>  0.17177971  0.08681616\n```\n:::\n\n::: {.cell}\n\n````{.cell-code #lst-calc-corr-matrix-post-b lst-cap=\"Calculate only crrelation\"}\n```{{r}}\n#| label: calc-corr-matrix-post-b\n#| attr-source: '#lst-calc-corr-matrix-post-b lst-cap=\"Calculate only crrelation\"'\n\n# correlation\npost_b %>%\n  select(b_Intercept, sigma) %>%\n  stats::cor()\n```\n````\n\n```\n#> Warning: Dropping 'draws_df' class as required metadata was removed.\n#>              b_Intercept        sigma\n#> b_Intercept  1.000000000 -0.004462902\n#> sigma       -0.004462902  1.000000000\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: show-data-structure\n\nstr(post_b)\n```\n````\n\n```\n#> draws_df [4,000 × 7] (S3: draws_df/draws/tbl_df/tbl/data.frame)\n#>  $ b_Intercept: num [1:4000] 155 155 154 154 155 ...\n#>  $ sigma      : num [1:4000] 7.55 7.02 7.58 7.95 7.63 ...\n#>  $ lprior     : num [1:4000] -8.49 -8.49 -8.52 -8.52 -8.52 ...\n#>  $ lp__       : num [1:4000] -1227 -1230 -1226 -1226 -1226 ...\n#>  $ .chain     : int [1:4000] 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ .iteration : int [1:4000] 1 2 3 4 5 6 7 8 9 10 ...\n#>  $ .draw      : int [1:4000] 1 2 3 4 5 6 7 8 9 10 ...\n```\n:::\n\n\nThe `post_b` object is not just a data frame, but also of class\n`draws_df`, which means it contains three metadata variables ----\n`.chain`, `.iteration`, and `.draw` --- which are often hidden from\nview, but are there in the background when needed. As you'll see, we'll\nmake good use of the `.draw` variable in the future. Notice how our post\ndata frame also includes a vector named `lp__`. That's the log\nposterior.\n\nFor details, see: - The [Log-Posterior (function and\ngradient)](https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html#the-log-posterior-function-and-gradient)\nsection of the Stan Development Team's (2023) vignette [RStan: the R\ninterface to\nStan](https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html)\nand - Stephen Martin's [explanation of the log\nposterior](https://discourse.mc-stan.org/t/basic-question-what-is-lp-in-posterior-samples-of-a-brms-regression/17567/2)\non the Stan Forums.\n\n::: callout-caution\n###### Summaries of {brms} and {posterior} packages\n\nKurz claims that `summary()` function doesn't work for {**brms**}\nposterior data frames quite the way `rethinking::precis()` does for\nposterior data frames from the {\\*\\*rethinking\\*} package. But I this\nobservation is somewhat misleading.\n\nThe posterior data frame `post_b` is not of class `brms`. Let's check\nthis:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: class-post_b-b\n\nclass(post_b)\n```\n````\n\n```\n#> [1] \"draws_df\"   \"draws\"      \"tbl_df\"     \"tbl\"        \"data.frame\"\n```\n:::\n\n\nThe class `draws_df`and `draws` refers to the {**posterior**} and not to\nthe {**brms**} package. Remember: In @lst-put-hmc-into-df-b we\ntransformed with the function `as_draws_df` the `brms` object into a\n`draws_df` and `draws` object.\n\nTherefore Kurz's claim should be read: The `summary()` function doesn't\nwork for {**posterior**} posterior data frames quite the way\n`rethinking::precis()` does for posterior data frames from the\n{**rethinking**} package. Instead of calling `brms:::summary.brmsfit()`\nI will use `posterior:::summary.draws()`.\n\nI wouldn't have noticed this difference if I hadn't mentioned explicitly\nthe name of the packages in front of the function, because in that case\nR would have used `base::summary()` as in Kurz's text.\n:::\n\n\n::: {.cell}\n\n````{.cell-code #lst-base-summary-samples-b4.1-b lst-cap=\"Summary the extracted iterations of the HMC chains: base version\"}\n```{{r}}\n#| label: base-summary-samples-b4.1-b\n#| attr-source: '#lst-base-summary-samples-b4.1-b lst-cap=\"Summary the extracted iterations of the HMC chains: base version\"'\n\nbase::summary(post_b[, 1:2])\n```\n````\n\n```\n#> Warning: Dropping 'draws_df' class as required metadata was removed.\n#>   b_Intercept        sigma      \n#>  Min.   :153.3   Min.   :6.841  \n#>  1st Qu.:154.3   1st Qu.:7.567  \n#>  Median :154.6   Median :7.757  \n#>  Mean   :154.6   Mean   :7.771  \n#>  3rd Qu.:154.9   3rd Qu.:7.971  \n#>  Max.   :156.2   Max.   :8.864\n```\n:::\n\n::: {.cell}\n\n````{.cell-code #lst-posterior-summary-samples-b4.1-b lst-cap=\"Summary the extracted iterations of the HMC chains: posterior version\"}\n```{{r}}\n#| label: posterior-summary-samples-b4.1-b\n#| attr-source: '#lst-posterior-summary-samples-b4.1-b lst-cap=\"Summary the extracted iterations of the HMC chains: posterior version\"'\n\nposterior:::summary.draws(post_b[, 1:2])\n```\n````\n\n```\n#> Warning: Dropping 'draws_df' class as required metadata was removed.\n#> # A tibble: 2 × 10\n#>   variable      mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>        <num>  <num> <num> <num>  <num>  <num> <num>    <num>    <num>\n#> 1 b_Intercept 155.   155.   0.414 0.421 154.   155.    1.00    2722.    2624.\n#> 2 sigma         7.77   7.76 0.295 0.301   7.31   8.27  1.00    3369.    2537.\n```\n:::\n\n\nTo get a similar summary with tiny histograms Kurz offers different\nsolutions:\n\n-   A base R approach by using the transpose of a `stats::quantile()`\n    call nested within `base::apply()`\n-   A {**tidyverse**} approach\n-   A {**brms**} approach by just putting the `brm()` fit object into\n    `posterior_summary()`\n-   A {**tidybayes**} approach using `tidybayes::mean_hdi()` if you're\n    willing to drop the posterior `sd` and\n-   Using additionally the [function\n    `histospark()`](https://github.com/hadley/precis/blob/master/R/histospark.R)\n    (from the unfinished {**precis**} package by Hadley Wickham supposed\n    to replace `base::summary()`) to get the tiny histograms and to add\n    them into the tidyverse approach.\n\nAdditionally I will propose using the {**skimr**} packages:\n\n\n::: {.cell}\n\n````{.cell-code #lst-skim-summary-samples-b4.1-b lst-cap=\"Summary the extracted iterations of the HMC chains: skimr version\"}\n```{{r}}\n#| label: skim-summary-samples-b4.1-b\n#| attr-source: '#lst-skim-summary-samples-b4.1-b lst-cap=\"Summary the extracted iterations of the HMC chains: skimr version\"'\n\nskimr::skim(post_b[, 1:2])\n```\n````\n\n```\n#> Warning: Dropping 'draws_df' class as required metadata was removed.\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |              |\n|:------------------------|:-------------|\n|Name                     |post_b[, 1:2] |\n|Number of rows           |4000          |\n|Number of columns        |2             |\n|_______________________  |              |\n|Column type frequency:   |              |\n|numeric                  |2             |\n|________________________ |              |\n|Group variables          |None          |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|   sd|     p0|    p25|    p50|    p75|   p100|hist  |\n|:-------------|---------:|-------------:|------:|----:|------:|------:|------:|------:|------:|:-----|\n|b_Intercept   |         0|             1| 154.60| 0.41| 153.29| 154.31| 154.59| 154.88| 156.22|▁▆▇▂▁ |\n|sigma         |         0|             1|   7.77| 0.29|   6.84|   7.57|   7.76|   7.97|   8.86|▁▆▇▂▁ |\n:::\n:::\n\n\nKurz refers only shortly to both `overthinking` blocks of this section:\n\n-   Start values for `rethinking::quap()` resp. `brms::brm()` (See\n    @sec-start-values-rethinking): Within the `brm()` function, you use\n    the `init` argument fpr the start values.\n-   Under the hood with multivariate sampling (See\n    @sec-under-the-hood-multivariate-sampling): Again Kurz remarked that\n    `brms::as_draws_df()` is not the same as\n    `rethinking::extract.samples()`. What this exactly means will\n    (hopefully) explained later in @sec-markov-chain-monte-carlo.\n\n## Linear prediction\n\n### Introduction\n\n#### Original\n\nWhat we've done until now is just a Gaussian model of height in a\npopulation of adults. But typically, we are interested in modeling how\nan outcome is related to some other variable, a predictor variable. If\nthe predictor variable has any statistical association with the outcome\nvariable, then we can use it to predict the outcome. When the predictor\nvariable is built inside the model in a particular way, we'll have\nlinear regression.\n\nLet's look at how height in these Kalahari foragers (the outcome\nvariable) co-varies with weight (the predictor variable).\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-height-against-weight-a\n#| fig-cap: \"Adult height and weight against one another\"\n\n## R code 4.37 #####################\nplot(d2_a$height ~ d2_a$weight)\n```\n````\n\n::: {.cell-output-display}\n![Adult height and weight against one another](04-geocentric-models_files/figure-html/fig-height-against-weight-a-1.png){#fig-height-against-weight-a width=672}\n:::\n:::\n\n\nThere's obviously a relationship: Knowing a person's weight helps you\npredict height. To make this vague observation into a more precise\nquantitative model that relates values of `weight` to plausible values\nof `height`, we need some more technology. How do we take our Gaussian\nmodel from @sec-gaussian-model-of-height and incorporate predictor\nvariables?\n\n#### Tidyverse\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-height-against-weight-b\n#| fig-cap: \"Adult height and weight against one another\"\n\n\nd2_b |> \n    ggplot(aes(height, weight)) + \n    geom_point()\n```\n````\n\n::: {.cell-output-display}\n![Adult height and weight against one another](04-geocentric-models_files/figure-html/fig-height-against-weight-b-1.png){#fig-height-against-weight-b width=672}\n:::\n:::\n\n\n### The linear model strategy\n\n#### Original\n\n##### Model definition\n\nRecall @def-prior-height-model for the Gaussian height model. How do we\nget `weight` into this model? Let `_x_` be the name for the column of\nweight measurements, `d2_a$weight`. Let the average of the `_x_` values\nbe $\\overline{x}$, \"ex bar\". Now we have a predictor variable `_x_`,\nwhich is a list of measures of the same length as `_h_`. To get weight\ninto the model, we define the mean `_μ_` as a function of the values in\n`_x_`.\n\n------------------------------------------------------------------------\n\n::: {#def-height-weight-linear-model}\nLinear model height against weight\n\n$$\n\\begin{align*}\nh_{i} \\sim \\operatorname{Normal}(μ_{i}, σ) \\space \\space (1) \\\\ \nμ_{i} = \\alpha + \\beta(x_{i}-\\overline{x}) \\space \\space (2) \\\\\n\\alpha \\sim \\operatorname{Normal}(178, 20) \\space \\space (3)  \\\\ \n\\beta \\sim \\operatorname{Normal}(0,10) \\space \\space (4) \\\\\n\\sigma \\sim \\operatorname{Uniform}(0, 50) \\space \\space (5)      \n\\end{align*}\n$$ {#eq-height-weight-linear-model}\n\n(1) **Likelihood (Probability of the data)**: The first line is nearly\n    identical to before, except now there is a little index $i$ on the\n    $μ$ as well as the $h$. You can read $h_{i}$ as \"each height\" and\n    $\\mu_{i}$ as \"each $μ$\" The mean $μ$ now depends upon unique values\n    on each row $i$. So the little $i$ on $\\mu_{i}$ indicates that *the\n    mean depends upon the row*.\n\n(2) **Linear model**: The mean $μ$ is no longer a parameter to be\n    estimated. Rather, as seen in the second line of the model, $\\mu{i}$\n    is constructed from other parameters, $\\alpha$ and $\\beta$, and the\n    observed variable $x$. This line is not a stochastic relationship\n    ----- there is no `~` in it, but rather an `=` in it ----- because\n    the definition of $\\mu{i}$ is deterministic. That is to say that,\n    once we know $\\alpha$ and $\\beta$ and $x_{i}$, we know $\\mu{i}$ with\n    certainty. (More details in @sec-linear-model-a.)\n\n(3) **includes (3),(4) and(5) with** $\\alpha, \\beta, \\sigma$ priors: The\n    remaining lines in the model define distributions for the unobserved\n    variables. These variables are commonly known as parameters, and\n    their distributions as priors. There are three parameters:\n    $\\alpha, \\beta, \\sigma$. You've seen priors for $\\alpha$ and $\\beta$\n    before, although $\\sigma$ was called $\\mu$ back then. (More details\n    in @sec-priors-a)\n:::\n\n------------------------------------------------------------------------\n\n##### Linear model {#sec-linear-model-a}\n\nThe value $x_{i}$ in the second line of @def-height-weight-linear-model\nis just the weight value on row $i$. It refers to the same individual as\nthe height value, $h_{i}$, on the same row. The parameters $\\alpha$ and\n$\\beta$ are more mysterious. Where did they come from? We made them up.\nThe parameters $\\mu$ and $\\sigma$ are necessary and sufficient to\ndescribe a Gaussian distribution. But $\\alpha$ and $\\beta$ are instead\ndevices we invent for manipulating $\\mu$, allowing it to vary\nsystematically across cases in the data.\n\nYou'll be making up all manner of parameters as your skills improve. One\nway to understand these made-up parameters is to think of them as\ntargets of learning. Each parameter is something that must be described\nin the posterior distribution. So when you want to know something about\nthe data, you ask your golem by inventing a parameter for it. This will\nmake more and more sense as you progress.\n\nWhat does the second line of @def-height-weight-linear-model? It tells\nthe regression golem that you are asking two questions about the mean of\nthe outcome.\n\n1.  What is the expected height when $x_{i} = \\overline{x}$? The\n    parameter $\\alpha$ answers this question, because when\n    $x_{i} = \\overline{x}$, $\\mu_{i} = \\alpha$. For this reason,\n    $\\alpha$ is often called the **intercept**. But we should think not\n    in terms of some abstract line, but rather in terms of the meaning\n    with respect to the observable variables.\n2.  What is the change in expected height, when $x_{i}$ changes by 1\n    unit? The parameter $\\beta$ answers this question. It is often\n    called a **slope**, again because of the abstract line. Better to\n    think of it as a rate of change in expectation.\n\nJointly these two parameters ask the golem to find a line that relates\n$x$ to $h$, a line that passes through $\\alpha$ when\n$x_{i} = \\overline{x}$ and has slope $\\beta$. That is a task that golems\nare very good at. It's up to you, though, to be sure it's a good\nquestion.\n\n##### Priors {#sec-priors-a}\n\nThe prior for $\\beta$ in @def-height-weight-linear-model deserves\nexplanation. Why have a Gaussian prior with mean zero? This prior places\njust as much probability below zero as it does above zero, and when\n$\\beta = 0$, weight has no relationship to height. To figure out what\nthis prior implies, we have to simulate the prior predictive\ndistribution.\n\nThe goal is to simulate heights from the model, using only the priors.\nFirst, let's consider a range of weight values to simulate over. The\nrange of observed weights will do fine. Then we need to simulate a bunch\nof lines, the lines implied by the priors for $\\alpha$ and $\\beta$.\nHere's how to do it, setting a seed so you can reproduce it exactly:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-sim-heights-only-with-priors-a\n#| fig-cap: \"Simulating heights from the model, using only the priors: rethinking version\"\n\n## R code 4.38 #####################\nset.seed(2971)\nN_100_a <- 100 # 100 lines\na <- rnorm(N_100_a, 178, 20)\nb <- rnorm(N_100_a, 0, 10)\n\n\n## R code 4.39 #####################\nplot(NULL,\n  xlim = range(d2_a$weight), ylim = c(-100, 400),\n  xlab = \"weight\", ylab = \"height\"\n)\nabline(h = 0, lty = 2)\nabline(h = 272, lty = 1, lwd = 0.5)\nmtext(\"b ~ dnorm(0,10)\")\nxbar <- mean(d2_a$weight)\nfor (i in 1:N_100_a) {\n  curve(a[i] + b[i] * (x - xbar),\n    from = min(d2_a$weight), to = max(d2_a$weight), add = TRUE,\n    col = rethinking::col.alpha(\"black\", 0.2)\n  )\n}\n```\n````\n\n::: {.cell-output-display}\n![Simulating heights from the model, using only the priors: rethinking version](04-geocentric-models_files/figure-html/fig-sim-heights-only-with-priors-a-1.png){#fig-sim-heights-only-with-priors-a width=672}\n:::\n:::\n\n\nFor reference, I've added a dashed line at zero---no one is shorter than\nzero---and the \"Wadlow\" line at 272 cm for the world's tallest person.\nThe pattern doesn't look like any human population at all. It\nessentially says that the relationship between weight and height could\nbe absurdly positive or negative. Before we've even seen the data, this\nis a bad model. Can we do better?\n\nWe can do better immediately. We know that average height increases with\naverage weight, at least up to a point. Let's try restricting it to\npositive values. The easiest way to do this is to define the prior as\nLog-Normal instead. Defining $\\beta$ as `Log-Normal(0,1)` means to claim\nthat the logarithm of $\\beta$ has a Normal(0,1) distribution.\n\n------------------------------------------------------------------------\n\n::: {#def-prior-log-normal-dist}\nDefining the prior as Log-Normal distribution\n\n$$\n\\beta \\sim \\operatorname{Log-Normal}(0,1)\n$$ {#eq-prior-log-normal-dist}\n:::\n\n------------------------------------------------------------------------\n\nBase R provides the `dlnorm()` and `rlnorm()` densities for working with\nlog-normal distributions. You can simulate this relationship to see what\nthis means for $\\beta$:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-log-normal-a\n#| fig-cap: \"Log-Normal distribution: rethinking version\"\n\n\nset.seed(4) # to reproduce with tidyverse version\n\n## R code 4.40 ####################\nb <- rlnorm(1e4, 0, 1)\nrethinking::dens(b, xlim = c(0, 5), adj = 0.1)\n```\n````\n\n::: {.cell-output-display}\n![Log-Normal distribution: rethinking version](04-geocentric-models_files/figure-html/fig-log-normal-a-1.png){#fig-log-normal-a width=672}\n:::\n:::\n\n\nIf the logarithm of $\\beta$ is normal, then $\\beta$ itself is strictly\npositive. The reason is that `exp(x)` is greater than zero for any real\nnumber `x`. This is the reason that Log-Normal priors are commonplace.\nThey are an easy way to enforce positive relationships.\n\nSo what does this earn us? Do the prior predictive simulation again, now\nwith the Log-Normal prior:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-prior-pred-sim-a\n#| fig-cap: \"Prior predictive simulation again, now with the Log-Normal prior: rethinking version\"\n\n\n## R code 4.41 ###################\nset.seed(2971)\nN_100_a <- 100 # 100 lines\na <- rnorm(N_100_a, 178, 20)\nb <- rlnorm(N_100_a, 0, 1)\n\n## R code 4.39 ###################\nplot(NULL,\n  xlim = range(d2_a$weight), ylim = c(-100, 400),\n  xlab = \"weight\", ylab = \"height\"\n)\nabline(h = 0, lty = 2)\nabline(h = 272, lty = 1, lwd = 0.5)\nmtext(\"b ~ dnorm(0,10)\")\nxbar <- mean(d2_a$weight)\nfor (i in 1:N_100_a) {\n  curve(a[i] + b[i] * (x - xbar),\n    from = min(d2_a$weight), to = max(d2_a$weight), add = TRUE,\n    col = rethinking::col.alpha(\"black\", 0.2)\n  )\n}\n\n```\n````\n\n::: {.cell-output-display}\n![Prior predictive simulation again, now with the Log-Normal prior: rethinking version](04-geocentric-models_files/figure-html/fig-prior-pred-sim-a-1.png){#fig-prior-pred-sim-a width=672}\n:::\n:::\n\n\nThis is much more sensible. There is still a rare impossible\nrelationship. But nearly all lines in the joint prior for $\\alpha$ and\n$\\beta$ are now within human reason.\n\n::: callout-note\n###### What is the correct prior?\n\nThere is no more a uniquely correct prior than there is a uniquely\ncorrect likelihood. Statistical models are machines for inference. Many\nmachines will work, but some work better than others. Priors can be\nwrong, but only in the same sense that a kind of hammer can be wrong for\nbuilding a table.\n\nPriors encode states of information before seeing data. So priors allow\nus to explore the consequences of beginning with different information.\nIn cases in which we have good prior information that discounts the\nplausibility of some parameter values, like negative associations\nbetween height and weight, we can encode that information directly into\npriors. When we don't have such information, we still usually know\nenough about the plausible range of values. And you can vary the priors\nand repeat the analysis in order to study how different states of\ninitial information influence inference. Frequently, there are many\nreasonable choices for a prior, and all of them produce the same\ninference.\n:::\n\n::: callout-note\n###### Prior predictive simulation and p-hacking\n\nWhen the model is adjusted in light of the observed data, then p-values\nno longer retain their original meaning. False results are to be\nexpected. This is valid for Bayesian and Non-Bayesian statistics. Even\nif Bayesian statistics don't pay any attention to p-values, the danger\nremains. We could choose our priors conditional on the observed sample,\njust to get some desired (wrong) result. It is therefore important to\nchoose priors conditional on pre-data knowledge of the variables---their\nconstraints, ranges, and theoretical relationships. We should always\njudge our priors against general facts, not the sample.\n:::\n\n#### Tidyverse\n\n##### Model definition (empty)\n\nNothing to add. Remains empty.\n\n##### Linear model (empty)\n\nNothing to add. Remains empty.\n\n##### Priors {#sec-priors-b}\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-sim-heights-only-with-priors-b\n#| fig-cap: \"Simulating heights from the model, using only the priors: tidyverse version\"\n\nset.seed(2971)\n# how many lines would you like?\nn_lines <- 100\n\nlines <-\n  tibble(n = 1:n_lines,\n         a = rnorm(n_lines, mean = 178, sd = 20),\n         b = rnorm(n_lines, mean = 0, sd = 10)) %>% \n  expand_grid(weight = range(d2_b$weight)) %>% \n  mutate(height = a + b * (weight - mean(d2_b$weight)))\n\n\nlines %>% \n  ggplot(aes(x = weight, y = height, group = n)) +\n  geom_hline(yintercept = c(0, 272), linetype = 2:1, linewidth = 1/3) +\n  geom_line(alpha = 1/10) +\n  coord_cartesian(ylim = c(-100, 400)) +\n  ggtitle(\"b ~ dnorm(0, 10)\") +\n  theme_classic()\n```\n````\n\n::: {.cell-output-display}\n![Simulating heights from the model, using only the priors: tidyverse version](04-geocentric-models_files/figure-html/fig-sim-heights-only-with-priors-b-1.png){#fig-sim-heights-only-with-priors-b width=672}\n:::\n:::\n\n\nUsing the Log-Normal distribution prohibits negative values. This is an\nimportant constraint for height and weight as these variables cannot be\nunder 0.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-log-normal-b\n#| fig-cap: \"Log-Normal distribution: tidyverse version\"\n\nset.seed(4)\n\ntibble(b = rlnorm(1e4, meanlog = 0, sdlog = 1)) %>% \n  ggplot(aes(x = b)) +\n  geom_density(fill = \"grey92\") +\n  coord_cartesian(xlim = c(0, 5)) +\n  theme_classic()\n```\n````\n\n::: {.cell-output-display}\n![Log-Normal distribution: tidyverse version](04-geocentric-models_files/figure-html/fig-log-normal-b-1.png){#fig-log-normal-b width=672}\n:::\n:::\n\n\n::: callout-note\nKurz used with `mean`and `sd`an abbreviated version of the argument\nnames `meanlog` and `sdlog`.\n:::\n\nI am not very skilled with the Log-Normal distribution, and so I am\nhappy that Kurz added some explanations:\n\n> If you're unfamiliar with the log-normal distribution, it is the\n> distribution whose logarithm is normally distributed. For example,\n> here's what happens when we compare Normal(0,1) with\n> log(Log-Normal(0,1)).\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-normal-log-normal\n#| fig-cap: \"Compare Normal(0,1) with log(Log-Normal(0,1))\"\n\nset.seed(4)\n\ntibble(rnorm           = rnorm(1e5, mean = 0, sd = 1),\n       `log(rlognorm)` = log(rlnorm(1e5, meanlog = 0, sdlog = 1))) %>% \n  pivot_longer(everything()) %>% \n\n  ggplot(aes(x = value)) +\n  geom_density(fill = \"grey92\") +\n  coord_cartesian(xlim = c(-3, 3)) +\n  theme_classic() +\n  facet_wrap(~ name, nrow = 2)\n```\n````\n\n::: {.cell-output-display}\n![Compare Normal(0,1) with log(Log-Normal(0,1))](04-geocentric-models_files/figure-html/fig-normal-log-normal-1.png){#fig-normal-log-normal width=672}\n:::\n:::\n\n\n> Those values are ~~what~~ the mean and standard deviation of the\n> output from the `rlnorm()` function **after** they are log\n> transformed. The formulas for the actual mean and standard deviation\n> for the log-normal distribution itself are complicated (see\n> [Wikipedia](https://en.wikipedia.org/wiki/Log-normal_distribution)).\n\n------------------------------------------------------------------------\n\n::: {#def-mean-sd}\n$$\n\\begin{align*}\n\\text{mean}               & = \\exp \\left (\\mu + \\frac{\\sigma^2}{2} \\right) \\\\\n\\text{standard deviation} & = \\sqrt{[\\exp(\\sigma ^{2})-1] \\; \\exp(2\\mu +\\sigma ^{2})}\n\\end{align*}\n$$ {#eq-formula-mean-sd}\n:::\n\n------------------------------------------------------------------------\n\nsee: @eq-formula-mean-sd\n\nLet's try our hand at those formulas and compute the mean and standard\ndeviation for Log-Normal(0,1):\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: compute-mu-sigma-for-log-normal-manually-b\n\nmu    <- 0\nsigma <- 1\n\n# mean\nexp(mu + (sigma^2) / 2)\n\n# sd\nsqrt((exp(sigma^2) - 1) * exp(2 * mu + sigma^2))\n```\n````\n\n```\n#> [1] 1.648721\n#> [1] 2.161197\n```\n:::\n\n\nLet's confirm with simulated draws from `rlnorm()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: compute-log-normal-b\n#| fig-cap: \"Compute mean and standard deviation of the Log-Normal distribution: tidyverse version\"\n\nset.seed(4)\n\ntibble(x = rlnorm(1e7, meanlog = 0, sdlog = 1)) %>% \n  summarise(mean = mean(x),\n            sd   = sd(x))\n```\n````\n\n```\n#> # A tibble: 1 × 2\n#>    mean    sd\n#>   <dbl> <dbl>\n#> 1  1.65  2.17\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-prior-pred-sim-b\n#| fig-cap: \"Prior predictive simulation again, now with the Log-Normal prior: tidyverse version\"\n\n\n# make a tibble to annotate the plot\ntext <-\n  tibble(weight = c(34, 43),\n         height = c(0 - 25, 272 + 25),\n         label  = c(\"Embryo\", \"World's tallest person (272 cm)\"))\n\n# simulate\nset.seed(2971)\n\ntibble(n = 1:n_lines,\n       a = rnorm(n_lines, mean = 178, sd = 20),\n       b = rlnorm(n_lines, mean = 0, sd = 1)) %>% \n  expand_grid(weight = range(d2_b$weight)) %>% \n  mutate(height = a + b * (weight - mean(d2_b$weight))) %>%\n  \n  # plot\n  ggplot(aes(x = weight, y = height, group = n)) +\n  geom_hline(yintercept = c(0, 272), linetype = 2:1, linewidth = 1/3) +\n  geom_line(alpha = 1/10) +\n  geom_text(data = text,\n            aes(label = label),\n            size = 3) +\n  coord_cartesian(ylim = c(-100, 400)) +\n  ggtitle(\"log(b) ~ dnorm(0, 1)\") +\n  theme_classic()\n```\n````\n\n::: {.cell-output-display}\n![Prior predictive simulation again, now with the Log-Normal prior: tidyverse version](04-geocentric-models_files/figure-html/fig-prior-pred-sim-b-1.png){#fig-prior-pred-sim-b width=672}\n:::\n:::\n\n\n::: callout-tip\n###### Literature reference\n\nThe paper by Simmons, Nelson and Simonsohn (2011), [False-positive\npsychology: Undisclosed flexibility in data collection and analysis\nallows presenting anything as\nsignificant](https://journals.sagepub.com/doi/10.1177/0956797611417632),\nis often cited as an introduction to the problem.\n:::\n\n### Finding the posterior distribution\n\n#### Original\n\nThe code needed to approximate the posterior is a straightforward\nmodification of the kind of code you've already seen. All we have to do\nis incorporate our new model for the mean into the model specification\ninside `rethinking::quap()` and be sure to add a prior for the new\nparameter, `β`. Let's repeat the model definition, now with the\ncorresponding R code as footnotes:\n\n------------------------------------------------------------------------\n\n::: {#def-find-post-dist}\nFinding the posterior distribution\n\n$$\n\\begin{align*}\nh_{i} \\sim \\operatorname{Normal}(μ_{i}, σ) \\space \\space (1) \\\\ \nμ_{i} = \\alpha + \\beta(x_{i}-\\overline{x}) \\space \\space (2) \\\\\n\\alpha \\sim \\operatorname{Normal}(178, 20) \\space \\space (3)  \\\\ \n\\beta \\sim \\operatorname{Log-Normal}(0,10) \\space \\space (4) \\\\\n\\sigma \\sim \\operatorname{Uniform}(0, 50)  \\space \\space (5) \\\\    \n\\end{align*} \n$$ {#eq-find-post-dist-a}\n\n```         \nheight ~ dnorm(mu, sigma)     # <1>\nmu <- a + b * (weight - xbar) # <2>\na ~ dnorm(178, 20)            # <3>\nb ~ dlnorm(0, 10)             # <4>\nsigma ~ dunif(0, 50)          # <5>\n```\n:::\n\n------------------------------------------------------------------------\n\nNotice that the linear model, in the R code on the right-hand side, uses\nthe R assignment operator, `<-` instead of the symbol `=`.\n\n\n::: {.cell}\n\n````{.cell-code #lst-find-post-dist-a lst-cap=\"Find the posterior distribution of the linear height-weight model: rethinking version\"}\n```{{r}}\n#| label: find-post-dist-a\n#| attr-source: '#lst-find-post-dist-a lst-cap=\"Find the posterior distribution of the linear height-weight model: rethinking version\"'\n\n## R code 4.42 #############################\n\n# define the average weight, x-bar\nxbar <- mean(d2_a$weight)\n\n# fit model\nm4.3 <- rethinking::quap(\n  alist(\n    height ~ dnorm(mu, sigma),\n    mu <- a + b * (weight - xbar),\n    a ~ dnorm(178, 20),\n    b ~ dlnorm(0, 1),\n    sigma ~ dunif(0, 50)\n  ),\n  data = d2_a\n)\n\n# summary result\n## R code 4.44 ############################\nrethinking::precis(m4.3)\n```\n````\n\n```\n#>              mean         sd        5.5%       94.5%\n#> a     154.6013671 0.27030766 154.1693633 155.0333710\n#> b       0.9032807 0.04192363   0.8362787   0.9702828\n#> sigma   5.0718809 0.19115478   4.7663786   5.3773831\n```\n:::\n\n\nYou can usefully think of as assigning to $y = log(x)$ the order of\nmagnitude of $x = exp(y)$. The function is the reverse, turning a\nmagnitude into a value. These definitions will make a mathematician\nshriek. But much of our computational work relies only on these\nintuitions.\n\nThese definitions allow the Log-Normal prior for `β` to be coded another\nway. Instead of defining a parameter `β`, we define a parameter that is\nthe logarithm of `β` and then assign it a normal distribution. Then we\ncan reverse the logarithm inside the linear model. It looks like this:\n\n\n::: {.cell}\n\n````{.cell-code #lst-find-post-dist2-a lst-cap=\"Find the posterior distribution of the linear height-weight model (log version): rethinking version\"}\n```{{r}}\n#| label: find-post-dist2-a\n#| attr-source: '#lst-find-post-dist2-a lst-cap=\"Find the posterior distribution of the linear height-weight model (log version): rethinking version\"'\n\n## R code 4.43 ############################\nm4.3b <- rethinking::quap(\n  alist(\n    height ~ dnorm(mu, sigma),\n    mu <- a + exp(log_b) * (weight - xbar),\n    a ~ dnorm(178, 20),\n    log_b ~ dnorm(0, 1),\n    sigma ~ dunif(0, 50)\n  ),\n  data = d2_a\n)\n\nrethinking::precis(m4.3b)\n```\n````\n\n```\n#>               mean         sd        5.5%        94.5%\n#> a     154.60260508 0.27034420 154.1705428 155.03466732\n#> log_b  -0.09955739 0.04626836  -0.1735032  -0.02561161\n#> sigma   5.07256420 0.19121896   4.7669594   5.37816904\n```\n:::\n\n\nNote the `exp(log_b)` in the definition of `mu`. This is the same model\nas `m4.3`. It will make the same predictions. But instead of `β` in the\nposterior distribution, you get `log((β)`. It is easy to translate\nbetween the two, because $\\beta = exp(log(\\beta))$. In code form:\n`b <- exp(log_b)`.\n\n#### Tidyverse\n\nUnlike with McElreath's `rethinking::quap()` formula syntax, Kurz is not\naware that we can just specify something like `weight – xbar` in the\n`formula` argument in `brms::brm()`. \n\n\nHowever, the alternative is easy:\nJust make a new variable in the data that is equivalent to\n`weight – mean(weight)`. We'll call it `weight_c`.\n\n\n::: {.cell}\n\n````{.cell-code #lst-create-weight-diff-var-b lst-cap=\"Create a new variable in the data equivalent to weight - mean(height): tidyverse version\"}\n```{{r}}\n#| label: create-weight-diff-var-b\n#| attr-source: '#lst-create-weight-diff-var-b lst-cap=\"Create a new variable in the data equivalent to weight - mean(height): tidyverse version\"'\n\n\nd2_b <-\n  d2_b %>% \n  mutate(weight_c = weight - mean(weight))\n```\n````\n:::\n\nUnlike with McElreath’s {**rethinking**} package, the conventional `brms::brm()` syntax doesn’t mirror the statistical notation. But here are the analogues to the exposition at the bottom of page 97:\n\n$$\n* $\\text{height}_i \\sim \\operatorname{Normal}(\\mu_i, \\sigma)$: `family = gaussian`,\n* $\\mu_i = \\alpha + \\beta \\text{weight}_i$: `height ~ 1 + weight_c`,\n* $\\alpha \\sim \\operatorname{Normal}(178, 20)$: `prior(normal(178, 20), class = Intercept`,\n* $\\beta \\sim \\operatorname{Log-Normal}(0, 1)$: `prior(lognormal(0, 1), class = b)`, and\n* $\\sigma \\sim \\operatorname{Uniform}(0, 50)$: `prior(uniform(0, 50), class = sigma)`.\n$$ {#eq-find-post-dist-b}\n\n\n\n\n::: {.cell}\n\n````{.cell-code #lst-find-and-summarize-post-dist-b lst-cap=\"Find the posterior distribution of the linear height-weight model: tidyverse version\"}\n```{{r}}\n#| label: find-and summarize-post-dist-b\n#| attr-source: '#lst-find-and-summarize-post-dist-b lst-cap=\"Find the posterior distribution of the linear height-weight model: tidyverse version\"'\n\nb4.3 <- \n  brms::brm(data = d2_b, \n      family = gaussian,\n      height ~ 1 + weight_c,\n      prior = c(brms::prior(normal(178, 20), class = Intercept),\n                brms::prior(lognormal(0, 1), class = b),\n                brms::prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4,\n      file = \"fits/b04.03\")\n\nbrms:::summary.brmsfit(b4.3)\n```\n````\n\n```\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 + weight_c \n#>    Data: d2_b (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   154.60      0.27   154.08   155.14 1.00     4445     2954\n#> weight_c      0.90      0.04     0.82     0.98 1.00     4035     2903\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     5.11      0.19     4.74     5.51 1.00     4349     3157\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nHere are the trace plots.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-find-post-dist-b\n#| fig-cap: \"Find the posterior distribution of the linear height-weight model: tidyverse version\"\n\nplot(b4.3, widths = c(1, 2))\n```\n````\n\n::: {.cell-output-display}\n![Find the posterior distribution of the linear height-weight model: tidyverse version](04-geocentric-models_files/figure-html/fig-find-post-dist-b-1.png){#fig-find-post-dist-b width=672}\n:::\n:::\n\n\n{**brms**} does not allow users to insert coefficients into functions\nlike exp() within the conventional `formula` syntax. We can fit a\n{**brms**} model like McElreath's `m4.3b` if we adopt what's called the\n[non-linear\nsyntax](https://cran.r-project.org/web/packages/brms/vignettes/brms_nonlinear.html).\nThe non-linear syntax is a lot like the syntax McElreath uses in\n{**rethinking**} in that it typically includes both predictor and\nvariable names in the `formula`. Since this is so early in the book, I\nwon't go into a full-blown explanation, here. There will be many more\nopportunities to practice with the non-linear syntax in the chapters to\ncome.\n\n\n::: {.cell}\n\n````{.cell-code #lst-find-post-dist2-b lst-cap=\"Find the posterior distribution of the linear height-weight model (log version): tidyverse version\"}\n```{{r}}\n#| label: find-post-dist2-b\n#| attr-source: '#lst-find-post-dist2-b lst-cap=\"Find the posterior distribution of the linear height-weight model (log version): tidyverse version\"'\n\nb4.3b <- \n  brms::brm(data = d2_b, \n      family = gaussian,\n      brms::bf(height ~ a + exp(lb) * weight_c,\n         a ~ 1,\n         lb ~ 1,\n         nl = TRUE),\n      prior = c(brms::prior(normal(178, 20), class = b, nlpar = a),\n                brms::prior(normal(0, 1), class = b, nlpar = lb),\n                brms::prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4,\n      file = \"fits/b04.03b\")\n```\n````\n:::\n\n\nIf you execute `summary(b4.3b)`, you\\'ll see the intercept and `σ`\nsummaries for this model are about the same as those for `b4.3`, above.\n\n\n::: {.cell}\n\n````{.cell-code #lst-summarize-post-dist2-b lst-cap=\"Summarize the posterior distribution of the linear height-weight model (log version): tidyverse version\"}\n```{{r}}\n#| label: summarize-post-dist2-b\n#| attr-source: '#lst-summarize-post-dist2-b lst-cap=\"Summarize the posterior distribution of the linear height-weight model (log version): tidyverse version\"'\n\nbrms:::summary.brmsfit(b4.3b)\n```\n````\n\n```\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ a + exp(lb) * weight_c \n#>          a ~ 1\n#>          lb ~ 1\n#>    Data: d2_b (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> a_Intercept    154.61      0.27   154.08   155.12 1.00     3524     2646\n#> lb_Intercept    -0.10      0.05    -0.20    -0.01 1.00     4412     2848\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     5.11      0.19     4.75     5.51 1.00     3697     2629\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nThe difference is for the β parameter, which we called `lb` in the\n`b4.3b` model. If we term that parameter from `b4.3` as $\\beta^{b4.3}$\nand the one from our new model $\\beta^{b4.3b}$, it turns out that\n$\\beta^{b4.3} = exp(\\beta^{b4.3b})$.\n\n\n::: {.cell}\n\n````{.cell-code #lst-extract-foxed-effects-b lst-cap=\"Extract and compare the population-level (fixed) effects from object b4.3 and b4.3b\"}\n```{{r}}\n#| label: extract-fixed-effects-b\n#| attr-source: '#lst-extract-foxed-effects-b lst-cap=\"Extract and compare the population-level (fixed) effects from object b4.3 and b4.3b\"'\n\nbrms::fixef(b4.3)[\"weight_c\", \"Estimate\"]\nbrms::fixef(b4.3b)[\"lb_Intercept\", \"Estimate\"] %>% exp()\n```\n````\n\n```\n#> [1] 0.9024216\n#> [1] 0.9037418\n```\n:::\n\n\nThey\\'re the same within simulation variance.\n\n### Interpretating the posterior distribution\n\n#### Original\n\nStatistical models are hard to interpret. There are two broad categories of interpretation:\n- reading tables\n- plotting simulation\n\nPlotting posterior distributions and posterior predictions is better than attempting to understand a table. \n\n##### Table of marginal distributions\n\nI have already included the summary (`precis()`) for the `m4.3` model in @lst-find-post-dist-a. But I will repeat it to inspect the marginal posterior distributions of the parameters in detail:\n\n\n::: {.cell}\n\n````{.cell-code #lst-display-precis-m4.3 lst-cap=\"Display the marginal posterior distributions of the parameters: rethinking version\"}\n```{{r}}\n#| label: display-precis-m4.3\n#| attr-source: '#lst-display-precis-m4.3 lst-cap=\"Display the marginal posterior distributions of the parameters: rethinking version\"'\n\n\n## R code 4.44 ################\nrethinking::precis(m4.3)\n```\n````\n\n```\n#>              mean         sd        5.5%       94.5%\n#> a     154.6013671 0.27030766 154.1693633 155.0333710\n#> b       0.9032807 0.04192363   0.8362787   0.9702828\n#> sigma   5.0718809 0.19115478   4.7663786   5.3773831\n```\n:::\n\n1. First row: quadratic approximation for $\\alpha$\n2. Second row: quadratic approximation for $\\beta$\n3. Third row: quadratic approximation for $\\sigma$\n\n\nLet’s focus on b ($\\beta$), because it’s the new parameter. Since ($\\beta$) is a slope, the value 0.90 can be read as *a person 1 kg heavier is expected to be 0.90 cm taller*. 89% of the posterior probability ($94.5-5.5$) lies between 0.84 and 0.97. That suggests that ($\\beta$) values close to zero or greatly above one are highly incompatible with these data and this model. It is most certainly not evidence that the relationship between weight and height is linear, because the model only considered lines. It just says that, if you are committed to a line, then lines with a slope around 0.9 are plausible ones.\n\nRemember, the numbers in the default precis output aren’t sufficient to describe the quadratic posterior completely. For that, we also require the variance-covariance matrix. \n\n\n::: {.cell}\n\n````{.cell-code #lst-var-cov-matrix-m4.3 lst-cap=\"Calculate the variance-covariance matrix for model m4.3\"}\n```{{r}}\n#| label: var-cov-matrix-m4.3\n#| attr-source: '#lst-var-cov-matrix-m4.3 lst-cap=\"Calculate the variance-covariance matrix for model m4.3\"'\n\n## R code 4.45 ######################\nround(rethinking::vcov(m4.3), 3)\n```\n````\n\n```\n#>           a     b sigma\n#> a     0.073 0.000 0.000\n#> b     0.000 0.002 0.000\n#> sigma 0.000 0.000 0.037\n```\n:::\n\n::: {.cell}\n\n````{.cell-code #lst-var-cov-matrix-m4.3 lst-cap=\"Calculate the marginal posteriors and covariance matrix for model m4.3\"}\n```{{r}}\n#| label: marg-post-cov-m4.3\n#| attr-source: '#lst-var-cov-matrix-m4.3 lst-cap=\"Calculate the marginal posteriors and covariance matrix for model m4.3\"'\n\nrethinking::pairs(m4.3)\n```\n````\n\n```\n#> Warning in par(usr): argument 1 does not name a graphical parameter\n\n#> Warning in par(usr): argument 1 does not name a graphical parameter\n\n#> Warning in par(usr): argument 1 does not name a graphical parameter\n```\n\n::: {.cell-output-display}\n![](04-geocentric-models_files/figure-html/marg-post-cov-m4.3-1.png){width=672}\n:::\n:::\n\n\n##### Plotting posterior inference against the data\n\nIt’s almost always much more useful to plot the posterior inference against the data. Not only does plotting help in interpreting the posterior, but it also provides an informal check on model assumptions. \n\nWe’re going to start with a simple version of that task, superimposing just the posterior mean values over the height and weight data. Then we’ll slowly add more and more information to the prediction plots, until we’ve used the entire posterior distribution.\n\nWe’ll start with just the raw data and a single line. The code below plots the raw data, computes the posterior mean values for `a` and `b`, then draws the implied line:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-raw-data-line-m4.3\n#| fig-cap: \"Height in centimeters (vertical) plotted against weight in kilograms (horizontal), with the line at the posterior mean plotted in black.\"\n\n## R code 4.46 ############################################\nplot(height ~ weight, data = d2_a, col = rethinking::rangi2)\npost_m4.3 <- rethinking::extract.samples(m4.3)\na_map <- mean(post_m4.3$a)\nb_map <- mean(post_m4.3$b)\ncurve(a_map + b_map * (x - xbar), add = TRUE)\n```\n````\n\n::: {.cell-output-display}\n![Height in centimeters (vertical) plotted against weight in kilograms (horizontal), with the line at the posterior mean plotted in black.](04-geocentric-models_files/figure-html/fig-raw-data-line-m4.3-1.png){#fig-raw-data-line-m4.3 width=672}\n:::\n:::\n\nEach point in this plot is a single individual. The black line is defined by the mean slope `β` and mean intercept `α`. This is not a bad line. It certainly looks highly plausible. But there are an infinite number of other highly plausible lines near it. Let’s draw those too.\n\n##### Adding uncertainty around the mean\n\nPlots of the average line, like in @fig-raw-data-line-m4.3, are useful for getting an impression of the magnitude of the estimated influence of a variable. But they do a poor job of communicating uncertainty. Remember, the posterior distribution considers every possible regression line connecting height to weight. It assigns a relative plausibility to each. This means that each combination of `α` and `β` has a posterior probability. It could be that there are many lines with nearly the same posterior probability as the average line. Or it could be instead that the posterior distribution is rather narrow near the average line.\n\nSo how can we get that uncertainty onto the plot? Together, a combination of `α` and `β` define a line. And so we could sample a bunch of lines from the posterior distribution. Then we could display those lines on the plot, to visualize the uncertainty in the regression relationship.\n\nTo better appreciate how the posterior distribution contains lines, we work with all of the samples from the model. \n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: collect-post-samples-a\n\n## R code 4.47 ################\n# post_m4.3 <- rethinking::extract.samples(m4.3) # already in previous listing\npost_m4.3[1:5, ]\n```\n````\n\n```\n#>          a         b    sigma\n#> 1 154.5208 0.8393668 4.995964\n#> 2 154.8405 0.8407996 5.016383\n#> 3 154.5813 0.9485057 5.143586\n#> 4 154.0805 0.8992872 5.100492\n#> 5 154.8228 0.9488178 5.146869\n```\n:::\n\n\nEach row is a correlated random sample from the joint posterior of all three parameters, using the covariances provided by `rethinking::vcov(m4.3)` (@lst-var-cov-matrix-m4.3). The paired values of `a` and `b` on each row define a line. The average of very many of these lines is the posterior mean line. But the scatter around that average is meaningful, because it alters our confidence in the relationship between the predictor and the outcome.\n\nSo now let’s display a bunch of these lines, so you can see the scatter. This lesson will be easier to appreciate, if we use only some of the data to begin. Then you can see how adding in more data changes the scatter of the lines. So we’ll begin with just the first 10 cases in `d2_a`. The following code extracts the first 10 cases and re-estimates the model:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: extract-10-re-est-mod-a\n\n## R code 4.48 ##########################\nN10_a <- 10\ndN10_a <- d2_a[1:N10_a, ]\nmN10_a <- rethinking::quap(\n  alist(\n    height ~ dnorm(mu, sigma),\n    mu <- a + b * (weight - mean(weight)),\n    a ~ dnorm(178, 20),\n    b ~ dlnorm(0, 1),\n    sigma ~ dunif(0, 50)\n  ),\n  data = dN10_a\n)\n```\n````\n:::\n\n\nNow let’s plot 20 of these lines for the 10 data points, to see what the uncertainty looks like.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-plot-lines-10-points-a\n#| fig-cap: \"Samples from the quadratic approximate posterior distribution for the height/weight model, m4.3. 20 lines sampled from 10 data points of the posterior distribution, showing the uncertainty in the regression relationship: rethinking version\"\n\n\n## R code 4.49 ##############################\n# extract 20 samples from the posterior\npost_20_m4.3 <- rethinking::extract.samples(mN10_a, n = 20)\n\n# display raw data and sample size\nplot(dN10_a$weight, dN10_a$height,\n  xlim = range(d2_a$weight), ylim = range(d2_a$height),\n  col = rethinking::rangi2, xlab = \"weight\", ylab = \"height\"\n)\nmtext(rethinking:::concat(\"N = \", N10_a))\n\n# plot the lines, with transparency\nfor (i in 1:20) {\n  curve(post_20_m4.3$a[i] + post_20_m4.3$b[i] * (x - mean(dN10_a$weight)),\n    col = rethinking::col.alpha(\"black\", 0.3), add = TRUE\n  )\n}\n```\n````\n\n::: {.cell-output-display}\n![Samples from the quadratic approximate posterior distribution for the height/weight model, m4.3. 20 lines sampled from 10 data points of the posterior distribution, showing the uncertainty in the regression relationship: rethinking version](04-geocentric-models_files/figure-html/fig-plot-lines-10-points-a-1.png){#fig-plot-lines-10-points-a width=672}\n:::\n:::\n\nThe result is shown in the upper-left plot in FIGURE 4.7. By plotting multiple regression lines, sampled from the posterior, it is easy to see both the highly confident aspects of the relationship and the less confident aspects. The cloud of regression lines displays greater uncertainty at extreme values for weight.\n\nThe other plots in FIGURE 4.7 show the same relationships, but for increasing amounts of data. Just re-use the code from before, but change N <- 10 to some other value. Notice that the cloud of regression lines grows more compact as the sample size increases. This is a result of the model growing more confident about the location of the mean.\n\nPlot 20 lines sampled from 50 data points of the posterior distribution\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-plot-lines-50-points-a\n#| fig-cap: \"Samples from the quadratic approximate posterior distribution for the height/weight model, m4.3. 20 lines sampled from 50 data points of the posterior distribution, showing the uncertainty in the regression relationship: rethinking version\"\n\n## R code 4.48, 4.49 ######################\nN50_a <- 50\ndN50_a <- d2_a[1:N50_a, ]\nmN50_a <- rethinking::quap(\n  alist(\n    height ~ dnorm(mu, sigma),\n    mu <- a + b * (weight - mean(weight)),\n    a ~ dnorm(178, 20),\n    b ~ dlnorm(0, 1),\n    sigma ~ dunif(0, 50)\n  ),\n  data = dN50_a\n)\n\n# extract 20 samples from the posterior\npost_50_m4.3 <- rethinking::extract.samples(mN50_a, n = 20)\n\n# display raw data and sample size\nplot(dN50_a$weight, dN50_a$height,\n  xlim = range(d2_a$weight), ylim = range(d2_a$height),\n  col = rethinking::rangi2, xlab = \"weight\", ylab = \"height\"\n)\nmtext(rethinking:::concat(\"N = \", N50_a))\n\n# plot the lines, with transparency\nfor (i in 1:20) {\n  curve(post_50_m4.3$a[i] + post_50_m4.3$b[i] * (x - mean(dN50_a$weight)),\n    col = rethinking::col.alpha(\"black\", 0.3), add = TRUE\n  )\n}\n```\n````\n\n::: {.cell-output-display}\n![Samples from the quadratic approximate posterior distribution for the height/weight model, m4.3. 20 lines sampled from 50 data points of the posterior distribution, showing the uncertainty in the regression relationship: rethinking version](04-geocentric-models_files/figure-html/fig-plot-lines-50-points-a-1.png){#fig-plot-lines-50-points-a width=672}\n:::\n:::\n\n\nPlot 20 lines sampled from 352 data points of the posterior distribution\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-plot-lines-all-352-points-a\n#| fig-cap: \"Samples from the quadratic approximate posterior distribution for the height/weight model, m4.3. 20 lines sampled from all 352 data points of the posterior distribution, showing the uncertainty in the regression relationship.\"\n\n## R code 4.48, 4.49 ###########################\nN352_a <- 352\ndN352_a <- d2_a[1:N352_a, ]\nmN352_a <- rethinking::quap(\n  alist(\n    height ~ dnorm(mu, sigma),\n    mu <- a + b * (weight - mean(weight)),\n    a ~ dnorm(178, 20),\n    b ~ dlnorm(0, 1),\n    sigma ~ dunif(0, 50)\n  ),\n  data = dN352_a\n)\n\n# extract 20 samples from the posterior\npost_352_m4.3 <- rethinking::extract.samples(mN352_a, n = 20)\n\n# display raw data and sample size\nplot(dN352_a$weight, dN352_a$height,\n  xlim = range(d2_a$weight), ylim = range(d2_a$height),\n  col = rethinking::rangi2, xlab = \"weight\", ylab = \"height\"\n)\nmtext(rethinking:::concat(\"N = \", N352_a))\n\n# plot the lines, with transparency\nfor (i in 1:20) {\n  curve(post_352_m4.3$a[i] + post_352_m4.3$b[i] * (x - mean(dN352_a$weight)),\n    col = rethinking::col.alpha(\"black\", 0.3), add = TRUE\n  )\n}\n```\n````\n\n::: {.cell-output-display}\n![Samples from the quadratic approximate posterior distribution for the height/weight model, m4.3. 20 lines sampled from all 352 data points of the posterior distribution, showing the uncertainty in the regression relationship.](04-geocentric-models_files/figure-html/fig-plot-lines-all-352-points-a-1.png){#fig-plot-lines-all-352-points-a width=672}\n:::\n:::\n\n\n\n#### Tidyverse\n\nInstead of `rethinking::extract.samples()` the {**brms**} packages extract all the posterior draws with `brms::as_draws_df()`. We have already done this with @lst-put-hmc-into-df-b. We just repeat this code here using `dplyr::slice(1:6)` instead of `utils::head()`\n\n\n\n::: {.cell}\n\n````{.cell-code #lst-put-hmc-into-df2-b lst-cap=\"Extract the iteration of the Hamiliton Monte Carlo (HMC) chains into a data frame\"}\n```{{r}}\n#| label: put-hmc-into-df2-b\n#| attr-source: '#lst-put-hmc-into-df2-b lst-cap=\"Extract the iteration of the Hamiliton Monte Carlo (HMC) chains into a data frame\"'\n\npost_b <- brms::as_draws_df(b4.3)\npost_b %>%\n  slice(1:6)\n```\n````\n\n```\n#> # A draws_df: 6 iterations, 1 chains, and 5 variables\n#>   b_Intercept b_weight_c sigma lprior  lp__\n#> 1         155       0.93   5.1   -9.3 -1079\n#> 2         154       0.87   5.1   -9.3 -1080\n#> 3         155       0.94   5.0   -9.4 -1080\n#> 4         155       0.93   5.2   -9.3 -1084\n#> 5         154       0.88   4.8   -9.4 -1085\n#> 6         155       0.91   5.3   -9.3 -1083\n#> # ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n```\n:::\n\n\nHere are the four models:\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-all-four-models-b lst-cap=\"Calculate all four models\"}\n```{{r}}\n#| label: calc-all-four-models-b\n#| attr-source: '#lst-calc-all-four-models-b lst-cap=\"Calculate all four models\"'\n\ndN10_b <- 10\n\nb4.3_010 <- \n  brms::brm(data = d2_b %>%\n        slice(1:dN10_b),  # note our tricky use of `N` and `slice()`\n      family = gaussian,\n      height ~ 1 + weight_c,\n      prior = c(brms::prior(normal(178, 20), class = Intercept),\n                brms::prior(lognormal(0, 1), class = b),\n                brms::prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4,\n      file = \"fits/b04.03_010\")\n\ndN50_b <- 50\n\nb4.3_050 <- \n  brms::brm(data = d2_b %>%\n        slice(1:dN50_b), \n      family = gaussian,\n      height ~ 1 + weight_c,\n      prior = c(brms::prior(normal(178, 20), class = Intercept),\n                brms::prior(lognormal(0, 1), class = b),\n                brms::prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4,\n      file = \"fits/b04.03_050\")\n\ndN150_b <- 150\n\nb4.3_150 <- \n  brms::brm(data = d2_b %>%\n        slice(1:dN150_b), \n      family = gaussian,\n      height ~ 1 + weight_c,\n      prior = c(brms::prior(normal(178, 20), class = Intercept),\n                brms::prior(lognormal(0, 1), class = b),\n                brms::prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4,\n      file = \"fits/b04.03_150\")\n\ndN352_b <- 352\n\nb4.3_352 <- \n  brms::brm(data = d2_b %>%\n        slice(1:dN352_b), \n      family = gaussian,\n      height ~ 1 + weight_c,\n      prior = c(brms::prior(normal(178, 20), class = Intercept),\n                brms::prior(lognormal(0, 1), class = b),\n                brms::prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4,\n      file = \"fits/b04.03_352\")\n```\n````\n:::\n\n\n\nHere are the trace plots and coefficient summaries from these four models.\n\n\n::: {.cell}\n\n````{.cell-code #lst-trace-plots-cov-sum-b lst-cap=\"Trace plots and coefficient summaries from all four models\"}\n```{{r}}\n#| label: trace-plots-cov-sum-b\n#| attr-source: '#lst-trace-plots-cov-sum-b lst-cap=\"Trace plots and coefficient summaries from all four models\"'\n\n\nplot(b4.3_010)\nprint(b4.3_010)\n```\n````\n\n```\n#> Warning: There were 1 divergent transitions after warmup. Increasing\n#> adapt_delta above 0.8 may help. See\n#> http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup\n```\n\n````{.cell-code #lst-trace-plots-cov-sum-b lst-cap=\"Trace plots and coefficient summaries from all four models\"}\n```{{r}}\n#| label: trace-plots-cov-sum-b\n#| attr-source: '#lst-trace-plots-cov-sum-b lst-cap=\"Trace plots and coefficient summaries from all four models\"'\n\n\nplot(b4.3_050)\nprint(b4.3_050)\n\nplot(b4.3_150)\nprint(b4.3_150)\n\nplot(b4.3_352)\nprint(b4.3_352)\n```\n````\n\n```\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 + weight_c \n#>    Data: d2_b %>% slice(1:dN10_b) (Number of observations: 10) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   152.12      1.99   148.31   156.28 1.00     2464     1901\n#> weight_c      0.91      0.20     0.49     1.29 1.00     2702     2078\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     5.88      1.91     3.40    10.62 1.00     1911     1879\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 + weight_c \n#>    Data: d2_b %>% slice(1:dN50_b) (Number of observations: 50) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   152.92      0.71   151.51   154.30 1.00     3989     2783\n#> weight_c      0.88      0.10     0.69     1.07 1.00     3776     3110\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     5.04      0.52     4.13     6.20 1.00     3637     2433\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 + weight_c \n#>    Data: d2_b %>% slice(1:dN150_b) (Number of observations: 150) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   153.85      0.46   152.94   154.74 1.00     3479     2849\n#> weight_c      0.90      0.06     0.77     1.02 1.00     3910     2652\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     5.51      0.32     4.92     6.19 1.00     3576     2896\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 + weight_c \n#>    Data: d2_b %>% slice(1:dN352_b) (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   154.60      0.27   154.08   155.14 1.00     4445     2954\n#> weight_c      0.90      0.04     0.82     0.98 1.00     4035     2903\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     5.11      0.19     4.74     5.51 1.00     4349     3157\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n::: {.cell-output-display}\n![](04-geocentric-models_files/figure-html/trace-plots-cov-sum-b-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](04-geocentric-models_files/figure-html/trace-plots-cov-sum-b-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](04-geocentric-models_files/figure-html/trace-plots-cov-sum-b-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](04-geocentric-models_files/figure-html/trace-plots-cov-sum-b-4.png){width=672}\n:::\n:::\n\n\n\nWe’ll need to put the chains of each model into data frames.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: put-chain-into-model-b\n#| #| attr-source: #lst-put-chain-into-model-b lst-cap=\"Put the chains of each model into data frames\"'\n\npost010_b4.3 <- brms::as_draws_df(b4.3_010)\npost050_b4.3 <- brms::as_draws_df(b4.3_050)\npost150_b4.3 <- brms::as_draws_df(b4.3_150)\npost352_b4.3 <- brms::as_draws_df(b4.3_352)\n```\n````\n:::\n\n\n\nHere is the code for the four individual plots:\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-code-for plots-b lst-cap=\"Prepare data for four individual plots\"}\n```{{r}}\n#| label: calc-code-for plots-b\n#| attr-source: '#lst-calc-code-for plots-b lst-cap=\"Prepare data for four individual plots\"'\n\np1 <- \n  ggplot(data =  d2_b[1:10, ], \n         aes(x = weight_c, y = height)) +\n  geom_abline(data = post010_b4.3 %>% slice(1:20),\n              aes(intercept = b_Intercept, slope = b_weight_c),\n              linewidth = 1/3, alpha = .3) +\n  geom_point(shape = 1, size = 2, color = \"royalblue\") +\n  coord_cartesian(xlim = range(d2_b$weight_c),\n                  ylim = range(d2_b$height)) +\n  labs(subtitle = \"N = 10\")\n\np2 <-\n  ggplot(data =  d2_b[1:50, ], \n         aes(x = weight_c, y = height)) +\n  geom_abline(data = post050_b4.3 %>% slice(1:20),\n              aes(intercept = b_Intercept, slope = b_weight_c),\n              linewidth = 1/3, alpha = .3) +\n  geom_point(shape = 1, size = 2, color = \"royalblue\") +\n  coord_cartesian(xlim = range(d2_b$weight_c),\n                  ylim = range(d2_b$height)) +\n  labs(subtitle = \"N = 50\")\n\np3 <-\n  ggplot(data =  d2_b[1:150, ], \n         aes(x = weight_c, y = height)) +\n  geom_abline(data = post150_b4.3 %>% slice(1:20),\n              aes(intercept = b_Intercept, slope = b_weight_c),\n              linewidth = 1/3, alpha = .3) +\n  geom_point(shape = 1, size = 2, color = \"royalblue\") +\n  coord_cartesian(xlim = range(d2_b$weight_c),\n                  ylim = range(d2_b$height)) +\n  labs(subtitle = \"N = 150\")\n\np4 <- \n  ggplot(data =  d2_b[1:352, ], \n         aes(x = weight_c, y = height)) +\n  geom_abline(data = post352_b4.3 %>% slice(1:20),\n              aes(intercept = b_Intercept, slope = b_weight_c),\n              linewidth = 1/3, alpha = .3) +\n  geom_point(shape = 1, size = 2, color = \"royalblue\") +\n  coord_cartesian(xlim = range(d2_b$weight_c),\n                  ylim = range(d2_b$height)) +\n  labs(subtitle = \"N = 352\")\n```\n````\n:::\n\n\n\nNow we can combine the ggplots with patchwork syntax to make the full version of Figure 4.7.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-draw-plots-figure-4.7-b\n#| fig-cap: \"Samples from the quadratic approximate posterior distribution for the height/weight model, b4.3, with increasing amounts of data. In each plot, 20 lines sampled from the posterior distribution, showing the uncertainty in the regression relationship. Tidyverse version.\"\n\n\n\nlibrary(patchwork)\n\n(p1 + p2 + p3 + p4) &\n  scale_x_continuous(\"weight\",\n                     breaks = c(-10, 0, 10),\n                     labels = labels) &\n  theme_classic()\n```\n````\n\n::: {.cell-output-display}\n![Samples from the quadratic approximate posterior distribution for the height/weight model, b4.3, with increasing amounts of data. In each plot, 20 lines sampled from the posterior distribution, showing the uncertainty in the regression relationship. Tidyverse version.](04-geocentric-models_files/figure-html/fig-draw-plots-figure-4.7-b-1.png){#fig-draw-plots-figure-4.7-b width=672}\n:::\n:::\n\n\n\n\n##### Plotting regression intervals and contours\n\nThe cloud of regression lines in @fig-plot-lines-10-points-a, @fig-plot-lines-50-points-a and @fig-plot-lines-all-352-points-a is an appealing display, because it communicates uncertainty about the relationship in a way that many people find intuitive. But it’s more common, and often much clearer, to see the uncertainty displayed by plotting an interval or contour around the average regression line.\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-PI-around-regr-line-a lst-cap=\"Calculate uncertainty around the average regression line\"}\n```{{r}}\n#| label: calc-PI-around-regr-line-a\n#| attr-source: '#lst-calc-PI-around-regr-line-a lst-cap=\"Calculate uncertainty around the average regression line\"'\n\n## R code 4.50 ##########################\n\npost_m4.3 <- rethinking::extract.samples(m4.3)      # <1>\nmu_at_50_a <- post_m4.3$a + post_m4.3$b * (50 - xbar) # <2>\nhead(mu_at_50_a)                                      # <3>\n```\n````\n\n```\n#> [1] 159.5583 159.4304 159.0339 159.5448 159.3048 159.0473\n```\n:::\n\n\n1. Repeating the code for drawing (extracting and collecting) from the fitted model m4.3 (already done in @fig-raw-data-line-m4.3)\n2. The code to the right of the `<-` takes its form from the equation for $\\mu_{i} = \\alpha + \\beta(x_{i} - \\overline{x})$. The value of $x_{i}$ in this case is 50.\n3. The result is a vector of predicted means, one for each random sample from the posterior. Since joint `a` and `b` went into computing each, the variation across those means incorporates the uncertainty in and correlation between both parameters.\n\nIt might be helpful at this point to actually plot the density for this vector of means:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-density-vector-mean-50-a\n#| fig-cap: \"The quadratic approximate posterior distribution of the mean height, μ, when weight is 50 kg. This distribution represents the relative plausibility of different values of the mean. Rehtinking version\"\n\n## R code 4.51 ##################\nrethinking::dens(mu_at_50_a, col = rethinking::rangi2, lwd = 2, xlab = \"mu|weight=50\")\n```\n````\n\n::: {.cell-output-display}\n![The quadratic approximate posterior distribution of the mean height, μ, when weight is 50 kg. This distribution represents the relative plausibility of different values of the mean. Rehtinking version](04-geocentric-models_files/figure-html/fig-density-vector-mean-50-a-1.png){#fig-density-vector-mean-50-a width=672}\n:::\n:::\n\n\nSince the components of `μ` have distributions, so too does `μ`. And since the distributions of `α` and `β` are Gaussian, so too is the distribution of `μ` (adding Gaussian distributions always produces a Gaussian distribution).\n\nSince the posterior for `μ` is a distribution, you can find intervals for it, just like for any posterior distribution. To find the 89% compatibility interval of `μ` at 50 kg, just use the `PI()` command as usual:\n\n\n::: {.cell}\n\n````{.cell-code #lst-PI-mu-at-50-a lst-cap=\"89% compatibility interval of μ at 50 kg\"}\n```{{r}}\n#| label: PI-mu-at-50-a\n#| attr-source: '#lst-PI-mu-at-50-a lst-cap=\"89% compatibility interval of μ at 50 kg\"'\n\n## R code 4.52 ##############\nrethinking::PI(mu_at_50_a, prob = 0.89)\n```\n````\n\n```\n#>       5%      94% \n#> 158.5863 159.6690\n```\n:::\n\n\nWhat these numbers mean is that the central 89% of the ways for the model to produce the data place the average height between about 159 cm and 160 cm (conditional on the model and data), assuming the weight is 50 kg.\n\nThat’s good so far, but we need to repeat the above calculation for every weight value on the horizontal axis, not just when it is 50 kg. We want to draw 89% intervals around the average slope in @fig-raw-data-line-m4.3.\n\nThis is made simple by strategic use of the `rethinking::`link()` function, a part of the {**rethinking**} package. What `rethinking::link()` will do is take your `rethinking::quap()` approximation, sample from the posterior distribution, and then compute `μ` for each case in the data and sample from the posterior distribution. Here’s what it looks like for the data you used to fit the model:\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-mu-with-link-a lst-cap=\"Calculate μ for each case in the data and sample from the posterior distribution: Rethinking version\"}\n```{{r}}\n#| label: calc-mu-with-link-a\n#| attr-source: '#lst-calc-mu-with-link-a lst-cap=\"Calculate μ for each case in the data and sample from the posterior distribution: Rethinking version\"'\n\n## R code 4.53 ##############\nmu_a <- rethinking::link(m4.3)\nstr(mu_a)\n```\n````\n\n```\n#>  num [1:1000, 1:352] 157 157 157 157 157 ...\n```\n:::\n\n\n\nYou end up with a big matrix of values of `μ`. Each row is a sample from the posterior distribution. The default is 1000 samples, but you can use as many or as few as you like. Each column is a case (row) in the data. There are 352 rows in `d2_a`, corresponding to 352 individuals. So there are 352 columns in the matrix mu above.\n\nThe function `rethinking::link()` provides a posterior distribution of `μ` for each case we feed it. So above we have a distribution of `μ` for each individual in the original data. We actually want something slightly different: a distribution of `μ` for each unique weight value on the horizontal axis. It’s only slightly harder to compute that, by just passing `rethinking::link()` some new data:\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-dist-mu-unique-with-link-a lst-cap=\"Calculate a distribution of μ for each unique weight value on the horizontal axis: rethinking version\"}\n```{{r}}\n#| label: calc-dist-mu-unique-with-link-a\n#| attr-source: '#lst-calc-dist-mu-unique-with-link-a lst-cap=\"Calculate a distribution of μ for each unique weight value on the horizontal axis: rethinking version\"'\n\n## R code 4.54 ###############################\n# define sequence of weights to compute predictions for\n# these values will be on the horizontal axis\nweight.seq <- seq(from = 25, to = 70, by = 1)\n\n# use link to compute mu\n# for each sample from posterior\n# and for each weight in weight.seq\nmu2_a <- rethinking::link(m4.3, data = data.frame(weight = weight.seq))\nstr(mu2_a)\n```\n````\n\n```\n#>  num [1:1000, 1:46] 137 137 137 136 136 ...\n```\n:::\n\n\nAnd now there are only 46 columns in mu, because we fed it 46 different values for weight. To visualize what you’ve got here, let’s plot the distribution of `μ` values at each height.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-dist-mu-height-100-a\n#| fig-cap: \"The first 100 values in the distribution of μ at each weight value. Rethinking version\"\n\n## R code 4.55\n# use type=\"n\" to hide raw data\nbase::plot(height ~ weight, d2_a, type = \"n\")\n\n# loop over samples and plot each mu value\nfor (i in 1:100) {\n  graphics::points(weight.seq, mu2_a[i, ], pch = 16, col = rethinking::col.alpha(rethinking::rangi2, 0.1))\n}\n```\n````\n\n::: {.cell-output-display}\n![The first 100 values in the distribution of μ at each weight value. Rethinking version](04-geocentric-models_files/figure-html/fig-dist-mu-height-100-a-1.png){#fig-dist-mu-height-100-a width=672}\n:::\n:::\n\nAt each weight value in `weight.seq`, a pile of computed `μ` values are shown. Each of these piles is a Gaussian distribution, like that in @fig-density-vector-mean-50-a. You can see now that the amount of uncertainty in `μ` depends upon the value of weight. And this is the same fact you saw in @fig-plot-lines-10-points-a, @fig-plot-lines-50-points-a and @fig-plot-lines-all-352-points-a.\n\nThe final step is to summarize the distribution for each weight value. We’ll use `base::apply()`, which applies a function of your choice to a matrix.\n\n\n::: {.cell}\n\n````{.cell-code #lst-sum-dist-weight-a lst-cap=\"Summary of the distribution for each weight value. Rethinking version\"}\n```{{r}}\n#| label: sum-dist-weight-a\n#| attr-source: '#lst-sum-dist-weight-a lst-cap=\"Summary of the distribution for each weight value. Rethinking version\"'\n\n## R code 4.56 #####################\n# summarize the distribution of mu\nmu2.mean <- apply(mu2_a, 2, mean)                      # <1>\nmu2.PI <- apply(mu2_a, 2, rethinking::PI, prob = 0.89) # <2>\nmu2.mean                                               # <3>\nmu2.PI                                                 # <4>\n```\n````\n\n```\n#>  [1] 136.5424 137.4466 138.3508 139.2550 140.1592 141.0634 141.9676 142.8718\n#>  [9] 143.7760 144.6802 145.5844 146.4886 147.3928 148.2970 149.2012 150.1054\n#> [17] 151.0096 151.9138 152.8180 153.7222 154.6264 155.5306 156.4348 157.3390\n#> [25] 158.2432 159.1474 160.0516 160.9558 161.8600 162.7642 163.6684 164.5726\n#> [33] 165.4768 166.3810 167.2852 168.1894 169.0936 169.9978 170.9020 171.8062\n#> [41] 172.7104 173.6146 174.5188 175.4230 176.3272 177.2314\n#>         [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]\n#> 5%  135.1820 136.1427 137.1090 138.0732 139.0427 140.0060 140.9769 141.9403\n#> 94% 137.9566 138.7957 139.6341 140.4685 141.3171 142.1576 142.9919 143.8282\n#>         [,9]    [,10]    [,11]    [,12]    [,13]    [,14]    [,15]    [,16]\n#> 5%  142.8926 143.8438 144.8002 145.7557 146.7248 147.6974 148.6586 149.5927\n#> 94% 144.6804 145.5304 146.3826 147.2280 148.0705 148.9315 149.7833 150.6489\n#>        [,17]    [,18]    [,19]    [,20]    [,21]    [,22]    [,23]    [,24]\n#> 5%  150.5291 151.4449 152.3822 153.2993 154.2077 155.0976 155.9761 156.8787\n#> 94% 151.5048 152.3802 153.2758 154.1675 155.0723 155.9922 156.9208 157.8639\n#>        [,25]    [,26]    [,27]    [,28]    [,29]    [,30]    [,31]    [,32]\n#> 5%  157.7496 158.6081 159.4745 160.3296 161.1675 162.0240 162.8661 163.6933\n#> 94% 158.8037 159.7456 160.7019 161.6398 162.6004 163.5497 164.5186 165.4686\n#>        [,33]    [,34]    [,35]    [,36]    [,37]    [,38]    [,39]    [,40]\n#> 5%  164.5345 165.3878 166.2443 167.0871 167.9170 168.7482 169.5905 170.4328\n#> 94% 166.4382 167.4100 168.3530 169.3173 170.2682 171.2195 172.1905 173.1432\n#>        [,41]    [,42]    [,43]    [,44]    [,45]    [,46]\n#> 5%  171.2669 172.1074 172.9446 173.7725 174.6008 175.4384\n#> 94% 174.1118 175.0804 176.0486 177.0111 177.9592 178.9288\n```\n:::\n\n\n1. Read `apply(mu2,2,mean)` as \"compute the mean of each column (dimension '2') of the matrix mu\". Now `mu2.mean` contains the average `μ` at each weight value.\n2. `mu2.PI` contains 89% lower and upper bounds for each weight value.\n3. `mu2.mean` and `mu2.PI` are just different kinds of summaries of the distributions in `mu2_a`, with each column being for a different weight value. These summaries are only summaries. The \"estimate\" is the entire distribution.\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-summaries-on-data-top-a\n#| fig-cap: \"Plot of the summaries on top of the !Kung height data again, now with 89% compatibility interval of the mean indicated by the shaded region. Compare this region to the distributions of blue points in @fig-dist-mu-height-100-a.\"\n\n## R code 4.57 ###########################\n# plot raw data\n# fading out points to make line and interval more visible\nplot(height ~ weight, data = d2_a, col = rethinking::col.alpha(rethinking::rangi2, 0.5))\n\n# plot the MAP line, aka the mean mu for each weight\ngraphics::lines(weight.seq, mu2.mean)\n\n# plot a shaded region for 89% PI\nrethinking::shade(mu2.PI, weight.seq)\n```\n````\n\n::: {.cell-output-display}\n![Plot of the summaries on top of the !Kung height data again, now with 89% compatibility interval of the mean indicated by the shaded region. Compare this region to the distributions of blue points in @fig-dist-mu-height-100-a.](04-geocentric-models_files/figure-html/fig-summaries-on-data-top-a-1.png){#fig-summaries-on-data-top-a width=672}\n:::\n:::\n\n::: callout-caution\nThere is very little uncertainty about the average height as a function of average weight. But keep in mind that these inferences are always conditional on the model. Think of the regression line in @fig-summaries-on-data-top-a as saying: *Conditional on the assumption that height and weight are related by a straight line, then this is the most plausible line, and these are its plausible bounds.*\n\n:::\n\n\nUsing this approach, you can derive and plot posterior prediction means and intervals for quite complicated models, for any data you choose. As long as you know the structure of the model —-- how parameters relate to the data —-- you can use samples from the posterior to describe any aspect of the model’s behavior.\n\nSummarizing the three steps for generating predictions and intervals from the posterior of a fit model:\n\n1. Use `rethinking::link()` to generate distributions of posterior values for `μ`. The default behavior of `rethinking::link()` is to use the original data, so you have to pass it a list of new horizontal axis values you want to plot posterior predictions across.\n2. Use summary functions like `mean` or `PI` to find averages and lower and upper bounds of `μ` for each value of the predictor variable.\n3. Finally, use plotting functions like `graphics::lines()` and `rethinking::shade()` to draw the lines and intervals. Or you might plot the distributions of the predictions, or do further numerical calculations with them. It’s really up to you.\n\n::: callout-note\nYou could write a function that accomplish the same thing as `rethinking::link()`:\n\n\n::: {.cell}\n\n````{.cell-code #lst-writing-link-function-a lst-cap=\"Code to perform the same steps as the rethinking::link() function\"}\n```{{r}}\n#| label: writing-link-function-a\n#| attr-source: '#lst-writing-link-function-a lst-cap=\"Code to perform the same steps as the rethinking::link() function\"'\n#|\n## R code 4.58 ################################\npost_m4.3 <- rethinking::extract.samples(m4.3)\nmu.link <- function(weight) post_m4.3$a + post_m4.3$b * (weight - xbar)\nweight.seq <- seq(from = 25, to = 70, by = 1)\nmu3_a <- sapply(weight.seq, mu.link)\nmu3.mean <- apply(mu3_a, 2, mean)\nmu3.CI <- apply(mu3_a, 2, rethinking::PI, prob = 0.89)\nmu3.mean\nmu3.CI\n```\n````\n\n```\n#>  [1] 136.5433 137.4467 138.3501 139.2535 140.1569 141.0603 141.9637 142.8671\n#>  [9] 143.7705 144.6740 145.5774 146.4808 147.3842 148.2876 149.1910 150.0944\n#> [17] 150.9978 151.9012 152.8046 153.7080 154.6114 155.5149 156.4183 157.3217\n#> [25] 158.2251 159.1285 160.0319 160.9353 161.8387 162.7421 163.6455 164.5489\n#> [33] 165.4523 166.3558 167.2592 168.1626 169.0660 169.9694 170.8728 171.7762\n#> [41] 172.6796 173.5830 174.4864 175.3898 176.2932 177.1967\n#>         [,1]     [,2]     [,3]     [,4]    [,5]     [,6]     [,7]     [,8]\n#> 5%  135.1346 136.1023 137.0692 138.0347 139.002 139.9674 140.9323 141.8988\n#> 94% 137.9574 138.7923 139.6301 140.4712 141.312 142.1543 142.9959 143.8406\n#>         [,9]    [,10]    [,11]    [,12]    [,13]    [,14]    [,15]    [,16]\n#> 5%  142.8629 143.8221 144.7844 145.7364 146.6898 147.6428 148.5936 149.5419\n#> 94% 144.6846 145.5325 146.3752 147.2210 148.0732 148.9256 149.7815 150.6415\n#>        [,17]    [,18]    [,19]    [,20]    [,21]    [,22]    [,23]    [,24]\n#> 5%  150.4843 151.4178 152.3481 153.2667 154.1750 155.0751 155.9637 156.8450\n#> 94% 151.5069 152.3764 153.2562 154.1457 155.0463 155.9524 156.8687 157.7983\n#>        [,25]    [,26]    [,27]    [,28]    [,29]    [,30]    [,31]    [,32]\n#> 5%  157.7134 158.5802 159.4383 160.2892 161.1380 161.9875 162.8366 163.6822\n#> 94% 158.7350 159.6771 160.6250 161.5771 162.5288 163.4906 164.4549 165.4137\n#>        [,33]    [,34]    [,35]    [,36]    [,37]    [,38]    [,39]    [,40]\n#> 5%  164.5318 165.3705 166.2136 167.0608 167.9028 168.7440 169.5778 170.4147\n#> 94% 166.3832 167.3498 168.3145 169.2823 170.2496 171.2195 172.1922 173.1626\n#>        [,41]    [,42]    [,43]    [,44]    [,45]    [,46]\n#> 5%  171.2495 172.0902 172.9308 173.7712 174.6080 175.4499\n#> 94% 174.1271 175.0931 176.0607 177.0282 177.9955 178.9654\n```\n:::\n\n\nAnd the values in `mu3.mean` and `mu3.CI` should be very similar (allowing for simulation variance) to what you got the automated way, using `rethinking::link()` in @lst-sum-dist-weight-a.\n\nKnowing this manual method is useful both for (1) understanding and (2) sheer power. Whatever the model you find yourself with, this approach can be used to generate posterior predictions for any component of it. Automated tools like link save effort, but they are never as flexible as the code you can write yourself.\n:::\n\n#### Tidyverse\n\nSince we used `weight_c` to fit our model, we might first want to understand what exactly the mean value is for weight.\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-mean-weight-b lst-cap=\"Calculate mean of weight\"}\n```{{r}}\n#| label: calc-mean-weight-b\n#| attr-source: '#lst-calc-mean-weight-b lst-cap=\"Calculate mean of weight\"'\n\nmean(d2_b$weight)\n```\n````\n\n```\n#> [1] 44.99049\n```\n:::\n\n\nJust a hair under 45. If we're interested in $\\mu$ at `weight` = 50, that implies we're also interested in $\\mu$ at `weight_c` + 5.01. Within the context of our model, we compute this with $\\alpha + \\beta \\cdot 5.01$. Here's what that looks like with `post_b`.\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-mean-weight-at-50-b lst-cap=\"Calculate the mean at weight 50 kg\"}\n```{{r}}\n#| label: calc-mean-weight-at-50-b\n#| attr-source: '#lst-calc-mean-weight-at-50-b lst-cap=\"Calculate the mean at weight 50 kg\"'\n\nmu_at_50_b <- \n  post_b %>% \n  transmute(mu_at_50_b = b_Intercept + b_weight_c * 5.01)\n```\n````\n\n```\n#> Warning: Dropping 'draws_df' class as required metadata was removed.\n```\n\n````{.cell-code #lst-calc-mean-weight-at-50-b lst-cap=\"Calculate the mean at weight 50 kg\"}\n```{{r}}\n#| label: calc-mean-weight-at-50-b\n#| attr-source: '#lst-calc-mean-weight-at-50-b lst-cap=\"Calculate the mean at weight 50 kg\"'\n\n \nhead(mu_at_50_b)\n```\n````\n\n```\n#> # A tibble: 6 × 1\n#>   mu_at_50_b\n#>        <dbl>\n#> 1       159.\n#> 2       159.\n#> 3       160.\n#> 4       160.\n#> 5       158.\n#> 6       160.\n```\n:::\n\n\nAnd here is a version McElreath’s Figure 4.8 density plot.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-density-vector-mean-50-b\n#| fig-cap: \"The quadratic approximate posterior distribution of the mean height, μ, when weight is 50 kg. This distribution represents the relative plausibility of different values of the mean. Tidyverse version\"\n\nmu_at_50_b %>%\n  ggplot(aes(x = mu_at_50_b)) +\n  geom_density(linewidth = 0, fill = \"deepskyblue\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(expression(mu[\"height | weight = 50\"])) +\n  theme_classic()\n```\n````\n\n::: {.cell-output-display}\n![The quadratic approximate posterior distribution of the mean height, μ, when weight is 50 kg. This distribution represents the relative plausibility of different values of the mean. Tidyverse version](04-geocentric-models_files/figure-html/fig-density-vector-mean-50-b-1.png){#fig-density-vector-mean-50-b width=672}\n:::\n:::\n\n\nWe’ll use `tidybayes::mean_hdi()` to get both 89% and 95% HPDIs along with the mean.\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-mean-and-HPDI-b lst-cap=\"Calculate both 89% and 95% Highest Priority Intensity Intervals (HPDIs) along with the mean.\"}\n```{{r}}\n#| label: calc-mean-and-HPDI-b\n#| attr-source: '#lst-calc-mean-and-HPDI-b lst-cap=\"Calculate both 89% and 95% Highest Priority Intensity Intervals (HPDIs) along with the mean.\"'\n\ntidybayes::mean_hdi(mu_at_50_b[, 1], .width = c(.89, .95))\n```\n````\n\n```\n#> # A tibble: 2 × 6\n#>   mu_at_50_b .lower .upper .width .point .interval\n#>        <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1       159.   159.   160.   0.89 mean   hdi      \n#> 2       159.   158.   160.   0.95 mean   hdi\n```\n:::\n\nIf you wanted to express those sweet 95% HPDIs on your density plot, you might use `tidybayes::stat_halfeye()`. Since `tidybayes::stat_halfeye()` also returns a point estimate, we’ll throw in the mode.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-half-eye-b\n#| fig-cap: \"Plot of half-eye (density + interval) geometry\"\nmu_at_50_b %>%\n  ggplot(aes(x = mu_at_50_b, y = 0)) +\n  tidybayes::stat_halfeye(point_interval = tidybayes::mode_hdi, .width = .95,\n               fill = \"deepskyblue\") +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(expression(mu[\"height | weight = 50\"])) +\n  theme_classic()\n```\n````\n\n::: {.cell-output-display}\n![Plot of half-eye (density + interval) geometry](04-geocentric-models_files/figure-html/fig-half-eye-b-1.png){#fig-half-eye-b width=672}\n:::\n:::\n\nWith {**brms**}, you would use fitted() to do what McElreath accomplished with `rethinking::link()`.\n\n::: {.callout-caution}\nKurz applies the function `fitted()` in the code, but in the text he uses twice `brms::fitted()` which doesn't exist. I used both `brms:::fitted.brmsfit()` and `stats::fitted()` to get the same results. \n\nThe object `b4.3` is of class `brmsfit` but in the help file of `stats::fitted()` you can read: \"`fitted` is a generic function which extracts fitted values from objects returned by modeling functions.  **All object classes which are returned by model fitting functions should provide a `fitted` method.** (emphasis is mine)\n\nMy interpretation therefore is that `stats::fitted()` is using `brms:::fitted.brmsfit()`. Thts why the results are identical.\n\n:::\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-mu-with-fitted-b lst-cap=\"Calculate μ for each case in the data and sample from the posterior distribution: Tidyverse version\"}\n```{{r}}\n#| label: calc-mu-with-fitted-b\n#| attr-source: '#lst-calc-mu-with-fitted-b lst-cap=\"Calculate μ for each case in the data and sample from the posterior distribution: Tidyverse version\"'\n\nmu2_b <- brms:::fitted.brmsfit(b4.3, summary = F)\nmu2.1_b <- stats::fitted(b4.3, summary = F)\nstr(mu2_b)\nstr(mu2.1_b)\n```\n````\n\n```\n#>  num [1:4000, 1:352] 157 157 157 158 156 ...\n#>  num [1:4000, 1:352] 157 157 157 158 156 ...\n```\n:::\n\n\nWhen you specify `summary = F`, `brms:::fitted.brmsfit()` returns a matrix of values with as many rows as there were post-warmup draws across your Hamilton Monte Carlo (HMC) chains and as many columns as there were cases in your analysis. Because we had 4,000 post-warmup draws and $n=352$, `brms:::fitted.brmsfit()` returned a matrix of 4,000 rows and 352 vectors. If you omitted the `summary = F` argument, the default is TRUE and `brms:::fitted.brmsfit()` will return summary information instead.\n\nMuch like `rethinking::link()`, `brms:::fitted.brmsfit()` can accommodate custom predictor values with its `newdata` argument.\n\n\n::: {.cell}\n\n````{.cell-code #lst-calc-dist-mu-unique-with-fitted.brmsfit-b lst-cap=\"Calculate a distribution of μ for each unique weight value on the horizontal axis: tidyverse version\"}\n```{{r}}\n#| label: calc-dist-mu-unique-with-fitted.brmsfit-b\n#| attr-source: '#lst-calc-dist-mu-unique-with-fitted.brmsfit-b lst-cap=\"Calculate a distribution of μ for each unique weight value on the horizontal axis: tidyverse version\"'\n\nweight_seq <- \n  tibble(weight = 25:70) %>% \n  mutate(weight_c = weight - mean(d2_b$weight))\n\nmu3_b <-\n  brms:::fitted.brmsfit(b4.3,\n         summary = F,\n         newdata = weight_seq) %>%\n  data.frame() %>%\n  # here we name the columns after the `weight` values from which they were computed\n  set_names(25:70) %>% \n  mutate(iter = 1:n())\n\nhead(mu3_b)\n```\n````\n\n```\n#>         25       26       27       28       29       30       31       32\n#> 1 136.3205 137.2465 138.1725 139.0985 140.0245 140.9505 141.8765 142.8025\n#> 2 136.8459 137.7155 138.5852 139.4549 140.3246 141.1943 142.0639 142.9336\n#> 3 136.1056 137.0420 137.9784 138.9148 139.8512 140.7876 141.7240 142.6604\n#> 4 136.8150 137.7457 138.6765 139.6073 140.5380 141.4688 142.3995 143.3303\n#> 5 136.1694 137.0518 137.9342 138.8166 139.6990 140.5814 141.4638 142.3462\n#> 6 137.2269 138.1342 139.0415 139.9488 140.8560 141.7633 142.6706 143.5779\n#>         33       34       35       36       37       38       39       40\n#> 1 143.7285 144.6545 145.5805 146.5065 147.4325 148.3585 149.2845 150.2105\n#> 2 143.8033 144.6730 145.5427 146.4123 147.2820 148.1517 149.0214 149.8911\n#> 3 143.5968 144.5332 145.4696 146.4060 147.3424 148.2788 149.2152 150.1516\n#> 4 144.2610 145.1918 146.1226 147.0533 147.9841 148.9148 149.8456 150.7763\n#> 5 143.2286 144.1110 144.9934 145.8758 146.7582 147.6405 148.5229 149.4053\n#> 6 144.4852 145.3925 146.2998 147.2071 148.1143 149.0216 149.9289 150.8362\n#>         41       42       43       44       45       46       47       48\n#> 1 151.1365 152.0625 152.9885 153.9145 154.8405 155.7665 156.6926 157.6186\n#> 2 150.7607 151.6304 152.5001 153.3698 154.2395 155.1092 155.9788 156.8485\n#> 3 151.0880 152.0243 152.9607 153.8971 154.8335 155.7699 156.7063 157.6427\n#> 4 151.7071 152.6379 153.5686 154.4994 155.4301 156.3609 157.2917 158.2224\n#> 5 150.2877 151.1701 152.0525 152.9349 153.8173 154.6997 155.5821 156.4645\n#> 6 151.7435 152.6508 153.5581 154.4654 155.3726 156.2799 157.1872 158.0945\n#>         49       50       51       52       53       54       55       56\n#> 1 158.5446 159.4706 160.3966 161.3226 162.2486 163.1746 164.1006 165.0266\n#> 2 157.7182 158.5879 159.4576 160.3272 161.1969 162.0666 162.9363 163.8060\n#> 3 158.5791 159.5155 160.4519 161.3883 162.3247 163.2611 164.1975 165.1339\n#> 4 159.1532 160.0839 161.0147 161.9454 162.8762 163.8070 164.7377 165.6685\n#> 5 157.3469 158.2293 159.1117 159.9941 160.8765 161.7589 162.6413 163.5237\n#> 6 159.0018 159.9091 160.8164 161.7237 162.6309 163.5382 164.4455 165.3528\n#>         57       58       59       60       61       62       63       64\n#> 1 165.9526 166.8786 167.8046 168.7306 169.6566 170.5826 171.5086 172.4346\n#> 2 164.6756 165.5453 166.4150 167.2847 168.1544 169.0241 169.8937 170.7634\n#> 3 166.0703 167.0067 167.9431 168.8795 169.8159 170.7523 171.6887 172.6251\n#> 4 166.5992 167.5300 168.4608 169.3915 170.3223 171.2530 172.1838 173.1145\n#> 5 164.4060 165.2884 166.1708 167.0532 167.9356 168.8180 169.7004 170.5828\n#> 6 166.2601 167.1674 168.0747 168.9820 169.8892 170.7965 171.7038 172.6111\n#>         65       66       67       68       69       70 iter\n#> 1 173.3606 174.2866 175.2126 176.1386 177.0646 177.9906    1\n#> 2 171.6331 172.5028 173.3725 174.2421 175.1118 175.9815    2\n#> 3 173.5615 174.4979 175.4343 176.3707 177.3071 178.2435    3\n#> 4 174.0453 174.9761 175.9068 176.8376 177.7683 178.6991    4\n#> 5 171.4652 172.3476 173.2300 174.1124 174.9948 175.8772    5\n#> 6 173.5184 174.4257 175.3330 176.2403 177.1475 178.0548    6\n```\n:::\n\n\nAnticipating {**ggplot2**}, we went ahead and converted the output to a data frame. But we might do a little more data processing with the aid of `tidyr::pivot_longer()`, which will convert the data from the wide format to the long format. \n\n::: callout-tip\n###### Literature references\n\nIf you are new to the distinction between wide and long data, you can learn more from the [Pivot data from wide to long](https://tidyr.tidyverse.org/reference/pivot_longer.html) vignette from the tidyverse team (2020); Simon Ejdemyr’s blog post, [Wide & long data](https://sejdemyr.github.io/r-tutorials/basics/wide-and-long/); or Karen Grace-Martin’s blog post, [The wide and long data format for repeated measures data](https://www.theanalysisfactor.com/wide-and-long-data/).\n:::\n\n\n::: {.cell}\n\n````{.cell-code #lst-convert-wide-to-long-b lst-cap=\"Data processing: Convert data from wide to long format: tidyverse version\"}\n```{{r}}\n#| label: convert-wide-to-long-b\n#| attr-source: '#lst-convert-wide-to-long-b lst-cap=\"Data processing: Convert data from wide to long format: tidyverse version\"'\n\nmu4_b <- \n  mu3_b %>%\n  pivot_longer(-iter,\n               names_to = \"weight\",\n               values_to = \"height\") %>% \n  # we might reformat `weight` to numerals\n  mutate(weight = as.numeric(weight))\n\nhead(mu4_b)\n```\n````\n\n```\n#> # A tibble: 6 × 3\n#>    iter weight height\n#>   <int>  <dbl>  <dbl>\n#> 1     1     25   136.\n#> 2     1     26   137.\n#> 3     1     27   138.\n#> 4     1     28   139.\n#> 5     1     29   140.\n#> 6     1     30   141.\n```\n:::\n\n\nNow our data processing is done, here we reproduce McElreath’s Figure 4.9.a.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-dist-mu-height-100-b\n#| fig-cap: \"The first 100 values in the distribution of μ at each weight value. Tidyverse version\"\nd2_b %>%\n  ggplot(aes(x = weight, y = height)) +\n  geom_point(data = mu4_b %>% filter(iter < 101), \n             color = \"navyblue\", alpha = .05) +\n  coord_cartesian(xlim = c(30, 65)) +\n  theme(panel.grid = element_blank())\n```\n````\n\n::: {.cell-output-display}\n![The first 100 values in the distribution of μ at each weight value. Tidyverse version](04-geocentric-models_files/figure-html/fig-dist-mu-height-100-b-1.png){#fig-dist-mu-height-100-b width=672}\n:::\n:::\n\nWith `brms:::fitted.brmsfit()`, it’s quite easy to plot a regression line and its intervals. Just omit the `summary = T` argument.\n\n\n::: {.cell}\n\n````{.cell-code #lst-sum-dist-weight-b lst-cap=\"Summary of the distribution for each weight value. Tidyverse version\"}\n```{{r}}\n#| label: sum-dist-weight-b\n#| attr-source: '#lst-sum-dist-weight-b lst-cap=\"Summary of the distribution for each weight value. Tidyverse version\"'\n\nmu_summary <-\n  brms:::fitted.brmsfit(b4.3, \n         newdata = weight_seq) %>%\n  data.frame() %>%\n  bind_cols(weight_seq)\n\nhead(mu_summary)\n```\n````\n\n```\n#>   Estimate Est.Error     Q2.5    Q97.5 weight  weight_c\n#> 1 136.5607 0.8782746 134.8478 138.2742     25 -19.99049\n#> 2 137.4631 0.8385116 135.8274 139.1020     26 -18.99049\n#> 3 138.3655 0.7989667 136.8134 139.9320     27 -17.99049\n#> 4 139.2680 0.7596740 137.7885 140.7732     28 -16.99049\n#> 5 140.1704 0.7206746 138.7764 141.6027     29 -15.99049\n#> 6 141.0728 0.6820190 139.7540 142.4244     30 -14.99049\n```\n:::\n\n\nHere it is, our analogue to Figure 4.9.b.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-summaries-on-data-top-b\n#| fig-cap: \"Plot of the summaries on top of the !Kung height data again, now with 89% compatibility interval of the mean indicated by the shaded region. Compare this region to the distributions of blue points in @fig-dist-mu-height-100-b.\"\n\n\nd2_b %>%\n  ggplot(aes(x = weight, y = height)) +\n  geom_smooth(data = mu_summary,\n              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),\n              stat = \"identity\",\n              fill = \"grey70\", color = \"black\", alpha = 1, linewidth = 1/2) +\n  geom_point(color = \"navyblue\", shape = 1, size = 1.5, alpha = 2/3) +\n  coord_cartesian(xlim = range(d2_b$weight)) +\n  theme(text = element_text(family = \"Times\"),\n        panel.grid = element_blank())\n```\n````\n\n::: {.cell-output-display}\n![Plot of the summaries on top of the !Kung height data again, now with 89% compatibility interval of the mean indicated by the shaded region. Compare this region to the distributions of blue points in @fig-dist-mu-height-100-b.](04-geocentric-models_files/figure-html/fig-summaries-on-data-top-b-1.png){#fig-summaries-on-data-top-b width=672}\n:::\n:::\n\n\nIf you wanted to use intervals other than the default 95% ones, you’d include the probs argument like this: `stats::fitted(b4.3, newdata = weight.seq, probs = c(.25, .75))`. The resulting third and fourth vectors from the `fitted()` object would be named `Q25` and `Q75` instead of the default `Q2.5` and `Q97.5`. The [Q prefix](https://github.com/paul-buerkner/brms/issues/425) stands for quantile.\n\nSimilar to `rethinking::link()`, `stats::fitted()` uses the formula from your model to compute the model expectations for a given set of predictor values. I use it a lot in this project. If you follow along, you’ll get a good handle on it. But to dive deeper, you can [go here for the documentation](https://rdrr.io/cran/brms/man/fitted.brmsfit.html). Though we won’t be using it in this project, {**brms**} users might want to know that fitted() is also an alias for the `brms::posterior_epred()` function, about which you might [learn more here](https://rdrr.io/cran/brms/man/posterior_epred.brmsfit.html). Users can always learn more about them and other functions in the [{**brms**} reference manual](https://cran.r-project.org/web/packages/brms/brms.pdf).\n\n## I STOPPED THIS CHAPTER HERE! (2023-08-11)\n",
    "supporting": [
      "04-geocentric-models_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}