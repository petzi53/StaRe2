{
  "hash": "b76faac82155811413b787e3b7e4ac36",
  "result": {
    "markdown": "# Sampling the Imaginary {#sec-chap03}\n\n:::::{.my-objectives}\n:::{.my-objectives-header}\nLearning Objectives:\n:::\n::::{.my-objectives-container}\n\nThis chapter teaches the basic skills for working with samples from the\nposterior distribution. We'll begin to use samples to summarize and\nsimulate model output. The skills learned here will apply to every\nproblem in the remainder of the book, even though the details of the\nmodels and how the samples are produced will vary.\n\nThe chapter exploits the fact that people are better in counts than in\nprobabilities. We will take the probability distributions from the\nprevious chapter and sampling from them to produce counts.\n::::\n:::::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.2     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n:::\n\n\n## Vampire Example {.unnumbered}\n\n### ORIGINAL {.unnumbered}\n\n:::::{.my-definition}\n:::{.my-definition-header}\n:::::: {#def-chap-03-1}\n: Probability Notation\n::::::\n:::\n::::{.my-definition-container}\nAs a repetition and to get a better understanding of the following formulae in this section I read a very [basic introduction into probability notation]((https://www.mathsisfun.com/data/probability-events-conditional.html))\n\n$P(A)$ means \"**Probability Of Event A**\".\n\n:::::{.my-example}\n:::{.my-example-header}\nProbability of an Event\n:::\n::::{.my-example-container}\nWhat is the probability of $2$ after throwing a dice?\n$$P(A) = \\frac{1}{6}$$\n::::\n:::::\n\n$P(B \\mid A)$ means \"**Probability of Event B given A**\". \n\nThis is a conditional probability. After event $A$ has happened, what is the probability of $B$? If the events are independent from each other than the changes do not influence each other. \n\n:::::{.my-example}\n:::{.my-example-header}\nIndependent Conditional Events\n:::\n::::{.my-example-container}\n\nThe probability to throw $2$ in a second dice throw are still $P(B \\mid A) = \\frac{1}{6}$. If the events are dependent of each other then \"Probability of event A and event B equals the probability of event A times the probability of event B given event A.\"\n\n$$\nP(A \\space and\\space B) = P(A) \\times P(B \\mid A)\n$$\n\n\n::::\n:::::\n\n:::::{.my-example}\n:::{.my-example-header}\nDependent Conditional Events\n:::\n::::{.my-example-container}\n    \nTypical example is removing marble from a bag without replacement. Let's take a red marble from a bag of $5$ red and $5$ blue marbles without replacement. Here the probability of a red marble (in the second draw) given the probability of a red marble (in the first draw) is\n\n$$\n\\frac{5}{10} \\times \\frac{4}{9} = \\frac{2}{9}\n$$\n\n::::\n:::::\n::::\n:::::\n\n\n#### a) Medical Test Scenario with Bayes theorem {.unnumbered}\n\n> “suppose there is a blood test that correctly detects vampirism 95% of the time. In more precise and mathematical notation, $Pr(\\text{positive test result} \\mid vampire) = 0.95$. It’s a very accurate test, nearly always catching real vampires. It also make mistakes, though, in the form of false positives. One percent of the time, it incorrectly diagnoses normal people as vampires, $Pr(\\text{positive test result}|mortal) = 0.01$. The final bit of information we are told is that vampires are rather rare, being only $0.1\\%$ of the population, implying $Pr(vampire) = 0.001$. Suppose now that someone tests positive for vampirism. What’s the probability that he or she is a bloodsucking immortal?” ([McElreath, 2020, p. 49](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=68&annotation=W9MU6VCZ))\n\n> “The correct approach is just to use Bayes’ theorem to invert the probability, to compute $Pr(vampire|positive)$. The calculation can be presented as:\n\n$$\n\\begin{align*}\nPr(vampire\\mid positive) = \\frac{Pr(positive\\mid vampire) Pr(vampire)}{Pr(positive)}\\\\\n\\text{where Pr(positive) is the average probability of a positive test result, that is,}\\\\ Pr(positive) = Pr(positive \\mid vampire) Pr(vampire) \\\\\n+ Pr(positive \\mid mortal) 1 − Pr(vampire)\n\\end{align*}\n$$ {#eq-vampire}\n” ([McElreath, 2020, p. 49](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=68&annotation=X4KD33AT))\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-vampire-bayes-a}\na: Performing vampire calculation with <a class='glossary' title='This is the theorem that gives Bayesian data analysis its name. But the theorem itself is a trivial implication of probability theory. The mathematical definition of the posterior distribution arises from Bayes’ Theorem. The key lesson is that the posterior is proportional to the product of the prior and the probability of the data. (Chap.2)'>Bayes’ theorem</a> in Base R\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.1a Vampire ##################\nPr_Positive_Vampire_a <- 0.95\nPr_Positive_Mortal_a <- 0.01\nPr_Vampire_a <- 0.001\nPr_Positive_a <- Pr_Positive_Vampire_a * Pr_Vampire_a +\n  Pr_Positive_Mortal_a * (1 - Pr_Vampire_a)\n\n( \n  Pr_Vampire_Positive_a <- Pr_Positive_Vampire_a * Pr_Vampire_a / Pr_Positive_a\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.08683729\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\nThere is only an 0.0868373% chance that the suspect is actually a vampire.\n\n> “Most people find this result counterintuitive. And it’s a very important result, because it mimics the structure of many realistic testing contexts, such as HIV and DNA testing, criminal profiling, and even statistical significance testing (see the Rethinking box at the end of this section). Whenever the condition of interest is very rare, having a test that finds all the true cases is still no guarantee that a positive result carries much information at all. The reason is that most positive results are false positives, even when all the true positives are detected correctly” ([McElreath, 2020, p. 49](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=68&annotation=CMMR49PQ))\n\n#### b) Medical test scenario with natural frequencies {.unnumbered}\n\n> “There is a way to present the same problem that does make it more intuitive” ([McElreath, 2020, p. 50](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=69&annotation=2DWF7729))\n\n```         \n(1)  In a population of 100,000 people, 100 of them are vampires.\n(2)  Of the 100 who are vampires, 95 of them will test positive for vampirism.\n(3)  Of the 99,900 mortals, 999 of them will test positive for vampirism.\n```\n\nThere are 999 + 95 = 1094 people tested positive. But from these\npeople only 95 / (999 + 95) = 8.6837294 % are actually\nvampires.\n\nOr with a slightly different wording it is still easier to\nunderstand: \n\n1. We can just count up the number of people who test positive: $95 + 999 = 1094$. \n2. Out of these $1094$ positive tests, $95$ of them are real vampires, so that implies:\n\n$$\nPr(positive \\mid vampire) = \\frac{95}{1094}\n$$\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-vampire-frequencies-a}\na: Performing vampire calculation with frequencies in Base R\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\npr_vampire_a2 <-  100 / 100000\npr_positive_vampire_a2 <-  95 / 100\npr_positive_mortal_a2  <-  999 / 99900\npr_positive_a2 <-  95 + 999\n\n(\n  pr_vampire_positive_a2 <-  \n    pr_positive_vampire_a2 * 100 / pr_positive_a2\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.08683729\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\n\n> “The second presentation of the problem, using counts rather than probabilities, is often called the frequency format or natural frequencies. Why a frequency format helps people intuit the correct approach remains contentious. Some people think that human psychology naturally works better when it receives information in the form a person in a natural environment would receive it. In the real world, we encounter counts only. No one has ever seen a probability, the thinking goes. But everyone sees counts (“frequencies”) in their daily lives.” ([McElreath, 2020, p. 50](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=69&annotation=G26ZTDUZ))\n\n\n> “many scientists are uncomfortable with integral calculus, even though they have strong and valid intuitions about how to summarize data. Working with samples transforms a problem in calculus into a problem in data summary, into a frequency format problem. An integral in a typical Bayesian context is just the total probability in some interval. That can be a challenging calculus problem. But once you have samples from the probability distribution, it’s just a matter of counting values in the interval. An empirical attack on the posterior allows the scientist to ask and answer more questions about the model, without relying upon a captive mathematician. For this reason, it is easier and more intuitive to work with samples from the posterior, than to work with probabilities and integrals directly.” ([McElreath, 2020, p. 51](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=70&annotation=M7I2DV3C))\n\n### TIDYVERSE {.unnumbered}\n\n#### a) Medical Test Scenario with Bayes theorem {.unnumbered}\n\n\n:::::{.my-important}\n:::{.my-important-header}\nVectors in Base R are tibble columns in tidyverse\n:::\n::::{.my-important-container}\nWhenever there is a calculation with vectors the pendant in tidyverse mode is to generate columns in a tibble with `tibble::tibble()` or if there is already a data frame with `dplyr::mutate()` and to do the appropriate calculation with these columns.\n\nThe following @cnj-vampire-bayes-a transformed the Base R calculation @cnj-vampire-bayes-b into a computation using the tidyverse approach.\n::::\n:::::\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-vampire-bayes-b}\nb: Performing the calculation using Bayes’ theorem with tidyverse approach in R\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.1b Vampire ##########\n\ntibble::tibble(pr_positive_vampire_b = .95,\n       pr_positive_mortal_b  = .01,\n       pr_vampire_b          = .001) |> \n  dplyr::mutate(pr_positive_b = pr_positive_vampire_b * pr_vampire_b\n         + pr_positive_mortal_b * (1 - pr_vampire_b)) |> \n  dplyr::mutate(pr_vampire_positive_b = \n           pr_positive_vampire_b * pr_vampire_b / pr_positive_b) |> \n  dplyr::glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Rows: 1\n#> Columns: 5\n#> $ pr_positive_vampire_b <dbl> 0.95\n#> $ pr_positive_mortal_b  <dbl> 0.01\n#> $ pr_vampire_b          <dbl> 0.001\n#> $ pr_positive_b         <dbl> 0.01094\n#> $ pr_vampire_positive_b <dbl> 0.08683729\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\n#### b) Medical test scenario with natural frequencies {.unnumbered}\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-vampire-frequencies-b}\nb: Performing the calculation using frequencies with tidyverse approach in R\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble::tibble(pr_vampire_b2          = 100 / 100000,\n       pr_positive_vampire_b2 = 95 / 100,\n       pr_positive_mortal_b2  = 999 / 99900)  |>  \n  dplyr::mutate(pr_positive_b2 = 95 + 999) |> \n  dplyr::mutate(pr_vampire_positive_b2 = \n                  pr_positive_vampire_b2 * 100 / pr_positive_b2) |> \n  dplyr::glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Rows: 1\n#> Columns: 5\n#> $ pr_vampire_b2          <dbl> 0.001\n#> $ pr_positive_vampire_b2 <dbl> 0.95\n#> $ pr_positive_mortal_b2  <dbl> 0.01\n#> $ pr_positive_b2         <dbl> 1094\n#> $ pr_vampire_positive_b2 <dbl> 0.08683729\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\n## Sampling from a grid-approximate posterior {#sec-chap-03-sampling-grid}\n\n### ORIGINAL\n\nBefore we are going to draw samples from the posterior distribution we\nneed to compute the distribution similar as we had done in the globe tossing example.\n\n> “Here’s a reminder for how to compute the posterior for the globe tossing model, using grid approximation. Remember, the posterior here means the probability of p conditional on the data.” ([McElreath, 2020, p. 52](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=71&annotation=KKQLR3FL))\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-grid-globe-tossing-a}\na: Generate the posterior distribution form the globe-tossing example (Base R)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### R code 3.2a Grid Globe ##########################\n# change prob_b to prior\n# change prob_data to likelihood\n# added variables: n_grid_a, n_success_a, n_trials_a\n\nn_grid_a <- 1000L # number of grid points\nn_success_a <- 6L # observed water\nn_trials_a <-  9L # number of trials\n\n\np_grid_a <- seq(from = 0, to = 1, length.out = n_grid_a)\nprior_a <- rep(1, n_grid_a) # = prior, = uniform distribution, 1000 times 1\nlikelihood_a <- \n  dbinom(n_success_a, size = n_trials_a, prob = p_grid_a) # = likelihood\nposterior_a <- likelihood_a * prior_a\nposterior_a <- posterior_a / sum(posterior_a)\n```\n:::\n\n\n::::\n:::::\n\n> “Now we wish to draw 10,000 samples from this posterior. Imagine the posterior is a bucket full of parameter values, numbers such as $0.1, 0.7, 0.5, 1,$ etc. Within the bucket, each value exists in proportion to its posterior probability, such that values near the peak are much more common than those in the tails. We’re going to scoop out 10,000 values from the bucket. Provided the bucket is well mixed, the resulting samples will have the same proportions as the exact posterior density. Therefore the individual values of $p$ will appear in our samples in proportion to the posterior plausibility of each value.” ([McElreath, 2020, p. 52](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=71&annotation=GS5GCASA))\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-sample-globe-tossing}\na: Draw 1000 samples from the posterior distribution (Base R)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_samples_a <- 1e4\n\nset.seed(3) # for reproducibility\n\n## R code 3.3a Sample Globe ##########################################\nsamples_a <- sample(p_grid_a, \n                    prob = posterior_a, # from previous code chunk\n                    size = n_samples_a, replace = TRUE)\n```\n:::\n\n\n::::\n:::::\n\nThe probability of each value is given by `posterior_a`, which we computed with @cnj-grid-globe-tossing-a.\n\n:::::{.my-note}\n:::{.my-note-header}\n:::::: {#cor-excursion-a}\n: Details for a better understanding and comparison with the tidyverse version\n::::::\n:::\n::::{.my-note-container}\n\nTo compare with the tidyverse version, I collected the three vectors with `base::cbind()` into a matrix and displayed the first six lines with `utils::head()`. Additionally I\nalso displayed the first 10 values of `samples_a` vector.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-excursion-a}\na: Excursion for better comparison (Base R)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# display grid results to compare with variant b\nd_a <- cbind(p_grid_a, prior_a, likelihood_a, posterior_a) \nhead(d_a, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>          p_grid_a prior_a likelihood_a  posterior_a\n#>  [1,] 0.000000000       1 0.000000e+00 0.000000e+00\n#>  [2,] 0.001001001       1 8.425225e-17 8.433659e-19\n#>  [3,] 0.002002002       1 5.375951e-15 5.381333e-17\n#>  [4,] 0.003003003       1 6.105137e-14 6.111249e-16\n#>  [5,] 0.004004004       1 3.419945e-13 3.423368e-15\n#>  [6,] 0.005005005       1 1.300676e-12 1.301978e-14\n#>  [7,] 0.006006006       1 3.872087e-12 3.875963e-14\n#>  [8,] 0.007007007       1 9.734489e-12 9.744233e-14\n#>  [9,] 0.008008008       1 2.162473e-11 2.164638e-13\n#> [10,] 0.009009009       1 4.370695e-11 4.375070e-13\n```\n\n\n:::\n\n```{.r .cell-code}\n# display sample results to compare with variant b\nhead(samples_a, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  [1] 0.5645646 0.6516517 0.5475475 0.5905906 0.5955956 0.7877878 0.7267267\n#>  [8] 0.4914915 0.7507508 0.4494494\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n\n\n::::\n:::::\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-globe-glossing-scatterplot-a}\na: Scatterplot of the drawn samples (Base R)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.4a Globe Scatterplot #############\nplot(samples_a)\n```\n\n::: {.cell-output-display}\n![Scatterplot of the drawn samples (Base R)](03-sampling-the-imaginary_files/figure-html/fig-globe-tossing-scatterplot-a-1.png){#fig-globe-tossing-scatterplot-a width=672}\n:::\n:::\n\n\n::::\n:::::\n\n\n> In fig-globe-glossing-plot-a “it’s as if you are flying over the posterior distribution, looking down on it. There are many more samples from the dense region near 0.6 and very few samples below 0.25. On the right, the plot shows the density estimate computed from these samples.” ([McElreath, 2020, p. 53](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=72&annotation=4WVLNZBT))\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-globe-tossing-density-plot-a}\na: Density estimate of the drawn samples (Rethinking)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.5a Globe Density plot #############\nrethinking::dens(samples_a)\n```\n\n::: {.cell-output-display}\n![Density estimate of the drawn samples (Rethinking)](03-sampling-the-imaginary_files/figure-html/fig-globe-tossing-density-plot-a-1.png){#fig-globe-tossing-density-plot-a width=672}\n:::\n:::\n\n\n\n::::\n:::::\n\n\n### TIDYVERSE\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-grid-globe-tossing-b}\nb: Generate the posterior distribution form the globe-tossing example (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.2b Grid Globe #####################\n\n# how many grid points would you like?\nn_grid_b <- 1000L\nn_success_b <- 6L\nn_trials_b  <- 9L\n\n(\n  d_b <-\n  tibble::tibble(p_grid_b = seq(from = 0, to = 1, length.out = n_grid_b),\n         prior_b  = 1) |>  # flat uniform prior, vector 1L recycling\n  dplyr::mutate(likelihood_b = \n                  dbinom(n_success_b, size = n_trials_b, prob = p_grid_b)) |> \n  dplyr::mutate(posterior_b = \n                  (likelihood_b * prior_b) / sum(likelihood_b * prior_b))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1,000 × 4\n#>    p_grid_b prior_b likelihood_b posterior_b\n#>       <dbl>   <dbl>        <dbl>       <dbl>\n#>  1  0             1     0           0       \n#>  2  0.00100       1     8.43e-17    8.43e-19\n#>  3  0.00200       1     5.38e-15    5.38e-17\n#>  4  0.00300       1     6.11e-14    6.11e-16\n#>  5  0.00400       1     3.42e-13    3.42e-15\n#>  6  0.00501       1     1.30e-12    1.30e-14\n#>  7  0.00601       1     3.87e-12    3.88e-14\n#>  8  0.00701       1     9.73e-12    9.74e-14\n#>  9  0.00801       1     2.16e-11    2.16e-13\n#> 10  0.00901       1     4.37e-11    4.38e-13\n#> # ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\nVariable names changed\n:::\n::::{.my-watch-out-container}\nI have changed McElreath's variable name `prob_p` and `prob_data` as `prior_x` and\n`likelihood_x`, where `x` stands for `a` (Base R) or `b` (Tidyverse).\n\nTo see the difference between grid and samples I will add \"\\_sample\" to all the other variable names.\n::::\n:::::\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-sample-globe-tossing-b}\nb: Draw 1000 samples from the posterior distribution (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.3b Sample Globe #####################\n# how many samples would you like?\nn_samples_b <- 1e4\n\n# make it reproducible\nset.seed(3)\n\ndf_samples_b <-\n  d_b |> \n    dplyr::slice_sample(n = n_samples_b, weight_by = posterior_b, replace = T)\n\n( \n  df_samples_b <- df_samples_b |>\n      dplyr::rename(samples_b = p_grid_b,\n             likelihood_samples_b = likelihood_b,\n             prior_samples_b = prior_b,\n             posterior_samples_b = posterior_b)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 10,000 × 4\n#>    samples_b prior_samples_b likelihood_samples_b posterior_samples_b\n#>        <dbl>           <dbl>                <dbl>               <dbl>\n#>  1     0.565               1                0.225             0.00225\n#>  2     0.652               1                0.272             0.00272\n#>  3     0.548               1                0.210             0.00210\n#>  4     0.591               1                0.245             0.00245\n#>  5     0.596               1                0.248             0.00248\n#>  6     0.788               1                0.192             0.00192\n#>  7     0.727               1                0.253             0.00253\n#>  8     0.491               1                0.156             0.00156\n#>  9     0.751               1                0.233             0.00233\n#> 10     0.449               1                0.116             0.00116\n#> # ℹ 9,990 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nidentical(samples_a, df_samples_b$samples_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] TRUE\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n\nThe column `samples_b` is identical with vector `samples_a`, because I have used in both sampling processes `set.seed(3)`, so that I (and you) could reproduce the data. \n\n\nThere are different possibilities to display data frames respectively tibbles:\n\n1. You can use the internal print facility of tibbles. It shows only the first ten rows and all columns that fit on the screen. You see an example in @cnj-sample-globe-tossing-b.\n2. With the `utils::str()` function you will get a result with shorter figures that is better adapted to a small screen.\n3. Another alternative is the tidyverse approach of `dplyr::glimpse()`.\n4. With `skimr::skim()` you will get a compact summary of all data.\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-excursion-b}\nb: Excursion: Printing varieties for better comparison (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglue::glue('USING THE str() FUNCTION:')\nutils::str(df_samples_b)\nglue::glue('#####################################################\\n\\n')\nglue::glue('USING THE dplyr::glimpse() FUNCTION:')\ndplyr::glimpse(df_samples_b)\nglue::glue('#####################################################\\n\\n')\nglue::glue('USING THE skimr::skim() FUNCTION:')\nskimr::skim(df_samples_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> USING THE str() FUNCTION:\n#> tibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n#>  $ samples_b           : num [1:10000] 0.565 0.652 0.548 0.591 0.596 ...\n#>  $ prior_samples_b     : num [1:10000] 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ likelihood_samples_b: num [1:10000] 0.225 0.272 0.21 0.245 0.248 ...\n#>  $ posterior_samples_b : num [1:10000] 0.00225 0.00272 0.0021 0.00245 0.00248 ...\n#> #####################################################\n#> \n#> USING THE dplyr::glimpse() FUNCTION:\n#> Rows: 10,000\n#> Columns: 4\n#> $ samples_b            <dbl> 0.5645646, 0.6516517, 0.5475475, 0.5905906, 0.595…\n#> $ prior_samples_b      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#> $ likelihood_samples_b <dbl> 0.22455994, 0.27190272, 0.20966655, 0.24460869, 0…\n#> $ posterior_samples_b  <dbl> 0.0022478473, 0.0027217490, 0.0020987643, 0.00244…\n#> #####################################################\n#> \n#> USING THE skimr::skim() FUNCTION:\n```\n\n\n:::\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |             |\n|:------------------------|:------------|\n|Name                     |df_samples_b |\n|Number of rows           |10000        |\n|Number of columns        |4            |\n|_______________________  |             |\n|Column type frequency:   |             |\n|numeric                  |4            |\n|________________________ |             |\n|Group variables          |None         |\n\n\n**Variable type: numeric**\n\n|skim_variable        | n_missing| complete_rate| mean|   sd|   p0|  p25|  p50|  p75| p100|hist  |\n|:--------------------|---------:|-------------:|----:|----:|----:|----:|----:|----:|----:|:-----|\n|samples_b            |         0|             1| 0.64| 0.14| 0.15| 0.55| 0.65| 0.74| 0.97|▁▂▇▇▂ |\n|prior_samples_b      |         0|             1| 1.00| 0.00| 1.00| 1.00| 1.00| 1.00| 1.00|▁▁▇▁▁ |\n|likelihood_samples_b |         0|             1| 0.20| 0.07| 0.00| 0.16| 0.23| 0.26| 0.27|▁▁▂▃▇ |\n|posterior_samples_b  |         0|             1| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00| 0.00|▁▁▂▃▇ |\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\nWe can plot the left panel of Figure 3.1 from the book with `ggplot2::geom_point()`. But before we do, we'll need to add a variable numbering the samples. This is necessary as the x-parameter of the plot.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-globe-tossing-scatterplot-b}\nb: Scatterplot of the drawn samples (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.4b Globe Scatterplot ########################\ndf_samples_b |> \n  dplyr::mutate(sample_number = 1:dplyr::n()) |> \n  \n  ggplot2::ggplot(ggplot2::aes(x = sample_number, y = samples_b)) +\n  ggplot2::geom_point(alpha = 1/10) +\n  ggplot2::scale_y_continuous(\"proportion of water (p)\", limits = c(0, 1)) +\n  ggplot2::xlab(\"sample number\") +\n  ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![Scatterplot of the drawn samples (Tidyverse)](03-sampling-the-imaginary_files/figure-html/fig-globe-tossing-scatterplot-b-1.png){#fig-globe-tossing-scatterplot-b width=672}\n:::\n:::\n\n\n\n::::\n:::::\n\n\nIf you hover over this link from @fig-globe-tossing-scatterplot-a you can compare the Base R version with the tidyverse result.\n\nInstead of the `rethinking::dens()` we'll plot the density in the right panel of the books Figure 3.1 with `ggplot2::geom_density()`.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-globe-tossing-densitiy-plot-b1}\nb: Density estimate of the drawn samples with 1e4 grid points (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.5b(1) Globe Density ###########################\ndf_samples_b |> \n  ggplot2::ggplot(ggplot2::aes(x = samples_b)) +\n  ggplot2::geom_density(fill = \"grey\") +\n  ggplot2::scale_x_continuous(\"proportion of water (p)\", limits = c(0, 1)) +\n  ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![Density estimate of the drawn samples with 1e4 grid points (Tidyverse)](03-sampling-the-imaginary_files/figure-html/fig-globe-tossing-density-plot-b1-1.png){#fig-globe-tossing-density-plot-b1 width=672}\n:::\n:::\n\n\n::::\n:::::\n\n\nCompare this somewhat smoother tidyverse plot with @fig-globe-tossing-density-plot-a.\n\n> “You can see that the estimated density is very similar to ideal posterior you computed via grid approximation. If you draw even more samples, maybe 1e5 or 1e6, the density estimate will get more and more similar to the ideal.” ([McElreath, 2020, p. 53](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=72&annotation=EXBQWX2M))\n \nHere's what it looks like with `1e6`.\n \n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-ID-text}\nb: Density estimate of the drawn samples with 1e6 grid points (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3)\n\n## R code 3.5b(2) Globe Density ###########################\nd_b |> \n  dplyr::slice_sample(n = 1e6, weight_by = posterior_b, replace = T) |>\n  \n  ggplot2::ggplot(ggplot2::aes(x = p_grid_b)) +\n  ggplot2::geom_density(fill = \"grey\") +\n  ggplot2::scale_x_continuous(\"proportion of water (p)\", limits = c(0, 1)) +\n  ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![Density estimate of the drawn samples with 1e6 grid points (Tidyverse)](03-sampling-the-imaginary_files/figure-html/fig-globe-tossing-density-plot-b2-1.png){#fig-globe-tossing-density-plot-b2 width=672}\n:::\n:::\n\n\n\n::::\n:::::\n\n## Sampling to Summarize {#sec-sampling-to-summarize}\n\nAll we have done so far is crudely replicate the posterior density we\nhad already computed in the previous chapter. Now it is time to use\nthese samples to describe and understand the posterior.\n\nThe description to understand the posterior can be divided into three inquiries:\n\n1.  Questions about intervals of *defined boundaries*. See @sec-chap-03-defined-boundaries.\n2.  Questions about intervals of *defined probability mass*. See @sec-chap-03-probability-mass.\n3.  Questions about *point estimates*. See: @sec-chap-03-point-estimates.\n\n### Intervals of Defined Boundaries {#sec-chap-03-defined-boundaries}\n\n#### ORIGINAL\n\n##### Grid-approximate Posterior\n\nFor instance: What is the probability that the proportion of water is\nless than 0.5?\n\n> “Using the grid-approximate posterior, you can just add up all of the probabilities, where the corresponding parameter value is less than 0.5:” ([McElreath, 2020, p. 53](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=72&annotation=Z7XSZ6WT))\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-grid-posterior-a}\na: Define boundaries using the grid-approximate posterior (Base R)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.6a Grid Posterior Boundary ##############################\n# add up posterior probability where p < 0.5\nsum(posterior_a[p_grid_a < 0.5])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.1718746\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\nAbout 17% of the posterior probability is below 0.5. \n\n##### Samples from the Posterior\n\nBut this easy calculation based on grid approximation is often not\npractical when there are more parameters. In this case you can draw samples from the posterior. But this approach requires a different calculation:\n\n\n> “This approach does generalize to complex models with many parameters, and so you can use it everywhere. All you have to do is similarly add up all of the samples below 0.5, but also // divide the resulting count by the total number of samples. In other words, find the frequency of parameter values below 0.5” (McElreath, 2020, p. 53/54)” ([McElreath, 2020, p. 53](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=72&annotation=SMQ6B78K))\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-sample-boundary-a}\na: Compute posterior probability below 0.5 using the sampling approach (Base R)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.7a Sample Boundary #############################\n(p_boundary_a <- sum(samples_a < 0.5) / 1e4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.1629\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\nDifferent values with samples from the posterior\n:::\n::::{.my-watch-out-container}\nIn comparison with the value of the posterior probability below 0.5 in the book of 0.1726 the result in 0.1629 from @cnj-sample-boundary-a is quite different. \n\nThe reason for the difference is that you can't get the same values in a\nsampling processes. This is the nature of randomness. And McElreath did\nnot include the `set.seed()` function for (exact) reproducibility. \n::::\n:::::\n\nUsing the same approach, you can ask how much posterior probability lies\nbetween 0.5 and 0.75:\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-sample-interval-a}\na: Compute posterior probability between 0.5 and 0.75 using the sampling approach (Base R)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.8a Sample Interval #############################\n(p_boundary_a8 <- sum(samples_a > 0.5 & samples_a < 0.75) / 1e4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.6061\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\n\n#### TIDYVERSE\n\n##### Grid-approximate Posterior\n\n> To get the proportion of water less than some value of `p_grid_b`\n> within the {**tidyverse}**, you might first `filter()` by that value\n> and then take the `sum()` within `summarise()`. ([Kurz](https://bookdown.org/content/4857/sampling-the-imaginary.html#intervals-of-defined-boundaries.))\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-grid-boundary-b}\nb: Compute posterior probability below 0.5 using the grid approach (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.6b Grid Boundary ######################\n# add up posterior probability where p < 0.5\nd_b |> dplyr::filter(p_grid_b < 0.5) |> \n    dplyr::summarize(sum = base::sum(posterior_b))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.172\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\n##### Samples from the Posterior\n\nKurz offers several methods to calculate the posterior probability below 0.5: \n\n1. **Method**: `filter()` & `n()` within `summarize()`\n2. **Method**: `count()` followed by `mutate()`\n3. **Method**: Logical condition within `mean()`\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-sample-boundary}\nb: Compute posterior probability below 0.5 using the sampling approach with different methods (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\n# add up all posterior probabilities of samples under .5\n## R code 3.7b Sample Boundary #########################\n\n###### Method (1) #######\nmethod_1 <- \n  df_samples_b |> \n      dplyr::filter(samples_b < .5) |> \n      dplyr::summarize(sum = dplyr::n() / n_samples_b)\n\nglue::glue('Method 1:\\n')\nmethod_1\nglue::glue('##################################################\\n\\n')\n\n###### Method (2) #######\nmethod_2 <- \n  df_samples_b |> \n    dplyr::count(samples_b < .5) |> \n    dplyr::mutate(probability = n_samples_b / base::sum(n_samples_b))\n\nglue::glue('Method 2:\\n')\nmethod_2\nglue::glue('##################################################\\n\\n')\n\n###### Method (3) #######\nmethod_3 <- \n  df_samples_b |> \n      dplyr::summarize(sum = mean(samples_b < .5))\n\nglue::glue('Method 3:\\n')\nmethod_3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Method 1:\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.163\n#> ##################################################\n#> \n#> Method 2:\n#> # A tibble: 2 × 3\n#>   `samples_b < 0.5`     n probability\n#>   <lgl>             <int>       <dbl>\n#> 1 FALSE              8371           1\n#> 2 TRUE               1629           1\n#> ##################################################\n#> \n#> Method 3:\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.163\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n\nTo determine the posterior probability between 0.5 and 0.75, you can use\n`&` within `filter()`. Just multiply that result by 100 to get the value\nin percent.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-sample-interval-b}\nb: Compute posterior probability between 0.5 and 0.75 using the sampling approach (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.8b Sample Interval ##############\ndf_samples_b |> \n    dplyr::filter(samples_b > .5 & samples_b < .75) |> \n    dplyr::summarize(sum = dplyr::n() / n_samples_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.606\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n\nAnd, of course, you can do this calculation with the other methods as well.\n\n\n\nTo produce the top part of Figure 3.2 of the book we apply following code lines:\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-fig-upper-part-3-2}\nb: Posterior distribution produced with {**tidyverse**} approach\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R Code Fig 3.2 Upper Part #############\n# upper left panel\np1 <-\n  df_samples_b  |>  \n  ggplot2::ggplot(ggplot2::aes(x = samples_b, y = posterior_samples_b)) +\n  ggplot2::geom_line() +\n  ggplot2::geom_area(data = df_samples_b  |>  \n         dplyr::filter(samples_b < .5), fill = \"deepskyblue\") +\n  ggplot2::labs(x = \"proportion of water (p)\", y = \"density\")  +\n  ggplot2::theme_bw()\n\n# upper right panel\np2 <- \n  df_samples_b  |>  \n  ggplot2::ggplot(ggplot2::aes(x = samples_b, y = posterior_samples_b)) +\n  ggplot2::geom_line() +\n  ggplot2::geom_area(data = df_samples_b  |>  \n         dplyr::filter(samples_b > .5 & samples_b < .75), fill = \"deepskyblue\") +\n  ggplot2::labs(x = \"proportion of water (p)\", y = \"density\") +\n  ggplot2::theme_bw()\n\nlibrary(patchwork)\np1 + p2\n```\n\n::: {.cell-output-display}\n![Upper part of SR2 Figure 3.2: Intervals of defined boundaries produced with {**tidyverse**} tools: Left: The blue area is the posterior probability below a parameter value of 0.5. Right: The posterior probability between 0.5 and 0.75.](03-sampling-the-imaginary_files/figure-html/fig-upper-part-3.2-b-1.png){#fig-upper-part-3.2-b width=672}\n:::\n:::\n\n\n\n::::\n:::::\n\n### Intervals of Defined Probability Mass {#sec-chap-03-probability-mass}\n\n#### ORIGINAL\n\n##### Quantiles\n\n:::::{.my-definition}\n:::{.my-definition-header}\n:::::: {#def-probability-mass-intervals}\n: Several Terms for Intervals of Defined Probability Mass\n::::::\n:::\n::::{.my-definition-container}\n- <a class='glossary' title='A range of values, calculated from the sample observations, that is believed, with a particular probability, to contain the true parameter value. (Cambridge Dictionary of Statistics, 4th ed., p.98)'>Confidence Interval</a>: Term chiefly used in frequentist statistics.\n- <a class='glossary' title='Two parameter values that contain between them a specified amount of posterior probability, a probability mass, is usually known as confidence interval in FREQUENTIST STATISTICS and credible interval in BAYESIAN STATISTICS.'>Credible Interval</a>: Term chiefly in Bayesian statistics.\n- <a class='glossary' title='Two parameter values that contain between them a specified amount of posterior probability, a probability mass, is usually know as confidence interval that may instead be called a credible interval. We’re going to call it a compatibility interval instead, in order to avoid the unwarranted implications of “confidence”” and “credibility.” What the interval indicates is a range of parameter values compatible with the model and data. The model and data themselves may not inspire confidence, in which case the interval will not either. (Chap.3)'>Compatibility Interval</a>: Term preferably used by Richard McElreath.\n\nThe abbreviation for all three versions of probability mass intervals is \"CI\".\n\nMcElreath tries to avoid the semantic of \"confidence\" or \"credibility\" because\n\n> “What the interval indicates is a range of parameter values compatible with the model and data. The model and data themselves may not inspire confidence, in which case the interval will not either.” ([McElreath, 2020, p. 54](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=73&annotation=BHMW5CJ4))\n\n\n\n::::\n:::::\n\nThe values of these intervals can be found easier with by using samples from the posterior than by using a grid approximation.\n\n> “Suppose for example you want to know the boundaries of the lower $80\\%$ posterior probability. You know this interval starts at $p = 0$. To find out where it stops, think of the samples as data and ask where the $80th$ percentile lies:” ([McElreath, 2020, p. 54](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=73&annotation=3SA8YJWX))\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-quantiles-a}\na: Compute posterior probability intervals lower $80\\%$ and from 10th to 90th percentile\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.9a Quantile 0.8 #######################\nq8 <- quantile(samples_a, 0.8)\n\n## R code 3.10a PI = Quantile 0.1-0.9 ###################\nq1_9 <- quantile(samples_a, c(0.1, 0.9))\n```\n:::\n\n\n- Lower $80\\%$ = 0.7627628\n- Between $10\\%$ = 0.4514515 and $90\\%$ = 0.8148148\n::::\n:::::\n\n##### Percentile Interval (PI)\n\nThe second calculation returns the middle 80% of the distribution\n\n> “Intervals of this sort, which assign equal probability mass to each tail, are very common in the scientific literature. We’ll call them <a class='glossary' title='The set of divisions that produce exactly 100 equal parts in a series of continuous values, such as blood pressure, weight, height, etc. Thus a person with blood pressure above the 80th percentile has a greater blood pressure value than over 80% of the other recorded values.” (CDS, p.323)'>percentile intervals</a>  (PI). These intervals do a good job of communicating the shape of a distribution, as long as the distribution isn’t too asymmetrical. But in terms of supporting inferences about which parameters are consistent with the data, they are not perfect.” ([McElreath, 2020, p. 55](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=74&annotation=5GPNVTUH))\n\nBut they do not work well with highly skewed data. See @fig-skewed-dist-a where the posterior is consistent with observing three waters in three tosses and a uniform (flat) prior.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-fig-skewed-dist-a}\na: Skewed posterior distribution observing three waters in three tosses and a uniform (flat) prior (Base R)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.11a Skewed data #####################\np_grid_skewed_a <- seq(from = 0, to = 1, length.out = 1000)\nprior_skewed_a <- rep(1, 1000)\nlikelihood_skewed_a <- dbinom(3, size = 3, prob = p_grid_skewed_a)\nposterior_skewed_a <- likelihood_skewed_a * prior_skewed_a\nposterior_skewed_a <- posterior_skewed_a / sum(posterior_skewed_a)\n\nset.seed(3) # added to make sampling distribution reproducible (pb)\nsamples_skewed_a <- sample(p_grid_skewed_a, \n             size = 1e4, replace = TRUE, prob = posterior_skewed_a)\n\n# added to show the skewed posterior distribution (pb)\nrethinking::dens(samples_skewed_a)\n```\n\n::: {.cell-output-display}\n![Skewed posterior distribution observing three waters in three tosses and a uniform (flat) prior. It is highly skewed, having its maximum value at the boundary where p equals 1.](03-sampling-the-imaginary_files/figure-html/fig-skewed-dist-a-1.png){#fig-skewed-dist-a width=672}\n:::\n:::\n\n\n::::\n:::::\n\n\n> “[The <a class='glossary' title='The set of divisions that produce exactly 100 equal parts in a series of continuous values, such as blood pressure, weight, height, etc. Thus a person with blood pressure above the 80th percentile has a greater blood pressure value than over 80% of the other recorded values.” (CDS, p.323)'>percentile interval</a>] assigns 25% of the probability mass above and below the interval. So it provides the central 50% probability. But in this example, it ends up excluding the most probable parameter values, near p = 1. So in terms of describing the shape of the posterior distribution—which is really all these intervals are asked to do—the percentile interval can be misleading.” ([McElreath, 2020, p. 56](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=75&annotation=96JZPRGW))\n\n`rethinking::PI()` is just a shorthand for the base R `stats::quantile()` function.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-pi-a1}\na: Computing the Percentile Interval (PI)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.12a(1) PI ############################\nrethinking::PI(samples_skewed_a, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       25%       75% \n#> 0.7087087 0.9349349\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n:::::{.my-procedure}\n:::{.my-procedure-header}\n:::::: {#prp-pi-a1}\n: Probability mass (PI) `prob = 0.6` equals the interval between $20-80\\%$\n::::::\n:::\n::::{.my-procedure-container}\n\n`rethinking::PI()` is just a shorthand for the base R `stats::quantile()` function. Instead of providing the interval explicitly (for instance $20-80\\%$) we just say that we want the central $60\\%$ = PI of `prob = 0.6`. \n\n`rethinking::PI()` simplifies the following three steps:\n\n1. We divide always the percentage assigned to the `prob` value by 2: 60% / 2 = 30$ \n2. We subtract, respectively add this value to 50: 50% - 30% = 20% and 50% + 30% = 80% \n3. The result is the probability mass between 20-80%.\n::::\n:::::\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-pi-a2}\na: Compute PI between $20-80\\%$ (Rethinking and Base R)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.12a(2) PI ############################\n\nglue::glue('Central Propbability Mass calculated with rethinking::PI()\\n')\nrethinking::PI(samples_skewed_a, prob = 0.6)\nglue::glue('########################################################\\n\\n')\nglue::glue('Central Propbability Mass calculated with stats::quantile()\\n')\nquantile(samples_skewed_a, prob = c(.20, .80))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Central Propbability Mass calculated with rethinking::PI()\n#>       20%       80% \n#> 0.6706707 0.9481481 \n#> ########################################################\n#> \n#> Central Propbability Mass calculated with stats::quantile()\n#>       20%       80% \n#> 0.6706707 0.9481481\n```\n\n\n:::\n:::\n\n\n::::\n:::::\n\n##### Highest Posterior Density Interval (HPDI)\n\nTo include the most probable parameter value, the modus or <a class='glossary' title='In Bayesian statistics a Maximum A Posteriori probability or MAP is essentially the mode of posterior distribution. (CDS, p.272)'>MAP</a> we should calculate the <a class='glossary' title='Highest Posterior Density Interval (HPDI) is the Highest Density Interval (HDI) or Highest Density Region (HDR) of all possible regions of probability coverage, the HDR has the smallest region possible in the sample space. For a unimodal distribution it will include the mode (the maximum a posteriori, or MAP). (Cross Validated).'>HPDI</a>:\n\n> “The HPDI is the narrowest interval containing the specified probability mass. If you think about it, there must be an infinite number of posterior intervals // with the same mass. But if you want an interval that best represents the parameter values most consistent with the data, then you want the densest of these intervals. That’s what the HPDI is.” (McElreath, 2020, p. 56/57)\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-hpdi-a}\na: Compute Highest Posterior Density Interval (HPDI) (Rethinking / Base R)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.13a HPDI ###############################\nrethinking::HPDI(samples_skewed_a, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>      |0.5      0.5| \n#> 0.8418418 0.9989990\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n\n:::::{.my-note}\n:::{.my-note-header}\n:::::: {#cor-pi-hpdo}\n: HPDI versus PI\n::::::\n:::\n::::{.my-note-container}\n**Advantages of HPDI**\n\n1. HPDI captures the parameters with highest posterior probability\n2. HPDI is noticeably narrower than PI. In our example 0.157 versus `r `round(rethinking::PI(samples_skewed_a, prob = 0.5)[[2]] - rethinking::PI(samples_skewed_a, prob = 0.5)[[1]], 3)`.\n\nBut this is only valid if we have a very skewed distribution. \n\n**Disadvantages of HPDI**\n\n1. HPDI is more computationally intensive than PI\n2. HPDI is sensitive of the number of samples drawn (= greater simulation variance)\n3. HPDI is more difficult to understand\n\n**Remember, the entire posterior distribution is the Bayesian estimate**\n\n> “Overall, if the choice of interval type makes a big difference, then you shouldn’t be using intervals to summarize the posterior. Remember, the entire posterior distribution is the Bayesian 'estimate.' It summarizes the relative plausibilities of each possible value of the parameter. Intervals of the distribution are just helpful for summarizing it. If choice of interval leads to different inferences, then you’d be better off just plotting the entire posterior distribution.” ([McElreath, 2020, p. 58](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=77&annotation=XGHNSWCG))\n\n::::\n:::::\n\n“[I]n most cases, these two types of interval are very similar.58 They only look so different in this case because the posterior distribution is highly skewed.” ([McElreath, 2020, p. 57](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=76&annotation=FQPNEVHV))n \n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-pi-hpdi-symmetric-dist-a}\na: Compare PI and HPDI of symmetric distributions: Six 'Water', 9 tosses\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\npi8a <- rethinking::PI(samples_a, prob = 0.8)\nhpdi8a <- rethinking::HPDI(samples_a, prob = 0.8)\n\npi95a <- rethinking::PI(samples_a, prob = 0.95)\nhpdi95a <- rethinking::HPDI(samples_a, prob = 0.95)\n```\n:::\n\n\n- PI 80% = 0.4514515, 0.8148148 versus HPDI 80% = 0.4874875, 0.8448448.\n- PI 95% = 0.3493493, 0.8788789 versus HPDI 95% = 0.3703704, 0.8938939.\n\n::::\n:::::\n\nThe 95% interval in frequentist statistics is just a convention, there are no analytical reasons why you should choose exactly this interval. But convenience is not a serious\ncriterion. So what to do instead?\n\n\n:::::{.my-tip}\n:::{.my-tip-header}\nInstead of 95% intervals use the widest interval that excludes the value you want to report or provide a series of nested intervals\n:::\n::::{.my-tip-container}\n\n> “If you are trying to say that an interval doesn’t include some value, then you might use the widest interval that excludes the value. Often, all compatibility intervals do is communicate the shape of a distribution. In that case, a series of nested intervals may be more useful than any one interval. For example, why not present 67%, 89%, and 97% intervals, along with the median? Why these values? No reason. They are prime numbers, which makes them easy to remember. But all that matters is they be spaced enough to illustrate the shape of the posterior. And these values avoid 95%, since conventional 95% intervals encourage many readers to conduct unconscious hypothesis tests.” ([McElreath, 2020, p. 56](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=75&annotation=TG2LCZAG))\n\n::::\n:::::\n\n:::::{.my-note}\n:::{.my-note-header}\nBoundaries versus Probability Mass Intervals\n:::\n::::{.my-note-container}\n\n**Boundaries**: \n\n- We ask for a **probability of frequencies**.\n- Result is a **percentage of probability**.\n- Boundaries are grounded on the **probability (`prob`) values ($0-1$)**.\n\n**Probability Mass**: \n\n- We ask for a specified **amount of posterior probability**.\n- Result is the probability value of the **percentage of frequencies** we looked for.\n- Probability Mass is grounded on the **percentage of probabilities ($0-100\\%$)**.\n\n::::\n:::::\n\n#### TIDYVERSE\n\n##### Quantiles\n\nKurz offers again different methods --- this time to calculate probability mass:\n\n1. **Method**: Since we saved our `samples_b` samples within the `df_samples_b`\ntibble, we'll have to index with `$` within `stats::quantile()`.\n2. **Method**: For an alternative approach, we could `dplyr::select()` the `samples_b`\nvector, extract it from the tibble with `dplyr::pull()`, and then pump\nit into `stats::quantile()`.\n\n  > `pull()` is similar to `$`. It's mostly useful because it looks a\n  > little nicer in pipes, it also works with remote data frames, and it\n  > can optionally name the output. ([`dplyr::pull()` help file \"Extract a single column\"](https://dplyr.tidyverse.org/reference/pull.html))\n\n3. **Method**: We might also use `stats::quantile()` within `dplyr::summarize()`.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-quantiles-b1}\nb: Compute posterior probability mass intervals of $80\\%$ with different methods\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.9b Quantile 0.8 diff. approaches   #######################\n###### Method (1) #######\nmethod_1 <- q80 <- \n  quantile(df_samples_b$samples_b, probs = .8)\n\nglue::glue('Method 1:\\n')\nmethod_1\nglue::glue('##################################################\\n\\n')\n\n###### Method (2) #######\nmethod_2 <- \n  df_samples_b |> \n    dplyr::pull(samples_b) |> \n    quantile(probs = .8)\n\nglue::glue('Method 2:\\n')\nmethod_2\nglue::glue('##################################################\\n\\n')\n\n###### Method (3) #######\nmethod_3 <- \n  df_samples_b |> \n    dplyr::summarize(q80_2 = quantile(samples_b, probs = .8))\n\nglue::glue('Method 3:\\n')\nmethod_3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Method 1:\n#>       80% \n#> 0.7627628 \n#> ##################################################\n#> \n#> Method 2:\n#>       80% \n#> 0.7627628 \n#> ##################################################\n#> \n#> Method 3:\n#> # A tibble: 1 × 1\n#>   q80_2\n#>   <dbl>\n#> 1 0.763\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n\n\n\n##### Percentile Interval (PI)\n\nHere's the `summarize()` approach with two probabilities returning the <a class='glossary' title='The set of divisions that produce exactly 100 equal parts in a series of continuous values, such as blood pressure, weight, height, etc. Thus a person with blood pressure above the 80th percentile has a greater blood pressure value than over 80% of the other recorded values.” (CDS, p.323)'>percentile interval</a>  (PI).\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-pi-b1}\nb: Compute probability mass of 80% with summarize method\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.10b(1) PI = Quantile 0.1-0.9 ###################\ndf_samples_b |> \n    dplyr::summarize(q10 = quantile(samples_b, probs = .1),\n              q90 = quantile(samples_b, probs = .9))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 2\n#>     q10   q90\n#>   <dbl> <dbl>\n#> 1 0.451 0.815\n```\n\n\n:::\n:::\n\n::::\n:::::\n\n\nKurz refers also to a now deprecated calculation using the vector feature of R to summarize different quantiles with one line. \n\n***\n```\nsamples_b |> dplyr::summarize(q10_90 = quantile(samples_b, probs = c(.1, .9)))\n```\n***\n\nThis produces nowadays the following warning message:\n\n::: {.callout-warning}\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in dplyr 1.1.0.\n\nPlease use `reframe()` instead.\n\nWhen switching from `summarise()` to `reframe()`, remember that `reframe()` always returns an ungrouped data frame and adjust accordingly.\n:::\n\nTherefore I am going to change `dplyr::summarize()` to `dplyr::reframe()`.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-reframe}\nb: Using `dplyr::reframe()` to compute probability mass intervals of 80%\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.10b(2) PI = Quantile 0.1-0.9 ###################\ndf_samples_b |> \n    dplyr::reframe(q10_90 = quantile(samples_b, probs = c(.1, .9)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 2 × 1\n#>   q10_90\n#>    <dbl>\n#> 1  0.451\n#> 2  0.815\n```\n\n\n:::\n:::\n\n\n:::::{.my-note}\n:::{.my-note-header}\n:::::: {#cor-reframe}\n: Excursion: Using `dplyr::reframe()` and friends\n::::::\n:::\n::::{.my-note-container}\nFrom the help file of `dplyr::reframe()`:\n\n> While `summarise()` requires that each argument returns a single\n> value, and `mutate()` requires that each argument returns the same\n> number of rows as the input, `reframe()` is a more general workhorse\n> with no requirements on the number of rows returned per group.\n>\n> `reframe()` creates a new data frame by applying functions to columns\n> of an existing data frame. It is most similar to `summarise()`, with\n> two big differences:\n>\n> -   `reframe()` can return an arbitrary number of rows per group,\n>     while `summarise()` reduces each group down to a single row.\n> -   `reframe()` always returns an ungrouped data frame, while\n>     `summarise()` might return a grouped or rowwise data frame,\n>     depending on the scenario.\n>\n> We expect that you'll use `summarise()` much more often than\n> `reframe()`, but `reframe()` can be particularly helpful when you need\n> to apply a complex function that doesn't return a single summary\n> value.\n\nSee also the appropriate [section in the blog\npost](https://www.tidyverse.org/blog/2023/02/dplyr-1-1-0-pick-reframe-arrange/#reframe)\nabout changes in {**dplyr**} 1.1.0. The name `reframe()` is in\naccordance with `tibble::enframe()` and `tibble::deframe()`:\n\n-   `enframe()`: Takes a vector, returns a data frame\n-   `deframe()`: Takes a data frame, returns a vector\n-   `reframe()`: Takes a data frame, returns a data frame\n\n::::\n:::::\n\n::::\n:::::\n\n\n\n> The functions of the tidyverse approach typically returns a data\n> frame. But sometimes you just want your values in a numeric vector for\n> the sake of quick indexing. In that case, base R `stats::quantile()`\n> shines: (Kurz in the section: [Intervals of defined mass](https://bookdown.org/content/4857/sampling-the-imaginary.html#intervals-of-defined-mass.))\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-pi-b2}\nb: Using `stats::quantile()` to get a vector of a probability mass calculation\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.12b(1) PI = Quantile 0.1-0.9#############################\n(q10_q90 = quantile(df_samples_b$samples_b, probs = c(.1, .9)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       10%       90% \n#> 0.4514515 0.8148148\n```\n\n\n:::\n:::\n\nThis is the same method as in R base with the difference that we are working with tibbles and need therefore to use the `$` operator.\n\n\n::::\n:::::\n\n\nTo produce the bottom part of Figure 3.2 of the book we apply following code lines.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-fig-lower-part-3-2b}\nb: Plots of defined mass intervals lower of 80% and the middle 80%\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R Code Fig 3.2b Lower Part #############\np1 <-\n  df_samples_b |> \n  ggplot2::ggplot(ggplot2::aes(x = samples_b, y = posterior_samples_b)) +\n  ggplot2::geom_line() +\n  ggplot2::geom_area(data = df_samples_b |> \n                dplyr::filter(samples_b < q80), fill = \"deepskyblue\") +\n  ggplot2::annotate(geom = \"text\",\n           x = .25, y = .0025,\n           label = \"lower 80%\") +\n  ggplot2::labs(x = \"proportion of water (p)\",\n       y = \"density\") +\n  ggplot2::theme_bw()\n\n# upper right panel\np2 <- \n  df_samples_b |> \n  ggplot2::ggplot(ggplot2::aes(x = samples_b, y = posterior_samples_b)) +\n  ggplot2::geom_line() +\n  ggplot2::geom_area(data = df_samples_b |> \n            dplyr::filter(samples_b > q10_q90[[1]] & \n                    samples_b < q10_q90[[2]]), fill = \"deepskyblue\") +\n  ggplot2::annotate(geom = \"text\",\n           x = .25, y = .0025,\n           label = \"middle 80%\") +\n  ggplot2::labs(x = \"proportion of water (p)\",\n       y = \"density\") +\n  ggplot2::theme_bw()\n\nlibrary(patchwork)\np1 + p2\n```\n\n::: {.cell-output-display}\n![Lower part of SR2 Figure 3.2: Intervals of defined mass produced with {**tidyverse**} tools: Left: Lower 80% posterior probability exists below a parameter value of about 0.75. Right: Middle 80% posterior probability lies between the 10% and 90% quantiles.](03-sampling-the-imaginary_files/figure-html/fig-lower-part-3-2b-1.png){#fig-lower-part-3-2b width=672}\n:::\n:::\n\n\n\n::::\n:::::\n\n\nAgain we will demonstrate the misleading character of <a class='glossary' title='The set of divisions that produce exactly 100 equal parts in a series of continuous values, such as blood pressure, weight, height, etc. Thus a person with blood pressure above the 80th percentile has a greater blood pressure value than over 80% of the other recorded values.” (CDS, p.323)'>Percentile Intervals</a> (PIs) with a very skewed distribution.\n\nWe've already defined `p_grid_b` and `prior_b` within `d_b`, above. Here\nwe'll reuse them and create a new tibble by updating all the columns\nwith the skewed parameters of three 'Water' in three tosses.\n\nTo see the difference how the skewed distribution is different to the\nFigure 3.2 lower part, I will draw the appropriate figure here myself.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-fig-skewed-dist-b}\nb: Skewed posterior distribution observing three waters in three tosses and a uniform (flat) prior (Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell layout-align=\"center\" figh-height='5'}\n\n```{.r .cell-code}\n## R code 3.11b Skewed data #########################\n# here we update the `dbinom()` parameters \n# for values for a skewed distribution\n# assuming three trials results in 3 W (Water)\n\nn_samples_skewed_b <- 1e4\nn_success_skewed_b <- 3\nn_trials_skewed_b  <- 3\n\n# update `d_b` to d_skewed_b\nd_skewed_b <-\n  d_b |> \n    dplyr::mutate(likelihood_skewed_b = \n        dbinom(n_success_skewed_b,\n           size = n_trials_skewed_b, prob = p_grid_b)) |> \n    dplyr::mutate(posterior_skewed_b  = \n          (likelihood_skewed_b * prior_b) / \n          sum(likelihood_skewed_b * prior_b))\n\n# make the next part reproducible\nset.seed(3)\n\n# here's our new samples tibble\nsamples_skewed_b <- \n    d_skewed_b |> \n    dplyr::slice_sample(n = n_samples_skewed_b, \n        weight_by = posterior_skewed_b, replace = T) |> \n    dplyr::rename(p_skewed_b = p_grid_b,\n           prior_skewed_b = prior_b)\n\n\n# added to see the skewed distribution\nsamples_skewed_b |>  \n  ggplot2::ggplot( ggplot2::aes(x = p_skewed_b, y = posterior_skewed_b)) +\n  ggplot2::geom_line() +\n  ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![Skewed posterior distribution observing three waters in three tosses and a uniform (flat) prior. The distribution is highly skewed, having its maximum value where p equals 1.](03-sampling-the-imaginary_files/figure-html/fig-skewed-dist-b-1.png){#fig-skewed-dist-b fig-align='center' width=50%}\n:::\n:::\n\n::::\n:::::\n\nTo see how the skewed distribution is different to the book’s\nFigure 3.2 lower part, I will draw the appropriate figure here.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-fig-prob-mass-skewed-dist}\nb: Lower 80% and middle 80% of probability mass intervals in the skewed distribution \n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.12b(2) PI < 80 & middle 80% #############################\np1 <-\n  samples_skewed_b |> \n  ggplot2::ggplot(ggplot2::aes(x = p_skewed_b, y = posterior_skewed_b)) +\n  ggplot2::geom_line() +\n  ggplot2::geom_area(data = samples_skewed_b |> \n      dplyr::filter(p_skewed_b < q80), fill = \"deepskyblue\") +\n  ggplot2::annotate(geom = \"text\",\n           x = .25, y = .0025,\n           label = \"lower 80%\") +\n  ggplot2::labs(x = \"proportion of water (p)\",\n       y = \"density\") +\n  ggplot2::theme_bw()\n\n# upper right panel\np2 <- \n  samples_skewed_b |> \n  ggplot2::ggplot(ggplot2::aes(x = p_skewed_b, y = posterior_skewed_b)) +\n  ggplot2::geom_line() +\n  ggplot2::geom_area(data = samples_skewed_b |> \n      dplyr::filter(p_skewed_b > q10_q90[[1]] & \n                    p_skewed_b < q10_q90[[2]]), fill = \"deepskyblue\") +\n  ggplot2::annotate(geom = \"text\",\n           x = .25, y = .0025,\n           label = \"middle 80%\") +\n  ggplot2::labs(x = \"proportion of water (p)\",\n       y = \"density\") +\n  ggplot2::theme_bw()\n\nlibrary(patchwork)\np1 + p2\n```\n\n::: {.cell-output-display}\n![Probability mass intervals in a skewed distribution. Left: Lower 80%. right: Middle 80% = 80% Percentile Interval (PI)](03-sampling-the-imaginary_files/figure-html/fig-prob-mass-skewed-dist-1.png){#fig-prob-mass-skewed-dist width=672}\n:::\n:::\n\n\n\n::::\n:::::\n\n\n##### Introducing tidybayes {.unnumbered}\n\n:::::{.my-resource}\n:::{.my-resource-header}\nIntroducing the {**tidybayes**} package by Matthew Kay\n:::\n::::{.my-resource-container}\nThe [{**tidybayes**}](https://mjskay.github.io/tidybayes/) package by [Matthew Kay](https://www.mjskay.com/) offers an array of convenience functions for summarizing Bayesian models. \n\n> {**tidybayes**} is an R package that aims to make it easy to integrate\n> popular Bayesian modeling methods into a tidy data + ggplot workflow.\n> It builds on top of (and re-exports) several functions for visualizing\n> uncertainty from its sister package,\n> [{**ggdist**}](https://mjskay.github.io/ggdist/).\n\n- For an introduction using {**tidybayes**} with {**brms**} see\n[Extracting and visualizing tidy draws from {**brms**}\nmodels](https://mjskay.github.io/tidybayes/articles/tidy-brms.html). \n\n- For a general introduction (not confined to {**brms**}) see [Using tidy data with Bayesian models](https://mjskay.github.io/tidybayes/articles/tidybayes.html) but read also the start page [tidybayes: Bayesian analysis + tidy data + geoms](https://mjskay.github.io/tidybayes/) of the package documentation.\n\n- Besides supporting many types of models there is an additional {**tidybayes.rethinking**} package [available on GitHub](https://mjskay.github.io/tidybayes.rethinking/) that extends {**tidybayes**} to work with the {**rethinking**} package. I think this package is a new development because Kurz didn't mention it. (As far as I know, because at the moment I have read his [version 0.40](https://bookdown.org/content/4857/) only until chapter 4.)\n\nFor the following parts the section on [Point Summaries and\nIntervals](https://mjskay.github.io/tidybayes/articles/tidy-brms.html#point-summaries-and-intervals)\nand the reference on [Point and interval summaries for tidy data frames\nof draws from\ndistributions](https://mjskay.github.io/ggdist/reference/point_interval.html)\nare especially important.\n\nThe mentioned vignettes above are long articles I haven't read yet. I plan to do this in the next future but for now I am concentrating and trusting on Kurz’ text to apply and explain the most important function parallel to McElreath book chapters.\n\n::::\n:::::\n\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\nMany function names used by Kurz do not apply anymore\n:::\n::::{.my-watch-out-container}\nI had difficulties to use Kurz's functions because there was an\n[overhaul in the naming\nscheme](https://mjskay.github.io/tidybayes/reference/tidybayes-deprecated.html)\nof {**tidybayes**} version 1.0 and a deprecation of horizontal shortcut\ngeoms and stats in {**tidybayes**} 2.1. Because {**tidybayes**}\nintegrates function of the sister package {**ggdist**} the [function\ndescriptions and references of\n{**ggdist**}](https://mjskay.github.io/ggdist/reference/index.html) are\nalso important to consult. For instance all the function on [point and interval summaries](https://mjskay.github.io/ggdist/reference/point_interval.html) are now documented in {**ggdist**}.\n\nThere is a systematic change of the function names: The `h` (for 'horizontal') in parameter name of the point estimate was removed. For instance: Instead of median_qih, median_hdih and median_hdcih it is now `tidybayes::median_qi()`, `tidybayes::median_hdi()` and `tidybayes::median_hdci()`. Similar with point_inverhalh, mean_* and mode_*.\n\n***\n\nThere is another adaption compared to the Kurz’ version: I can't reproduce the codes with his  `samples` (my `samples_b`) data frame, because the data has changed values recently to the skewed sampling version. To get the same results as Kurz I have to use\nin my naming scheme the `skewed` version.\n::::\n:::::\n\n\n> The {**tidybayes**} package contains a [family of\nfunctions](https://mjskay.github.io/tidybayes/articles/tidy-brms.html#point-summaries-and-intervals)\nthat make it easy to summarize a distribution with a measure of central\ntendency accompanied by intervals. With `tidybayes::median_qi()`, we\nwill ask for the median and quantile-based intervals --- just like we've\nbeen doing with `stats::quantile()`. ([Kurz](https://bookdown.org/content/4857/sampling-the-imaginary.html#intervals-of-defined-mass.))\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-median-qi}\n: Computing the median quantile interval with {**tidybayes**}\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidybayes::median_qi(samples_skewed_b$p_skewed_b, .width = .5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.8428428 0.7087087 0.9349349    0.5 median        qi\n```\n\n\n:::\n:::\n\n\n\n> Note how the `.width` argument within `tidybayes::median_qi()` worked\nthe same way the `prob` argument did within `rethinking::PI()`. With\n`.width = .5`, we indicated we wanted a quantile-based 50% interval,\nwhich was returned in the `ymin` and `ymax` columns.\n\n::::\n:::::\n\n\n:::::{.my-note}\n:::{.my-note-header}\n:::::: {#cor-point-interval-summaries}\n: Point and interval summaries for tidy data frames of draws from distributions\n::::::\n:::\n::::{.my-note-container}\n\nThe `qi` in `tidybayes::median_qi()` stands for \"quantile interval\". The explanation of this function family (`median_qi()`, `mean_qi()` and `mode_qi()`) is now documented in the {**ggdist**} package. \n\n> The `qi`-variants is the short form of the function family of `tidybayes::point_interval(..., .point = median, .interval = qi)`. \n>\n> There are several point intervals that {**tidybayes**} respectively {**ggdist**} computes: \n> \n> - **qi** yields the quantile interval (also known as the percentile interval or equi-tailed interval) as a 1x2 matrix.\n> - **hdi** yields the highest-density interval(s) (also known as the highest posterior density interval). Note: If the distribution is multimodal, hdi may return multiple intervals for each probability level (these will be spread over rows). You may wish to use hdci (below) instead if you want a single highest-density interval, with the caveat that when the distribution is multimodal hdci is not a highest-density interval.\n> - **hdci** yields the highest-density continuous interval, also known as the shortest probability interval. Note: If the distribution is multimodal, this may not actually be the highest-density interval (there may be a higher-density discontinuous interval, which can be found using hdi).\n> - **ll and ul** yield lower limits and upper limits, respectively (where the opposite limit is set to either Inf or -Inf). ([ggdist reference](https://mjskay.github.io/ggdist/reference/point_interval.html))\n::::\n:::::\n\n\n> The {**tidybayes**} framework makes it easy to request multiple types of\nintervals. In the following code chunk we'll request 50%, 80%, and 99%\nintervals.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-multiple-intervals-b}\nb: Requesting multiple type of intervals with {**tidybayes**}\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.12b(3) different PIs ##############\ntidybayes::median_qi(samples_skewed_b$p_skewed_b, .width = c(.5, .8, .99))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.8428428 0.7087087 0.9349349   0.50 median        qi\n#> 2 0.8428428 0.5705706 0.9749750   0.80 median        qi\n#> 3 0.8428428 0.2562563 0.9989990   0.99 median        qi\n```\n\n\n:::\n:::\n\n\n\n> The .width column in the output indexed which line presented which\n> interval. The value in the y column remained constant across rows.\n> That's because that column listed the measure of central tendency, the\n> median in this case.\n::::\n:::::\n\n##### Highest Posterior Density Interval (HPDI)\n\n> Now let's use the `rethinking::HPDI()` function to return 50% highest\n> posterior density intervals (HPDIs).\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-rethinking-hpdi-b}\nb: Compute Highest Posterior Density Interval (HPDI) (Rethinking / Tidyverse)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.13b(1) HPDI ###############################\nrethinking::HPDI(samples_skewed_b$p_skewed_b, prob = .5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>      |0.5      0.5| \n#> 0.8418418 0.9989990\n```\n\n\n:::\n:::\n\n\n\n::::\n:::::\n\n\n> The reason I introduce {**tidybayes**} now is that the functions of\n> the {**brms**} package only support percentile-based intervals of the\n> type we computed with `quantile()` and `median_qi()`. But\n> {**tidybayes**} also supports HPDIs.\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\n: Two Version for Highest Density Intervals\n:::\n::::{.my-watch-out-container}\nAs already mentioned in @cor-point-interval-summaries there is `hdi`and `hcdi`. Both functions produce the same result in unimodal distributions. \n\nBut in the case of an extreme skewed distribution like our data frame with the observation of 3 'Water' with 3 tosses the `tidybayes::hdi()` functions generates an error.\n\n> Error in quantile.default(dist_y, probs = 1 - .width) :  \n> missing values and NaN's not allowed if 'na.rm' is FALSE\n\nMy error message with `hdi``` is in contrast to Kurz’ version where this function seems to work. BTW: I got the same error message providing the vector `samples_skewed_a` from the Base R version.\n\n::::\n:::::\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-tidyverse-HPDI-b}\n: High Density Intervals with {**tidybayes**}\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.panel-tabset}\n\n###### 6 W, n=9\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.13b(2a) HPDI 6 Water, 9 tosses #####################\ntidybayes::mode_hdi(df_samples_b$samples_b, .width = .5)\ntidybayes::mode_hdci(df_samples_b$samples_b, .width = .5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.6508383 0.5685686 0.7597598    0.5   mode       hdi\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.6508383 0.5685686 0.7597598    0.5   mode      hdci\n```\n\n\n:::\n:::\n\n\n\n###### 3 W, n=3\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.13b(2b) HPDI 3 Water, 3 tosses #####################\n# tidybayes::mode_hdi(samples_skewed_b$p_skewed_b, .width = .5) # generates error\ntidybayes::mode_hdci(samples_skewed_b$p_skewed_b, .width = .5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>           y      ymin     ymax .width .point .interval\n#> 1 0.9995616 0.8418418 0.998999    0.5   mode      hdci\n```\n\n\n:::\n:::\n\n\n:::\n\n\n::::\n:::::\n\n\nIn contrast to @cnj-multiple-intervals-b and @cnj-rethinking-hpdi-b we used this time the mode as the measure of central tendency. With this\nfamily of {**tidybayes**} functions, you specify the measure of central\ntendency in the prefix (i.e., mean, median, or mode) and then the type\nof interval you'd like (i.e., `qi()` or `hdci()`).\n\nIf all you want are the intervals without the measure of central\ntendency or all that other technical information, {**tidybayes**} also\noffers the handy `qi()` and `hdi()` functions.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-pi-4}\n: Numbered R Code Title\n::::::\n:::\n::::{.my-r-code-container}\nHere include code lines\n::::\n:::::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.12b4 PI 0.5 ##############################\ntidybayes::qi(samples_skewed_b$p_skewed_b, .width = .5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>           [,1]      [,2]\n#> [1,] 0.7087087 0.9349349\n```\n\n\n:::\n:::\n\n\n\nWe have now all necessary skills to plot book’s Figure 3.3:\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-fig-pi-hpdi}\nb: Plot the difference between percentile interval (PI) and highest posterior density  intervals (HPDI)\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code Figure 3.3 #######################\n# left panel\np1 <-\n  samples_skewed_b |> \n  ggplot2::ggplot(ggplot2::aes(x = p_skewed_b, y = posterior_skewed_b)) +\n  # check out our sweet `qi()` indexing\n  ggplot2::geom_area(data = samples_skewed_b |> \n              dplyr::filter(p_skewed_b >\n                tidybayes::qi(samples_skewed_b$p_skewed_b, .width = .5)[1] & \n                     p_skewed_b <\n                tidybayes::qi(samples_skewed_b$p_skewed_b, .width = .5)[2]),\n                fill = \"deepskyblue\") +\n  ggplot2::geom_line() +\n  ggplot2::labs(subtitle = \"50% Percentile Interval\",\n       x = \"proportion of water (p)\",\n       y = \"density\") +\n  ggplot2::theme_bw()\n\n# right panel\np2 <-\n  samples_skewed_b |> \n  ggplot2::ggplot(ggplot2::aes(x = p_skewed_b, y = posterior_skewed_b)) +\n  ggplot2::geom_area(data = samples_skewed_b |> \n              dplyr::filter(p_skewed_b > \n                 tidybayes::hdci(samples_skewed_b$p_skewed_b, .width = .5)[1] & \n                       p_skewed_b < \n                 tidybayes::hdci(samples_skewed_b$p_skewed_b, .width = .5)[2]),\n                 fill = \"deepskyblue\") +\n  ggplot2::geom_line() +\n  ggplot2::labs(subtitle = \"50% HPDI\",\n       x = \"proportion of water (p)\",\n       y = \"density\") +\n  ggplot2::theme_bw()\n\n# combine!\nlibrary(patchwork)\np1 | p2\n```\n\n::: {.cell-output-display}\n![Reproduction of Figure 3.3 (p.57): The difference between percentile and highest posterior density compatibility intervals. The posterior density here corresponds to a flat prior and observing three water samples in three total tosses of the globe. Left: 50% percentile interval. This interval assigns equal mass (25%) to both the left and right tail. As a result, it omits the most probable parameter value, where p equals 1. Right: 50% highest posterior density interval, HPDI. This interval finds the narrowest region with 50% of the posterior probability. Such a region always includes the most probable parameter value.](03-sampling-the-imaginary_files/figure-html/fig-pi-hpdi-1.png){#fig-pi-hpdi width=672}\n:::\n:::\n\n\n\n::::\n:::::\n\nComparing the two panels of the plot you can see that in contrast to the\n50% HPDI the 50% of PI does not include the highest probability value.\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\n{**magrittr**} and native R pipe\n:::\n::::{.my-watch-out-container}\nKurz uses the {**magrittr**} paipe whereas I am using the native R pipe. These two pipes are not in every aspect equivalent. One difference is the dot (`.`) syntax, \"since the dot syntax is a feature of {**magrittr**} and not of base R.\" ([Understanding the native R pipe](https://ivelasq.rbind.io/blog/understanding-the-r-pipe/#how-the-native-r-pipe-works)).\n\nThe native pipe is available starting with R 4.1.0. It is constructed\nwith `|` followed by `>` resulting in the symbol `|>` to differentiate\nit from the {**magrittr**} pipe (`%>%`). To understand the details of the\ndifferences of `|>` and the native R pipe `|>` read this elaborated\n[blog article by Isabella\nVelásquez](https://ivelasq.rbind.io/blog/understanding-the-r-pipe/index.html),\nan employee of [Posit](https://posit.co/) (formerly RStudio).\n\nSo the following trick does not work with the native R pipe: \n\n> In the geom_area() line for the HPDI plot, did you notice how we\n> replaced `data = samples_skewed_b` with `data = .`? When using the\n> pipe (i.e., `%>%`), you can use the `.` as a placeholder for the\n> original data object. It's an odd and handy trick to know about.\n\nTherefore I had to replace the dot with the name of the data frame.\n\nLearn more of the [pipe function `%>%` of the {**magrittr**}\npackage](https://magrittr.tidyverse.org/reference/pipe.html) and about\nthe [base R native forward pipe\noperator](https://stat.ethz.ch/R-manual/R-devel/library/base/html/pipeOp.html).\n\n::::\n:::::\n\n\n\nPI and HPDI are only different if you have a very skewed\ndistribution. This means that in unimodal somewhat normal distribution `hdi` and `hdci` are exactly the same and pretty similar to `qi` calculation. In skewed distribution they differ.\nassertion:\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-tidyverse-HPDI-b}\nb: High Density Intervals with {**tidybayes**}\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.panel-tabset}\n\n###### 6 W, n=9\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.13b(2a) HPDI 6 Water, 9 tosses #####################\ntidybayes::mode_hdi(df_samples_b$samples_b, .width = .5)\ntidybayes::mode_hdci(df_samples_b$samples_b, .width = .5)\ntidybayes::mode_qi(df_samples_b$samples_b, .width = .5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.6508383 0.5685686 0.7597598    0.5   mode       hdi\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.6508383 0.5685686 0.7597598    0.5   mode      hdci\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.6508383 0.5475475 0.7427427    0.5   mode        qi\n```\n\n\n:::\n:::\n\n\n\n###### 3 W, n=3\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.13b(2b) HPDI 3 Water, 3 tosses #####################\n# tidybayes::mode_hdi(samples_skewed_b$p_skewed_b, .width = .5) # generates error\ntidybayes::mode_hdci(samples_skewed_b$p_skewed_b, .width = .5)\ntidybayes::mode_qi(samples_skewed_b$p_skewed_b, .width = .5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>           y      ymin     ymax .width .point .interval\n#> 1 0.9995616 0.8418418 0.998999    0.5   mode      hdci\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.9995616 0.7087087 0.9349349    0.5   mode        qi\n```\n\n\n:::\n:::\n\n\n:::\n\n\n::::\n:::::\n\n\nBecause of the disadvantages of <a class='glossary' title='Highest Posterior Density Interval (HPDI) is the Highest Density Interval (HDI) or Highest Density Region (HDR) of all possible regions of probability coverage, the HDR has the smallest region possible in the sample space. For a unimodal distribution it will include the mode (the maximum a posteriori, or MAP). (Cross Validated).'>HPDI</a> (more computationally intensive,\ngreater simulation variance and harder to understand)  Kurz will primarily\nstick to the PI-based intervals. And he will not use the 5.5% and 94.5% <a class='glossary' title='Quantiles are cut points dividing the range of a probability distribution into continuous intervals with equal probabilities (Wikipedia)'>quantiles</a> that are <a class='glossary' title='The set of divisions that produce exactly 100 equal parts in a series of continuous values, such as blood pressure, weight, height, etc. Thus a person with blood pressure above the 80th percentile has a greater blood pressure value than over 80% of the other recorded values.” (CDS, p.323)'>percentile intervals</a> boundaries, corresponding to an 89% <a class='glossary' title='Two parameter values that contain between them a specified amount of posterior probability, a probability mass, is usually know as confidence interval that may instead be called a credible interval. We’re going to call it a compatibility interval instead, in order to avoid the unwarranted implications of “confidence”” and “credibility.” What the interval indicates is a range of parameter values compatible with the model and data. The model and data themselves may not inspire confidence, in which case the interval will not either. (Chap.3)'>compatibility interval</a> but stick to the 95% standard (frequentist) <a class='glossary' title='A range of values, calculated from the sample observations, that is believed, with a particular probability, to contain the true parameter value. (Cambridge Dictionary of Statistics, 4th ed., p.98)'>confidence interval</a>. \n\n### Point Estimates {#sec-chap-03-point-estimates}\n\n#### ORIGINAL\n\n\n##### Measures of Central Tendency\n\n> “Given the entire posterior distribution, what value should you report? This seems like an innocent question, but it is difficult to answer. The Bayesian parameter estimate is precisely the entire posterior distribution, which is not a single number, but instead a function that maps each unique parameter value onto a plausibility value. So really the most important thing to note is that you don’t have to choose a point estimate. It’s hardly ever necessary and often harmful. It discards information.” ([McElreath, 2020, p. 58](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=77&annotation=EVCFUS3F))\n\n\nBut whenever you have to do it, you must choose between mean, median and MAP (= the parameter value with highest posterior probability, a *maximum a posteriori*, essentially the \"peak\" or mode of the posterior distribution. \n\nIn the very skewed globe tossing example where we observed 3 waters out of 3 tosses they are all different.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-point-estimates-a}\na: Compute MAP, median and mean\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.14a MAP (from grid) ###############\nmap_skewed_a_1 <- p_grid_skewed_a[which.max(posterior_skewed_a)]\n\n## R code 3.15a MAP from posterior samples ################\nmap_skewed_a_2 <- rethinking::chainmode(samples_skewed_a, adj = 0.01)\n\n## R code 3.16a mean and median #############\nmean_skewed_a <- mean(samples_skewed_a)\nmedian_skewed_a <- median(samples_skewed_a)\n```\n:::\n\n\n**Results:**\n\n- MAP with `which.max()` = 1\n- MAP with `rethinking::chainmode()` = 0.9938226\n- Mean: 0.8027632\n- Median: 0.8428428\n\n::::\n:::::\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\nDifference between MAP and mode calculation?\n:::\n::::{.my-watch-out-container}\nI have observed small differences between the MAP calculation in @cnj-point-estimates-a and the mode calculation of other packages. I wonder why all these other methods give  0.95/0.96 whereas the MAP calculation results in 0.99/1.0.\n\nOne explanation I could think is that the mode is defined by the *maximum frequency* of observations, whereas the MAP is calculated from the *maximum of the weighted probability frequency *.\n\nBut I am not sure. One thing I can say with some certainty is that MAP seems [a complicated theoretical construct](https://web.stanford.edu/class/archive/cs/cs109/cs109.1216/lectures/22_map.pdf) and a [difficult computational procedure](https://machinelearningmastery.com/maximum-a-posteriori-estimation/).\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-map-mode}\na: Compare MAP and mode calculation of different packages\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.cell}\n\n```{.r .cell-code}\nm_skewed_1 <- modeest::mlv(samples_skewed_a, method = \"mfv\")\nm_skewed_2 <- DescTools::Mode(samples_skewed_a)\nm_skewed_3 <- bayestestR::map_estimate(samples_skewed_a)\n```\n:::\n\n\nResults of mode calculation with several packages:\n\n- `modeest::mlv()`: 0.953954\n- `DescTools::Mode()`: 0.953954\n- `bayestestR::map_estimate()`: 0.9622849\n::::\n:::::\n\n\n::::\n:::::\n\nThe graphical representation as shown in Figure 3.4 will be calculated\nin the tidyverse version of this section. See: @fig-left-panel-3-4-skewed-b for\nthe left panel and @fig-minimum-loss2-b for the right panel of Figure\n3.4.\n\n##### Loss function to support particular decisions\n\n“One principled way to go beyond using the entire posterior as the estimate is to choose a <a class='glossary' title='A loss function is a rule that tells you the cost associated with using any particular point estimate. … The key insight is that different loss functions imply different point estimates. (SR2, p.59)'>loss function</a>.” ([McElreath, 2020, p. 59](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=78&annotation=42KE9FFZ))\n\n:::::{.my-important}\n:::{.my-important-header}\nDifferent loss functions imply different point estimates. ([McElreath, 2020, p. 59](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=78&annotation=3X2FI82B))\n:::\n\n:::::\n\n> “Here’s an example to help us work through the procedure. Suppose I offer you a bet. Tell me which value of p, the proportion of water on the Earth, you think is correct. I will pay you $\\$100$, if you get it exactly right. But I will subtract money from your gain, proportional to the distance of your decision from the correct value. Precisely, your loss is proportional to the absolute value of $d − p$, where $d$ is your decision and $p$ is the correct answer. We could change the precise dollar values involved, without changing the important aspects of this // problem. What matters is that the loss is proportional to the distance of your decision from the true value. Now once you have the posterior distribution in hand, how should you use it to maximize your expected winnings? It turns out that the parameter value that maximizes expected winnings (minimizes expected loss) is the median of the posterior distribution.” ([McElreath, 2020, p. 59/60](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=79&annotation=59IS3PFL))\n\n\n> “Calculating expected loss for any given decision means using the posterior to average over our uncertainty in the true value. Of course we don’t know the true value, in most cases. But if we are going to use our model’s information about the parameter, that means using the entire posterior distribution. So suppose we decide $p = 0.5$ will be our decision.” ([McElreath, 2020, p. 60](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=79&annotation=UTEYE7VX)).\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-expected-loss-a}\na: Calculated expected loss for $p = 0.5$\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.17a weighted average loss ##################\nloss_avg_a <- sum(posterior_skewed_a * abs(0.5 - p_grid_skewed_a))\n\n## R code 3.18a for every possible value #############################\nloss_a <- sapply(p_grid_skewed_a, \n     function(d) sum(posterior_skewed_a * abs(d - p_grid_skewed_a)))\n\n## R code 3.19a minimized loss value #############################\nloss_min_a <- p_grid_skewed_a[which.min(loss_a)]\n```\n:::\n\n\n**Results:**\n\n- Weighted average loss value = 0.3128752.\n- parameter value that minimizes the loss = 0.8408408. This is the posterior median that we already have calculated in @cnj-point-estimates-a. Because of sampling variation it is not identical but pretty close (0.8428428 versus 0.8408408).\n\n::::\n:::::\n\n:::::{.my-important}\n:::{.my-important-header}\nLearnings: Point estimates\n:::\n::::{.my-important-container}\n\n> “In order to decide upon a *point estimate*, a single-value summary of the posterior distribution, we need to pick a loss function. Different loss functions nominate different point estimates. The two most common examples are the absolute loss as above, which leads to the median as the point estimate, and the quadratic loss $(d − p)^{2}$, which leads to the posterior mean (`mean(samples_a)`) as the point estimate. When the posterior distribution is symmetrical and normal-looking, then the median and mean converge to the same point, which relaxes some anxiety we might have about choosing a loss function. For the original globe tossing data (6 waters in 9 tosses), for example, the mean and median are barely different.” ([McElreath, 2020, p. 60](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=79&annotation=JHGI3FVY))\n\n> “Usually, research scientists don’t think about loss functions. And so any point estimate like the mean or MAP that they may report isn’t intended to support any particular decision, but rather to describe the shape of the posterior. You might argue that the decision to make is whether or not to accept an hypothesis. But the challenge then is to say what the relevant costs and benefits would be, in terms of the knowledge gained or lost. Usually it’s better to communicate as much as you can about the posterior distribution, as well as the data and the model itself, so that others can build upon your work. Premature decisions to accept or reject hypotheses can cost lives.” ([McElreath, 2020, p. 61](zotero://select/groups/5243560/items/NFUEVASQ)) ([pdf](zotero://open-pdf/groups/5243560/items/CPFRPHX8?page=80&annotation=6GVPUF4Z))\n::::\n:::::\n\n\n#### TIDYVERSE\n\n##### Measures of Central Tendency\n\nIf we sort the posterior values of `d_skewed_b` (three tosses with three `W`) from highest to lowest values then the first row (= the maximum value of `posterior_skewed_b`) will give us the MAP as the corresponding `p_grid_b` value. Additionally the {**tidybayes**} has other options to compute the MAP. To calculate mean and median we will use the Base R functions. In the following code chunk I have collected all these different calculations.\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-point-estimates-b}\nb: Compute MAP, median and mean\n::::::\n:::\n::::{.my-r-code-container}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.14b MAP (from grid) ###############################\nglue::glue('MAP computed with dplyr::arrange(dplyr::desc())\\n')\nmap_skewed_b <- d_skewed_b |> \n  dplyr::arrange(dplyr::desc(posterior_skewed_b)) \n\nmap_skewed_b[1, c(1,6)]\nglue::glue('#####################################################\\n\\n')\n\n## R code 3.15b MAP (from posterior sample) ###############################\nglue::glue('MAP computed with tidybayes::mode_qi()\\n')\nsamples_skewed_b |> tidybayes::mode_qi(p_skewed_b)\nglue::glue('#####################################################\\n\\n')\n\nglue::glue('MAP computed with tidybayes::mode_hdci()\\n')\nsamples_skewed_b |> tidybayes::mode_hdci(p_skewed_b)\nglue::glue('#####################################################\\n\\n')\n\nglue::glue('MAP computed with tidybayes::Mode()\\n')\ntidybayes::Mode(samples_skewed_b$p_skewed_b)\nglue::glue('#####################################################\\n\\n')\n\n## R code 3.16b mean and median #############################\nglue::glue('Mean & Median computed with mean() & median()\\n')\nsamples_skewed_b |> \n  dplyr::summarize(mean   = mean(p_skewed_b),\n            median = median(p_skewed_b))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> MAP computed with dplyr::arrange(dplyr::desc())\n#> # A tibble: 1 × 2\n#>   p_grid_b posterior_skewed_b\n#>      <dbl>              <dbl>\n#> 1        1            0.00400\n#> #####################################################\n#> \n#> MAP computed with tidybayes::mode_qi()\n#> # A tibble: 1 × 6\n#>   p_skewed_b .lower .upper .width .point .interval\n#>        <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1       1.00  0.399  0.994   0.95 mode   qi       \n#> #####################################################\n#> \n#> MAP computed with tidybayes::mode_hdci()\n#> # A tibble: 1 × 6\n#>   p_skewed_b .lower .upper .width .point .interval\n#>        <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1       1.00  0.475      1   0.95 mode   hdci     \n#> #####################################################\n#> \n#> MAP computed with tidybayes::Mode()\n#> [1] 0.9995616\n#> #####################################################\n#> \n#> Mean & Median computed with mean() & median()\n#> # A tibble: 1 × 2\n#>    mean median\n#>   <dbl>  <dbl>\n#> 1 0.803  0.843\n```\n\n\n:::\n:::\n\n::::\n:::::\n\nWe can now plot a graph to reproduce the left panel of the books Figure 3.4 where we will see the three different measures of central tendency. I will compare the skewed (three 'W', three tosses) with the somewhat normal version (six 'W', nine tosses).\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-fig-left-panel-3-4-b}\n: Posterior density for skewed and symmetric distribution\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.panel-tabset}\n\n###### 3W, n=3\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 1. bundle three types of estimates into a tibble. #######\npoint_estimates_b1 <-\n  dplyr::bind_rows(samples_skewed_b |> tidybayes::mean_qi(p_skewed_b),\n            samples_skewed_b |> tidybayes::median_qi(p_skewed_b),\n            samples_skewed_b |> tidybayes::mode_qi(p_skewed_b)) |> \n  dplyr::select(p_skewed_b, .point) |> \n\n## 2. create two columns to annotate the plot #######\n  dplyr::mutate(x = p_skewed_b + c(-.03, .03, -.03),\n       y = c(.0005, .0012, .002))\n\n## 3. plot #######\nsamples_skewed_b |> \n  ggplot2::ggplot(ggplot2::aes(x = p_skewed_b)) +\n  ggplot2::geom_area(ggplot2::aes(y = posterior_skewed_b),\n            fill = \"deepskyblue\") +\n  ggplot2::geom_vline(xintercept = point_estimates_b1$p_skewed_b) +\n  ggplot2::geom_text(data = point_estimates_b1,\n            ggplot2::aes(x = x, y = y, label = .point),\n            angle = 90) +\n  ggplot2::labs(x = \"proportion of water (p)\",\n       y = \"density\") +\n  ggplot2::theme(panel.grid = ggplot2::element_blank()) +\n  ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![Posterior distribution after observing 3 'water' in 3 tosses of the globe. Vertical lines show the locations of the mode, median, and mean. All three measures of central tendency differ because of the skewness of the distribution. Therefore each point implies a different loss function. ](03-sampling-the-imaginary_files/figure-html/fig-left-panel-3-4-skewed-b-1.png){#fig-left-panel-3-4-skewed-b width=672}\n:::\n:::\n\n###### 6W, n=9\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 0. compute mode with different method\nmode2_b <- df_samples_b |>\n  dplyr::arrange(dplyr::desc(posterior_samples_b)) |> \n  dplyr::slice(1) |> \n  dplyr::rename(.point = prior_samples_b) |> \n  dplyr::select(samples_b, .point) |> \n  dplyr::mutate(.point = \"mode2\")\n\n## 1. bundle three types of estimates into a tibble ######\npoint_estimates_b2 <-\n  dplyr::bind_rows(df_samples_b |> tidybayes::mean_qi(samples_b),\n            df_samples_b |> tidybayes::median_qi(samples_b),\n            df_samples_b |> tidybayes::mode_qi(samples_b)) |> \n  dplyr::select(samples_b, .point) |> \n  dplyr::bind_rows(mode2_b) |>\n  \n## 2. create two columns to annotate the plot #######\n  dplyr::mutate(x = c(.55, .55, .75, .75),\n         y = c(.0006, .0011, .0016, .0021))\n\n## 3. plot ##########################################\ndf_samples_b |> \n  ggplot2::ggplot(ggplot2::aes(x = samples_b)) +\n  ggplot2::geom_area(ggplot2::aes(y = posterior_samples_b),\n           fill = \"deepskyblue\") +\n  ggplot2::geom_vline(xintercept = point_estimates_b2$samples_b) +\n  ggplot2::geom_text(data = point_estimates_b2,\n            ggplot2::aes(x = x, y = y, label = .point)) +\n  ggplot2::labs(x = \"proportion of water (p)\",\n       y = \"density\") +\n  ggplot2::theme(panel.grid = ggplot2::element_blank()) +\n  ggplot2::theme_bw() + \n\n## 4. annotation (arrows & text) ####################\n  ggplot2::geom_segment(\n    ggplot2::aes(x = 0.4, y = .0005, xend = point_estimates_b2$samples_b[[1]], yend = .0005),\n    arrow = grid::arrow(length = grid::unit(0.5, \"cm\"))) +\n  ggplot2::geom_segment(\n    ggplot2::aes(x = 0.4, y = .001, xend = point_estimates_b2$samples_b[[2]], yend = .001),\n    arrow = grid::arrow(length = grid::unit(0.5, \"cm\"))) +  \n  ggplot2::geom_segment(\n    ggplot2::aes(x = 0.85, y = .0015, xend = point_estimates_b2$samples_b[[3]], yend = .0015),\n    arrow = grid::arrow(length = grid::unit(0.5, \"cm\"))) +\n  ggplot2::geom_segment(\n    ggplot2::aes(x = 0.85, y = .002, xend = point_estimates_b2$samples_b[[4]], yend = .002),\n    arrow = grid::arrow(length = grid::unit(0.5, \"cm\"))\n)\n```\n\n::: {.cell-output-display}\n![Point estimates in the almost symmetrical distribution of 6 'water' in 9 tosses. Vertical lines show the locations of the mode, median, and mean. All three points are in a similar locatioon and have approximately the same loss function.](03-sampling-the-imaginary_files/figure-html/fig-left-panel-3-4-sym-b2-1.png){#fig-left-panel-3-4-sym-b2 width=672}\n:::\n:::\n\n\n:::::{.my-watch-out}\n:::{.my-watch-out-header}\nMAP (mode) is not the highest point in the more symmetric version (6 'W', n=9)\n:::\n::::{.my-watch-out-container}\nI wounder if the calculation of the MAP of the somewhat symmetrical version is correct, because the MAP or mode is not the highest value in the distribution. In addition to calculate the mode with {**tidybayes**}, I have also used R code 3.14b from @cnj-point-estimates-b to compute MAP with `dplyr::arrange(dplyr::desc())`.\n\nIt turns out that there is difference: In contrast to  {**tidybayes**} arranging the data frame results in a MAP value (`mode2`) which is indeed the highest point of the distribution. I don't know how to interpret this disparity.\n::::\n:::::\n\n\n:::\n::::\n:::::\n\n##### Loss function to support particular decisions\n\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-expected-loss-b}\nb: Calculated expected loss for $p = 0.5$ with proportional and quadratic loss function\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.panel-tabset}\n\n\n###### $d-p$\n\nThe absolute proportional loss $d-p$ for the decision $p = 0.5$ results into the median.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.17b weighted average loss ##################\nloss_avg_b <- d_skewed_b |> \n    dplyr::summarise(`expected loss` = \n               base::sum(posterior_skewed_b * base::abs(0.5 - p_grid_b)))\n\n## R code 3.18b for every possible value #############################\n\n## write function\nmake_loss_b <- function(our_d) {\n  d_skewed_b |> \n    dplyr::mutate(loss_b = posterior_skewed_b * base::abs(our_d - p_grid_b)) |> \n    dplyr::summarise(weighted_average_loss_b = base::sum(loss_b))\n}\n\n## calculate loss for all possible values \nglue::glue(\"Every possible loss values for decision 0.5 with proportional loss function\\n\")\n(\n  l_b <-\n  d_skewed_b |> \n  dplyr::select(p_grid_b) |> \n  dplyr::rename(decision_b = p_grid_b) |> \n  dplyr::mutate(weighted_average_loss_b = purrr::map(decision_b, make_loss_b)) |> \n  tidyr::unnest(weighted_average_loss_b) \n)\n\n## R code 3.19b minimized loss value #############################\n# this will help us find the x and y coordinates for the minimum value\nloss_min_b <-\n    l_b |> \n    dplyr::filter(weighted_average_loss_b == base::min(weighted_average_loss_b)) |> \n    base::as.numeric()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Every possible loss values for decision 0.5 with proportional loss function\n#> # A tibble: 1,000 × 2\n#>    decision_b weighted_average_loss_b\n#>         <dbl>                   <dbl>\n#>  1    0                         0.800\n#>  2    0.00100                   0.799\n#>  3    0.00200                   0.798\n#>  4    0.00300                   0.797\n#>  5    0.00400                   0.796\n#>  6    0.00501                   0.795\n#>  7    0.00601                   0.794\n#>  8    0.00701                   0.793\n#>  9    0.00801                   0.792\n#> 10    0.00901                   0.791\n#> # ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\n**Results:**\n\n- Weighted average loss value = 0.3128752.\n- Parameter value that minimizes the loss = 0.8408408. This is the posterior median that we already have calculated in @cnj-point-estimates-b. Because of sampling variation it is not identical but pretty close (0.8428428 versus 0.8408408).\n\n###### $(d−p)^{2}$\n\nThe quadratic loss $(d−p)^{2}$ for the decision $p = 0.5$ suggests we should use the mean.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.17b weighted average loss ##################\nloss_avg_b2 <- d_skewed_b |> \n    dplyr::summarise(`expected loss` = \n               base::sum(posterior_skewed_b * base::sqrt(abs(0.5 - p_grid_b))))\n\n## R code 3.18b for every possible value #############################\n# amend our loss function\n\nmake_loss2_b <- function(our_d2) {\n  d_skewed_b |> \n    dplyr::mutate(loss2_b = posterior_skewed_b * (our_d2 - p_grid_b)^2) |> \n    dplyr::summarise(weighted_average_loss2_b = base::sum(loss2_b))\n}\n\n\n# remake our `l` data\nglue::glue(\"Every possible loss values for decision 0.5 with quadratic loss function\\n\")\n(\n  l2_b <-\n    d_skewed_b |> \n    dplyr::select(p_grid_b) |> \n    dplyr::rename(decision2_b = p_grid_b) |> \n    dplyr::mutate(weighted_average_loss2_b = purrr::map(decision2_b, make_loss2_b)) |> \n    tidyr::unnest(weighted_average_loss2_b)\n)\n\n## R code 3.19b minimized loss value #############################\n# update to the new minimum loss coordinates\n\n\nloss_min_b2 <-\n    l2_b |> \n    dplyr::filter(weighted_average_loss2_b == base::min(weighted_average_loss2_b)) |> \n    base::as.numeric()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Every possible loss values for decision 0.5 with quadratic loss function\n#> # A tibble: 1,000 × 2\n#>    decision2_b weighted_average_loss2_b\n#>          <dbl>                    <dbl>\n#>  1     0                          0.667\n#>  2     0.00100                    0.666\n#>  3     0.00200                    0.664\n#>  4     0.00300                    0.663\n#>  5     0.00400                    0.661\n#>  6     0.00501                    0.659\n#>  7     0.00601                    0.658\n#>  8     0.00701                    0.656\n#>  9     0.00801                    0.655\n#> 10     0.00901                    0.653\n#> # ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\n**Results:**\n\n- Weighted average loss value = 0.5390867.\n- Parameter value that minimizes the loss = 0.8008008. This is the posterior mean that we already have calculated in @cnj-point-estimates-b. Because of sampling variation it is not identical but pretty close (0.8027632 versus 0.8008008).\n\n\n:::\n::::\n:::::\n\n\n\nNow we're ready to reproduce the right panel of Figure 3.4., e.g., displaying the the loss function and computing the minimum loss value. Remember: Different loss functions imply different point estimates.\n\n\n\n:::::{.my-r-code}\n:::{.my-r-code-header}\n:::::: {#cnj-fig-prop-loss-b}\nb: Plot expected loss for $p = 0.5$ with proportional and quadratic loss function\n::::::\n:::\n::::{.my-r-code-container}\n\n::: {.panel-tabset}\n\n###### $d-p$\n\nThe absolute proportional loss $d-p$ for the decision $p = 0.5$ results into the median.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## right panel figure 3.4 ########################\n\nl_b |>   \n  ggplot2::ggplot(ggplot2::aes(x = decision_b, y = weighted_average_loss_b)) +\n  ggplot2::geom_area(fill = \"deepskyblue\") +\n  ggplot2::geom_vline(xintercept = loss_min_b[1], color = \"black\", linetype = 3) +\n  ggplot2::geom_hline(yintercept = loss_min_b[2], color = \"black\", linetype = 3) +\n  ggplot2::ylab(\"expected proportional loss\") +\n  ggplot2::theme(panel.grid = ggplot2::element_blank()) +\n  ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![Expected loss under the rule that loss is proportional to absolute distance of decision (horizontal axis) from the true value. The point marks the value of `p` that minimizes the expected loss, the posterior median.](03-sampling-the-imaginary_files/figure-html/fig-prop-loss-b-1.png){#fig-prop-loss-b width=672}\n:::\n:::\n\n\nWe saved the exact minimum value as `loss_min_b[1]`, which is\n0.8408408. Within sampling error, this is the posterior median\nas depicted by our samples (0.8428428 versus 0.8408408).\n\n\n\n###### $(d−p)^{2}$\n\nThe quadratic loss $(d−p)^{2}$ for the decision $p = 0.5$ suggests we should use the mean.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# update the plot\nl2_b |>   \n  ggplot2::ggplot(ggplot2::aes(x = decision2_b, y = weighted_average_loss2_b)) +\n  ggplot2::geom_area(fill = \"deepskyblue\") +\n  ggplot2::geom_vline(xintercept = loss_min_b2[1], color = \"black\", linetype = 3) +\n  ggplot2::geom_hline(yintercept = loss_min_b2[2], color = \"black\", linetype = 3) +\n  ggplot2::ylab(\"expected proportional loss\") +\n  ggplot2::theme(panel.grid = ggplot2::element_blank()) +\n  ggplot2::theme_bw()\n```\n\n::: {.cell-output-display}\n![Expected loss under the rule that loss is quadratic to the distance of decision (horizontal axis) from the true value. The point marks the value of `p` that minimizes the expected loss, the posterior mean](03-sampling-the-imaginary_files/figure-html/fig-quad-loss-b-1.png){#fig-quad-loss-b width=672}\n:::\n:::\n\n\nBased on quadratic loss $(d−p)^{2}$, the exact minimum value is\n0.8008008. Within sampling error, this is the posterior mean of\nour samples (0.8027632 versus 0.8008008).\n\n:::\n\n::::\n:::::\n\n## I STOPPED HERE (2nd PASS, 2023-11-12)\n\n## Sampling to simulate prediction\n\n### Original\n\nTo generate implied observations from a model is useful for at least\nfive reasons:\n\n1.  **Model design**: We can sample not only from the posterior, but\n    also from the prior. Seeing what the model expects, before the data\n    arrive, is the best way to understand the implications of the prior.\n    We'll do a lot of this in later chapters, where there will be\n    multiple parameters and so their joint implications are not always\n    very clear.\n2.  **Model checking**: After a model is updated using data, it is worth\n    simulating implied observations, to check both whether the fit\n    worked correctly and to investigate model behavior.\n3.  **Software validation**: In order to be sure that our model fitting\n    software is working, it helps to simulate observations under a known\n    model and then attempt to recover the values of the parameters the\n    data were simulated under.\n4.  **Research design**: If you can simulate observations from your\n    hypothesis, then you can evaluate whether the research design can be\n    effective. In a narrow sense, this means doing power analysis, but\n    the possibilities are much broader.\n5.  **Forecasting**: Estimates can be used to simulate new predictions,\n    for new cases and future observations. These forecasts can be useful\n    as applied prediction, but also for model criticism and revision.\n\n#### Dummy data\n\n> Now note that these assumptions not only allow us to infer the\n> plausibility of each possible value of *p*, after observation. That's\n> what you did in the previous chapter. These assumptions also allow us\n> to simulate the observations that the model implies. They allow this,\n> because likelihood functions work in both directions. Given a realized\n> observation, the likelihood function says how plausible the\n> observation is. And given only the parameters, the likelihood defines\n> a distribution of possible observations that we can sample from, to\n> simulate observation. In this way, Bayesian models are always\n> *generative*, capable of simulating predictions. Many non-Bayesian\n> models are also generative, but many are not.\n>\n> We will call such simulated data **DUMMY DATA**, to indicate that it\n> is a stand-in for actual data.\n\n##### Probability of each globe toss\n\n> Suppose $N = 2$, two tosses of the globe. Then there are only three\n> possible observations: 0 water, 1 water, 2 water. You can quickly\n> compute the probability of each, for any given value of *p*. Let's use\n> $p = 0.7$, which is just about the true proportion of water on the\n> Earth:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## R code 3.20 #############################\ndbinom(0:2, size = 2, prob = 0.7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.09 0.42 0.49\n```\n\n\n:::\n:::\n\n\n##### Simulation of globe tosses\n\n> Now we're going to simulate observations, using these probabilities.\n> This is done by sampling from the distribution just described above.\n> You could use `sample()` to do this, but R provides convenient\n> sampling functions for all the ordinary probability distributions,\n> like the binomial.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3) # for reproducibility\n\n## R code 3.21 #############################\nrbinom(1, size = 2, prob = 0.7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 2\n```\n\n\n:::\n:::\n\n\n(As the outcome results from a random process the above value differs\nfrom the SR2 version. But with `set.seed(3)`\\` you will get the same\nvalue of $2$.)\n\n> That $1$ means \"2 water in 2 tosses.\" The \"`r`\" in `rbinom` stands for\n> \"random.\" It can also generate more than one simulation at a time. A\n> set of 10 simulations can be made by:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3)\n## R code 3.22 #############################\nrbinom(10, size = 2, prob = 0.7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  [1] 2 1 2 2 1 1 2 2 1 1\n```\n\n\n:::\n:::\n\n\n> Let's generate 100,000 dummy observations, just to verify that each\n> value (0, 1, or 2) appears in proportion to its likelihood:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3)\n## R code 3.23 #############################\ndummy_w_a <- rbinom(1e5, size = 2, prob = 0.7)\ntable(dummy_w_a) / 1e5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> dummy_w_a\n#>       0       1       2 \n#> 0.09000 0.42051 0.48949\n```\n\n\n:::\n:::\n\n\n##### Plot simulation of globe tosses\n\nWe could use either the base R `graphics::hist()` or --- as in the SR2\nbook --- the `rethinking::simplehist()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3)\ndummy_w_a <- rbinom(1e5, size = 9, prob = 0.7)\nhist(dummy_w_a, xlab = \"dummy water count\")\n```\n\n::: {.cell-output-display}\n![Distribution of simulated sample observations from 9 tosses of the globe. These samples assume the proportion of water is 0.7. The plot uses the base R `hist()` function](03-sampling-the-imaginary_files/figure-html/fig-plot-hist-figure-3.5-a-1.png){#fig-plot-hist-figure-3.5-a width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3)\n## R code 3.24 #############################\ndummy_w_a <- rbinom(1e5, size = 9, prob = 0.7)\nrethinking::simplehist(dummy_w_a, xlab = \"dummy water count\")\n```\n\n::: {.cell-output-display}\n![Distribution of simulated sample observations from 9 tosses of the globe. These samples assume the proportion of water is 0.7. the plot uses the rethinking::simplehist() function](03-sampling-the-imaginary_files/figure-html/fig-plot-simplehist-figure-3.5-a-1.png){#fig-plot-simplehist-figure-3.5-a width=672}\n:::\n:::\n\n\n> Notice that most of the time the expected observation does not contain\n> water in its true proportion, 0.7. That's the nature of observation:\n> There is a one-to-many relationship between data and data-generating\n> processes. You should experiment with sample size, the `size` input in\n> the code above, as well as the prob, to see how the distribution of\n> simulated samples changes shape and location.\n\n> Many readers will already have seen simulated observations. **SAMPLING\n> DISTRIBUTIONS** are the foundation of common non-Bayesian statistical\n> traditions. In those approaches, inference about parameters is made\n> through the sampling distribution. In this book, inference about\n> parameters is never done directly through a sampling distribution. The\n> posterior distribution is not sampled, but deduced logically. Then\n> samples can be drawn from the posterior, as earlier in this chapter,\n> to aid in inference. In neither case is \"sampling\" a physical act. In\n> both cases, it's just a mathematical device and produces only *small\n> world* (@sec-chap02) numbers.\n\n#### Model checking\n\n> MODEL CHECKING means (1) ensuring the model fitting worked correctly\n> and (2) evaluating the adequacy of a model for some purpose. Since\n> Bayesian models are always *generative*, able to simulate observations\n> as well as estimate parameters from observations, once you condition a\n> model on data, you can simulate to examine the model's empirical\n> expectations.\n\n> We'd like to *propagate* the parameter uncertainty---carry it\n> forward---as we evaluate the implied predictions. All that is required\n> is averaging over the posterior density for `p`, while computing the\n> predictions. For each possible value of the parameter `p`, there is an\n> implied distribution of outcomes. So if you were to compute the\n> sampling distribution of outcomes at each value of `p`, then you could\n> average all of these prediction distributions together, using the\n> posterior probabilities of each value of `p`, to get a POSTERIOR\n> PREDICTIVE DISTRIBUTION.\n\nThe reproduction of FIGURE 3.6 that illustrates this averaging is shown\nin ref###.\n\n> we need to learn how to combine sampling of simulated observations, as\n> in the previous section, with sampling parameters from the posterior\n> distribution. We expect to do better when we use the entire posterior\n> distribution, not just some point estimate derived from it.\n\nSo how do you actually do the calculations?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3)\n## R code 3.25 #############################\nw_a <- rbinom(1e4, size = 9, prob = 0.6)\nrethinking::simplehist(w_a)\n```\n\n::: {.cell-output-display}\n![](03-sampling-the-imaginary_files/figure-html/sim-pred-values-a-1.png){width=672}\n:::\n:::\n\n\n> This generates 10,000 (1e4) simulated predictions of 9 globe tosses\n> (size=9), assuming $p = 6$. The predictions are stored as counts of\n> water, so the theoretical minimum is zero and the theoretical maximum\n> is nine.\n\nWe used `rethinking::`simplehist(w_a)\\` to get a clean histogram of the\nsimulated outcomes.\n\n> All you need to propagate parameter uncertainty into these predictions\n> is replace the value 0.6 with samples from the posterior:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-sim-pred-samples-a lst-cap=\"Generate 1e4 random binomial samples to simulate predicted observations for $p = 0.6$\"}\nset.seed(3)\n## R code 3.26 #############################\nw2_a <- rbinom(1e4, size = 9, prob = samples_a)\nrethinking::simplehist(w2_a)\n```\n\n::: {.cell-output-display}\n![Random binomial samples to simulate predicted observations for $p = 0.6$](03-sampling-the-imaginary_files/figure-html/fig-sim-pred-samples-a-1.png){#fig-sim-pred-samples-a width=672}\n:::\n:::\n\n\nThe symbol `samples_a` above is the same list of random samples from the\nposterior distribution that we have calculated in @cnj-sample-globe-tossing\nand used in previous sections.\n\n> For each sampled value, a random binomial observation is generated.\n> Since the sampled values appear in proportion to their posterior\n> probabilities, the resulting simulated observations are averaged over\n> the posterior. You can manipulate these simulated observations just\n> like you manipulate samples from the posterior---you can compute\n> intervals and point statistics using the same procedures.\n\n> The simulated model predictions are quite consistent with the observed\n> data in this case---the actual count of 6 lies right in the middle of\n> the simulated distribution. ... So far, we've only viewed the data\n> just as the model views it: Each toss of the globe is completely\n> independent of the others. This assumption is questionable.\n\n> So with the goal of seeking out aspects of prediction in which the\n> model fails, let's look at the data in two different ways. Recall that\n> the sequence of nine tosses was `W L W W W L W L W`. First, consider\n> the length of the longest run of either water or land. This will\n> provide a crude measure of correlation between tosses. So in the\n> observed data, the longest run is 3 W's. Second, consider the number\n> of times in the data that the sample switches from water to land or\n> from land to water. This is another measure of correlation between\n> samples. In the observed data, the number of switches is 6. There is\n> nothing special about these two new ways of describing the data. They\n> just serve to inspect the data in new ways. In your own modeling,\n> you'll have to imagine aspects of the data that are relevant in your\n> context, for your purposes.\n\nFIGURE 3.7 showing the simulated predictions, viewed in these two new\nways, is reproduced in ref###. I have also postponed the interpretation\nof Figure 3.7 to ref###, because it is more understandable viewing the\nplots.\n\n### Tidyverse\n\n#### Dummy data\n\n> Dummy data for the globe tossing model arise from the binomial\n> likelihood.\n\n##### Probability of each globe toss\n\nSuppose $N = 2$, two tosses of the globe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(n      = 2,\n       `p(w)` = .7,\n       w      = 0:n) |> \n  mutate(density = dbinom(w, size = n, prob = `p(w)`))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 3 × 4\n#>       n `p(w)`     w density\n#>   <dbl>  <dbl> <int>   <dbl>\n#> 1     2    0.7     0    0.09\n#> 2     2    0.7     1    0.42\n#> 3     2    0.7     2    0.49\n```\n\n\n:::\n:::\n\n\n##### Simulation of globe tosses\n\nSimulate one globe toss:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3)\nrbinom(1, size = 2, prob = .7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 2\n```\n\n\n:::\n:::\n\n\nSimulate 10 globe tosses.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3)\nrbinom(10, size = 2, prob = .7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  [1] 2 1 2 2 1 1 2 2 1 1\n```\n\n\n:::\n:::\n\n\nNow generate 100,000 (i.e., 1e5) reproducible dummy observations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_draws_b <- 1e5\n\nset.seed(3)\ndummy_w_b <- tibble(draws = rbinom(n_draws_b, size = 2, prob = .7)) \n    \n    dummy_w_b |> \n        count(draws) |> \n        mutate(proportion = n / nrow(dummy_w_b))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 3 × 3\n#>   draws     n proportion\n#>   <int> <int>      <dbl>\n#> 1     0  9000      0.09 \n#> 2     1 42051      0.421\n#> 3     2 48949      0.489\n```\n\n\n:::\n:::\n\n\n##### Plot simulation of globe tosses\n\nThe simulation updated to $n=9$ and plotting the tidyverse version of\nFigure 3.5.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_draws_b <- 1e5\n\nset.seed(3)\ndummy_w2_b <- tibble(draws = rbinom(n_draws_b, size = 9, prob = .7))\n\np1 <- dummy_w2_b |> \n    ggplot(aes(x = draws)) + \n    geom_histogram(binwidth = 1, center = 0,\n                 fill = \"deepskyblue\", color = \"black\", \n                 linewidth = 1/10) +\n    # breaks = 0:10 * 2 = equivalent in Kurz's versions:  breaks = 0:4 * 2\n    scale_x_continuous(\"dummy water count\", breaks = 0:10 * 2) +\n    ylab(\"frequency\") +\n    coord_cartesian(xlim = c(0, 9)) +\n    theme(panel.grid = ggplot2::element_blank())\n\np2 <- dummy_w2_b |> \n    ggplot(aes(x = draws)) + \n    geom_histogram(binwidth = 1, center = 0,\n                 fill = \"deepskyblue\", color = \"black\", \n                 linewidth = 1/10) +\n    ## breaks = 0:10 * 2 = equivalent in Kurz's versions:  breaks = 0:4 * 2\n    ## I decided to set a break at each of the draws: breaks = 0:9 * 1\n    scale_x_continuous(\"dummy water count\", breaks = 0:9 * 1) +\n    ylab(\"frequency\") +\n    ## I did not zoom into the graph because doesn't look so nice\n    ## for instance the last line is not visible\n    # coord_cartesian(xlim = c(0, 9)) +\n    theme(panel.grid = ggplot2::element_blank())\n\nlibrary(patchwork)\np1 + p2\n```\n\n::: {.cell-output-display}\n![Distribution of simulated sample observations from 9 tosses of the globe. These samples assume the proportion of water is 0.7. The plot uses the {**ggplot2**} functions. The left panel is Kurz's original, the right one is my version slightly changed.](03-sampling-the-imaginary_files/figure-html/fig-plot-ggplot2-figure-3.5-b-1.png){#fig-plot-ggplot2-figure-3.5-b width=672}\n:::\n:::\n\n\n##### Simulating and plotting 9 conditions\n\nMcElreath suggested we play around with different values of `size` and\n`prob`. The next block of code simulates nine conditions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_draws <- 1e5\n\nsimulate_binom <- function(n, probability) {\n  set.seed(3)\n  rbinom(n_draws, size = n, prob = probability) \n}\n\nd9_b <-\n  crossing(n9_b           = c(3, 6, 9),\n           probability9_b = c(.3, .6, .9)) |> \n  mutate(draws9_b = map2(n9_b, probability9_b, simulate_binom)) |> \n  ungroup() |> \n  mutate(n           = str_c(\"n = \", n9_b),\n         probability = str_c(\"p = \", probability9_b)) |> \n  unnest(draws9_b)\n\nd9_b |> \n    slice_sample(n = 10) |> \n    arrange(n9_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 10 × 5\n#>     n9_b probability9_b draws9_b n     probability\n#>    <dbl>          <dbl>    <int> <chr> <chr>      \n#>  1     3            0.3        2 n = 3 p = 0.3    \n#>  2     3            0.9        3 n = 3 p = 0.9    \n#>  3     3            0.9        3 n = 3 p = 0.9    \n#>  4     3            0.9        3 n = 3 p = 0.9    \n#>  5     3            0.6        3 n = 3 p = 0.6    \n#>  6     6            0.9        5 n = 6 p = 0.9    \n#>  7     6            0.9        5 n = 6 p = 0.9    \n#>  8     6            0.6        3 n = 6 p = 0.6    \n#>  9     9            0.6        7 n = 9 p = 0.6    \n#> 10     9            0.3        3 n = 9 p = 0.3\n```\n\n\n:::\n:::\n\n\nI am still not very experienced with `tidyr::crossing()` and\n`tidyr::unnest()`:\n\n-   **`crossing()`** is a wrapper around `expand_grid()` and therefore\n    creates a tibble from all combination of inputs. In addition to\n    `expand_grid()` it de-duplicates and sorts its input.\n-   **`unnest()`** expands a list-column containing data frames into row\n    and columns. In the above case `map2()` returns a list and stores\n    the data in `draws9_b`.\n\nInstead of `head()` I used `dplyr::slice_sample()` and ordered the\nresult by the first column. I think this will get a better glimpse on\nthe data as just the first 6 rows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd9_b |> \n  ggplot(aes(x = draws9_b)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 color = \"deepskyblue\", linewidth = 1/10) +\n  scale_x_continuous(\"dummy water count\", breaks = 0:4 * 2) +\n  ylab(\"frequency\") +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = ggplot2::element_blank()) +\n  facet_grid(n9_b ~ probability9_b)\n```\n\n::: {.cell-output-display}\n![](03-sampling-the-imaginary_files/figure-html/fig-sim-plot-9-cond-b-1.png){#fig-sim-plot-9-cond-b width=672}\n:::\n:::\n\n\n#### Model checking\n\nOn software checking Kurz refers to some material, that is too special\nfor me. So I do not include it here. Maybe I will come later here again\nwhen I have more experiences with Bayesian statistics and the necessary\ntools.\n\n##### Reproduction of Figure 3.6\n\nAt first I thought I do not need to refresh the original grid\napproximation from @lst-grid-approx-b as I have it stored it with the\nunique name `d_b`. But it turned out that the above code with\n`n_grid_b = 1000L` does not work, because it draws no vertical lines by\nthe posterior density. Instead one has to sample 1001 times.\n\nActually I do not know why this (small) difference is necessary, but I\nnoticed that with most sample numbers the plot does not work correctly.\nIt worked with 1071. The sequence 1011, 1021, 1031, 1041, 1051, 1061\nmisses just one vertical line at .7 Ab exception is 1041, which misses\n.6.\n\nSo I have to crate the data with 1001 samples again before I produce the\nplot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn2_b <- 1001L\nn_success <- 6L\nn_trials  <- 9L\n\n(\n  d2_b <-\n  tibble(p_grid2_b = seq(from = 0, to = 1, length.out = n2_b),\n         # note we're still using a flat uniform prior\n         prior2_b  = 1) |> \n  mutate(likelihood2_b = dbinom(n_success, size = n_trials, prob = p_grid2_b)) |> \n  mutate(posterior2_b = (likelihood2_b * prior2_b) / sum(likelihood2_b * prior2_b))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1,001 × 4\n#>    p_grid2_b prior2_b likelihood2_b posterior2_b\n#>        <dbl>    <dbl>         <dbl>        <dbl>\n#>  1     0            1      0            0       \n#>  2     0.001        1      8.37e-17     8.37e-19\n#>  3     0.002        1      5.34e-15     5.34e-17\n#>  4     0.003        1      6.07e-14     6.07e-16\n#>  5     0.004        1      3.40e-13     3.40e-15\n#>  6     0.005        1      1.29e-12     1.29e-14\n#>  7     0.006        1      3.85e-12     3.85e-14\n#>  8     0.007        1      9.68e-12     9.68e-14\n#>  9     0.008        1      2.15e-11     2.15e-13\n#> 10     0.009        1      4.34e-11     4.34e-13\n#> # ℹ 991 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nd2_b |> \n  ggplot(aes(x = p_grid2_b, y = posterior2_b)) +\n  geom_area(color = \"deepskyblue\", fill = \"deepskyblue\") +\n  geom_segment(data = d2_b |>   # must use data explictly instead of %>% and dot (.) \n                 filter(p_grid2_b %in% c(seq(from = .1, to = .9, by = .1), 3 / 10)),\n               aes(xend = p_grid2_b, yend = 0, linewidth = posterior2_b),\n               color = \"black\", show.legend = F) +\n  geom_point(data = d2_b |>     # must use data explictly instead of %>%  and dot (.)\n               filter(p_grid2_b %in% c(seq(from = .1, to = .9, by = .1), 3 / 10))) +\n  annotate(geom = \"text\", \n           x = .08, y = .0025,\n           label = \"Posterior probability\") +\n  scale_linewidth_continuous(range = c(0, 1)) +\n  scale_x_continuous(\"probability of water\", breaks = 0:10 / 10) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  theme(panel.grid = ggplot2::element_blank())\n```\n\n::: {.cell-output-display}\n![Reproduction of the top part of figure 3.6](03-sampling-the-imaginary_files/figure-html/fig-repr-figure-3.6-top-b-1.png){#fig-repr-figure-3.6-top-b width=672}\n:::\n:::\n\n\nWe'll need to do a bit of wrangling before we're ready to make the plot\nin the middle panel of Figure 3.6.\n\nGAP HERE! (2023-07-31) THERE IS A GAP BECAUSE THE FOLLOWING CODE CHUNKS\nOF CHAP 3.3 (MOSTLY DRAWINGS) ARE FOR MY PURPOSE (LEARNING BAYESIAN\nSTATISTICS) NOT RELEVANT.\n\n## Synopsis\n\nThe third chapter teaches the basic skills for working with samples from\nthe posterior distribution. The posterior distribution is a probability\ndistribution. And like all probability distributions, we can imagine\ndrawing samples from it.\n\n### Sampling from a grid-approximate posterior\n\nBefore beginning to work with samples, we need to generate them with\n@lst-grid-approx-base-demo respectively with\n@lst-grid-approx-tidyverse-demo. Then we can draw - for instance -\n10,000 samples from the posterior. To make the random draws reproducible\nwe will use `base::set.seed()` with a see of 3.\n\n#### Base R\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-draw-samples-base-demo lst-cap=\"Drawing 10,000 sample from the posterior using `base::sample()`\"}\n## R code 3.2 ###########################\n## compute the posterior for the globe tossing model, using grid approximation\np_grid_r <- seq(from = 0, to = 1, length.out = 1000)\nprob_p <- rep(1, 1000)\nprob_data <- dbinom(6, size = 9, prob = p_grid_r)\nposterior <- prob_data * prob_p\nposterior_r <- posterior / sum(posterior)\n\nset.seed(3)\n\n## R code 3.3 ###########################\n## draw 10,000 samples from the posterior.\nsamples_r <- sample(p_grid_r, prob = posterior_r, size = 1e4, replace = TRUE)\n```\n:::\n\n\n#### Tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-draw-samples-tidyverse-demo lst-cap=\"Drawing 10,000 sample from the posterior using `dplyr::slice_sample()`\"}\n# how many grid points would you like?\nn <- 1000\nn_success <- 6\nn_trials  <- 9\n\n  d_t <-\n  tibble(p_grid_t = seq(from = 0, to = 1, length.out = n),\n         # note we're still using a flat uniform prior\n         prior_t  = 1) |> \n  mutate(likelihood_t = dbinom(n_success, size = n_trials, prob = p_grid_t)) |> \n  mutate(posterior_t = (likelihood_t * prior_t) / sum(likelihood_t * prior_t))\n\nset.seed(3)\nsamples_t <-\n  d_t |> \n    slice_sample(n = 1e4, weight_by = posterior_t, replace = T)\n```\n:::\n\n\n### Sampling to summarize\n\nThe next step after sampling is to summarize and interpret the posterior\ndistribution. The type of summary depends upon your purpose. But common\nquestions include:\n\n-   How much posterior probability lies below some parameter value?\n-   How much posterior probability lies between two parameter values?\n-   Which parameter value marks the lower 5% of the posterior\n    probability?\n-   Which range of parameter values contains 90% of the posterior\n    probability?\n-   Which parameter value has highest posterior probability?\n\nThese questions can be divided into :\n\n1.  Questions about intervals of *defined boundaries*\n    (\\@sec-intervals-of-defined-boundaries)\n2.  Qustions about Intervals of *defined probability mass*\n    (\\@sec-intervals-of-defined-probability-mass) and\n3.  Questions about *point estimates* (\\@sec-point-estimates)\n\n#### Intervals of defined boundaries {#sec-intervals-of-defined-boundaries}\n\nFor instance I will ask for the posterior probability that the\nproportion of water is less than 0.5. We could use the grid-approximate\nposterior to just add up all all of the probabilities, where the\ncorresponding parameter value is less than 0.5\n\nBut since grid approximation isn't practical in general, it won't always\nbe so easy. Once there is more than one parameter in the posterior\ndistribution, even this simple sum is no longer very simple. So wee need\nto perform the same calculation, using samples from the posterior.\n\n##### Base R: Define boundary\n\nUsing the grid-approximate posterior:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-define-boundary-from-grid-base-demo lst-cap=\"Define boundary by using the grid-approximate posterior with base R functions\"}\n## R code 3.6 #############################\n# add up posterior probability where p < 0.5\nsum(posterior_r[p_grid_r < 0.5])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.1718746\n```\n\n\n:::\n:::\n\n\nUsing the samples from the posterior:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-define-boundary-from-samples-base-demo lst-cap=\"Define boundary by summing up the samples from the posterior with base R functions\"}\n## R code 3.7 #############################\n## sum samples of posterior probability where p < 0.5\nsum(samples_r < 0.5) / 1e4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.1629\n```\n\n\n:::\n\n```{.r .cell-code #lst-define-boundary-from-samples-base-demo lst-cap=\"Define boundary by summing up the samples from the posterior with base R functions\"}\n## R code 3.8 #############################\n## find boundaries samples of posterior probability \n## where p lies between 0.5 and 0.75\nsum(samples_r > 0.5 & samples_r < 0.75) / 1e4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.6061\n```\n\n\n:::\n:::\n\n\n##### Tidyverse: Define boundary\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-define-boundary-from-grid-tidyverse-demo lst-cap=\"Define boundary by using the grid-approximate posterior with {tidyverse} functions\"}\n## add up posterior probability where p < 0.5\nd_t |> \n  filter(p_grid_t < .5) |> \n  summarise(sum = sum(posterior_t))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.172\n```\n\n\n:::\n:::\n\n\nUsing the samples from the posterior:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-define-boundary-from-samples-tidyverse-demo lst-cap=\"Define boundary by summing up the samples from the posterior with {tidyverse} function `filter()` and `summarize()`\"}\n## filter and summarize samples of posterior probability where p < 0.5\nsamples_t |>\n  filter(p_grid_t < .5) |> \n  summarise(sum = n() / 1e4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.163\n```\n\n\n:::\n\n```{.r .cell-code #lst-define-boundary-from-samples-tidyverse-demo lst-cap=\"Define boundary by summing up the samples from the posterior with {tidyverse} function `filter()` and `summarize()`\"}\n## filter and summarize samples of posterior probability \n## where p lies between 0.5 and 0.75\nsamples_t |> \n  filter(p_grid_t > .5 & p_grid_t < .75) |> \n  summarise(sum = n() / 1e4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.606\n```\n\n\n:::\n:::\n\n\nA more explicit approach for the same computation is to follow up\n`dplyr::count()` with `dplyr::mutate()`.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-define-boundary-from-samples-tidyverse2-demo lst-cap=\"Define boundary by summing up the samples from the posterior with {tidyverse} functions `count()` and `mutate()`\"}\n## count and sum samples of posterior probability where p < 0.5\nsamples_t |> \n  count(p_grid_t < .5) |> \n  mutate(probability = n / sum(n))\n\n## count and sum samples of posterior probability \n## where p lies between .5 and .75\nsamples_t |> \n  count(p_grid_t > .5 & p_grid_t < .75) |> \n  mutate(probability = n / sum(n))\n```\n:::\n\n\n#### Intervals of defined probability mass {#sec-intervals-of-defined-probability-mass}\n\nIn scientific journals it is usual to report an interval of defined\nmass, usually known as a confidence interval. What the interval\nindicates is a range of parameter values compatible with the model and\ndata. The model and data themselves may not inspire confidence, in which\ncase the interval will not either. McElreath therefore call these areas\ncompatibility intervals.\n\nThese posterior intervals report two parameter values that contain\nbetween them a specified amount of posterior probability, a probability\nmass. For this type of interval, it is easier to find the answer by\nusing samples from the posterior than by using a grid approximation.\n\n##### Base R: Define probability mass\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-PI-base-demo lst-cap=\"Boundaries of the lower 80% and middle 80% posterior probability: Base R version\"}\n## R code 3.9 #######################\n## find boundaries of the lower 80% posterior probability\nquantile(samples_r, 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       80% \n#> 0.7627628\n```\n\n\n:::\n\n```{.r .cell-code #lst-PI-base-demo lst-cap=\"Boundaries of the lower 80% and middle 80% posterior probability: Base R version\"}\n## R code 3.10 ######################\n## find the interval of the middle 80% posterior probability\nquantile(samples_r, c(0.1, 0.9))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       10%       90% \n#> 0.4514515 0.8148148\n```\n\n\n:::\n:::\n\n\nIntervals of this sort, which assign equal probability mass to each\ntail, are very common in the scientific literature. We'll call them\n**percentile intervals (PI)**. These intervals do a good job of\ncommunicating the shape of a distribution, as long as the distribution\nisn't too asymmetrical.\n\nBut in highly skewed distribution they are --- in terms of supporting\ninferences about which parameters are consistent with the data --- not\nperfect. It could be the case that they do not include the most probable\nparameter variable (the mode or MAP, Maximum A Posterior). In this case\nyou should use the **highest posterior density interval (HPDI)**.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-HPDI-base-demo lst-cap=\"Boundaries of the lower 80% and middle 80% posterior probability: Base R version\"}\n## R code 3.13 ##################################\n## find the narrowest region with 50% of the posterior probability\nrethinking::HPDI(samples_r, prob = 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>      |0.5      0.5| \n#> 0.5695696 0.7607608\n```\n\n\n:::\n:::\n\n\n##### Tidyverse: Define probability mass\n\nAs in the base R version the tidyverse variant is also using the\n`quantile()`\\` function. The only difference is the call of the correct\nvector. Since `p_grid` samples are saved in the `samples` tibble, we'll\nhave to index with `$` within `quantile()`.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-PI-tidyverse-demo lst-cap=\"Boundaries of the lower 80% and middle 80% posterior probability: tidyverse version\"}\n## find boundaries of the lower 80% posterior probability\nquantile(samples_t$p_grid_t, prob = .8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       80% \n#> 0.7627628\n```\n\n\n:::\n\n```{.r .cell-code #lst-PI-tidyverse-demo lst-cap=\"Boundaries of the lower 80% and middle 80% posterior probability: tidyverse version\"}\n## find the interval of the middle 80% posterior probability\nquantile(samples_t$p_grid_t, prob = c(.1, .9))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       10%       90% \n#> 0.4514515 0.8148148\n```\n\n\n:::\n:::\n\n\nFor calculating the HPDI we will use the {**tidybayes**} package. which\noffers an array of convenience functions for summarizing Bayesian\nmodels.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-HPDI-tidyverse-demo lst-cap=\"Boundaries of the lower 80% and middle 80% posterior probability: Base R version\"}\n## find the narrowest region with 50% of the posterior probability\ntidybayes::mode_hdci(samples_t$p_grid_t, .width = .5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.6508383 0.5685686 0.7597598    0.5   mode      hdci\n```\n\n\n:::\n:::\n\n\n#### Point Estimates {#sec-point-estimates}\n\nPoint estimates are of limited value: The Bayesian parameter estimate is\nprecisely the entire posterior distribution, which is not a single\nnumber, but instead a function that maps each unique parameter value\nonto a plausibility value. So really the most important thing to note is\nthat you don't have to choose a point estimate. It's hardly ever\nnecessary and often harmful. It discards information.\n\n##### Base R\n\n###### Find the mode (MAP) from the grid approximation\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-MAP-grid-base-demo lst-cap=\"Find value with the highest posterior probability, also called maximum a posteriori (MAP) estimate, from the grid approximation: Base R version\"}\n## R code 3.14 ######################\n## find highest posterior probability (MAP) from grid approx\np_grid_r[which.max(posterior_r)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.6666667\n```\n\n\n:::\n:::\n\n\n###### Find the MAP (mode) from the samples from the posterior\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-MAP-posterior-rethinking-demo lst-cap=\"Find value with the highest posterior probability, also called maximum a posteriori (MAP) estimate, from the posterior: rethinking version\"}\n## R code 3.15 ######################\n## find highest posterior probability (MAP) from the posterior\nrethinking::chainmode(samples_r, adj = 0.01)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.6324631\n```\n\n\n:::\n:::\n\n\n###### Loss function\n\nBut why is this point, the mode, interesting? Why not report the\nposterior mean or median? These are also point estimates, and they also\nsummarize the posterior. But all three---the mode (MAP), mean, and\nmedian---are different in this case. How can we choose?\n\nOne principled way to go beyond the both extremes (choosing just a point\nestimate or using the entire posterior as the estimate) is to choose a\n**loss function**. A loss function is a rule that tells you the cost\nassociated with using any particular point estimate. \n\n\n\n\n*Different loss\nfunctions imply different point estimates!*\n\nSo suppose we decide $p = 0.5$ will be our decision:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-loss-0.5-base-demo lst-cap=\"Find loss for the decision 0.5: base version\"}\n## R code 3.17\n## loss with decision .05\nsum(posterior_r * abs(0.5 - p_grid_r))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.1640626\n```\n\n\n:::\n:::\n\n\nCalculating the loss function is repeating the calculation of\n@lst-loss-0.5-base-demo for every possible decision. Then you can\ndetermine the value for the decision with minimum loss.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-loss-minimum-base-demo lst-cap=\"Find decision for minimum loss: base version\"}\n## R code 3.18\nloss_r <- sapply(p_grid_r, function(d) sum(posterior_r * abs(d - p_grid_r)))\n\n## R code 3.19\np_grid_r[which.min(loss_r)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.6446446\n```\n\n\n:::\n:::\n\n\nAnd this is actually the posterior median, the parameter value that\nsplits the posterior density such that half of the mass is above it and\nhalf below it.\n\n##### Tidyverse\n\n###### Find the mode (MAP) from the posterior samples\n\nThree different ways to find the mode (MAP) with {**tidybayes**}:\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-MAP-tidyverse-demo lst-cap=\"Find value with the highest posterior probability, also called maximum a posteriori (MAP) estimate, with three different functions: tidybayes version\"}\nsamples_t |> \n    tidybayes::mode_qi(p_grid_t)\n\nsamples_t |> \n    tidybayes::mode_hdci(p_grid_t)\n\n## just the mode\ntidybayes::Mode(samples_t$p_grid_t)\n```\n:::\n\n\n###### Loss function\n\nFind loss with the decision $p = 0.5$.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-loss-0.5-tidyverse-demo lst-cap=\"Find loss for the decision 0.5: tidyverse version\"}\n## find loss with the decision of .5\nd_t |> \n  summarise(`expected loss` = sum(posterior_t * abs(0.5 - p_grid_t)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> # A tibble: 1 × 1\n#>   `expected loss`\n#>             <dbl>\n#> 1           0.164\n```\n\n\n:::\n:::\n\n\nFind minimum loss: The tidyverse version uses for the loop instead of\n`base::sapply()` the `purrr::map()` function from the {**purrr}**\npackage, a member of the {**tidyverse}** packages.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-loss-minimum-tidyverse-demo lst-cap=\"Find decision for minimum loss: tidyverse version\"}\nmake_loss_t <- function(our_d) {\n  d_t |> \n    mutate(loss_t = posterior_t * abs(our_d - p_grid_t)) |> \n    summarise(weighted_average_loss_t = sum(loss_t))\n}\n\nloss_t <- \n    d_t |> \n        select(p_grid_t) |> \n        rename(decision_t = p_grid_t) |> \n            mutate(weighted_average_loss_t = purrr::map(decision_t, make_loss_t)) |>\n        unnest(weighted_average_loss_t) \n  \nmin_loss_t <-\n  loss_t |> \n    filter(weighted_average_loss_t == min(weighted_average_loss_t)) |>\n    as.numeric()\n```\n:::\n\n\n### Sampling to simulate prediction\n\nAnother common job for samples is to ease simulation of the model's\nimplied observations. This is useful for 1. Model design 2. Model\nchecking 3. Software validation 4. Research design 5. Forecasting\n\n#### Dummy data\n\nInstead of using `dbinom()` to compute the probability of events, we\nwill use `rbinom()` to generate dummy data to simulate observations.\n\nWe will generate 100,000 dummy observations to verify that each value of\nthe globe tossing model (6 Waters with 9 tosses) appears in proportion\nto its likelihood:\n\n##### Base R\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-generate-dummy-obs-base-demo lst-cap=\"Generating dummy observation to simulate the probability of each value of the globe tossing model: base R version\"}\nset.seed(3)\n## R code 3.24 ###############################\ndummy_data_r <- rbinom(1e5, size = 9, prob = 0.7)\n## replace `rethinking::simplehist()` with base R `graphics::hist()`\nhist(dummy_data_r, xlab = \"dummy water count\") \n```\n\n::: {.cell-output-display}\n![Dsitribution of 100,000 dummy observations of the globe tossing model resulting in 6 Water with 9 tosses: base R version](03-sampling-the-imaginary_files/figure-html/fig-generate-dummy-obs-base-demo-1.png){#fig-generate-dummy-obs-base-demo width=672}\n:::\n:::\n\n\n##### Tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-generate-dummy-obs-tidyverse-demo lst-cap=\"Generating dummy observation to simulate the probability of each value of the globe tossing model: tidyverse version\"}\nset.seed(3)\nd2_t <- tibble(draws_t = rbinom(1e5, size = 9, prob = .7))\n\n# the histogram\nd2_t |> \n  ggplot(aes(x = draws_t)) +\n  geom_histogram(binwidth = 1, center = 0,\n                 fill = \"deepskyblue\", color = \"black\", linewidth = 1/10) +\n  scale_x_continuous(\"dummy water count\", breaks = 0:4 * 2) +\n  ylab(\"frequency\") +\n  theme(panel.grid = ggplot2::element_blank())\n```\n\n::: {.cell-output-display}\n![Dsitribution of 100,000 dummy observations of the globe tossing model resulting in 6 Water with 9 tosses: tidyverse version](03-sampling-the-imaginary_files/figure-html/generate-dummy-obs-tidyverse-demo-1.png){width=672}\n:::\n:::\n\n\n#### Model checking\n\nSince Bayesian models are always generative, able to simulate\nobservations as well as estimate parameters from observations, once you\ncondition a model on data, you can simulate to examine the model's\nempirical expectations.\n\nAll that is required is averaging over the posterior density for `p`,\nwhile computing the predictions. For each possible value of the\nparameter `p`, there is an implied distribution of outcomes. So if you\nwere to compute the sampling distribution of outcomes at each value of\n`p`, then you could average all of these prediction distributions\ntogether, using the posterior probabilities of each value of `p`, to get\na **posterior predictive distribution**.\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-post-pred-dist-r lst-cap=\"Using the posterior probabilities of each value of p, to get a posterior predictive distribution: rethinking version\"}\nset.seed(3)\n## R code 3.26 #############################\nw_predicted_r <- rbinom(1e4, size = 9, prob = samples_r)\nhist(w_predicted_r)\n```\n\n::: {.cell-output-display}\n![](03-sampling-the-imaginary_files/figure-html/post-pred-dist-r-1.png){width=672}\n:::\n:::\n\n\n##### Tidyverse\n\n\n::: {.cell}\n\n```{.r .cell-code #lst-post-pred-dist-t lst-cap=\"Using the posterior probabilities of each value of p, to get a posterior predictive distribution: tidyverse version\"}\nset.seed(3)\n\nsamples2_t <-\n  d_t |> \n  slice_sample(n = 1e4, weight_by = posterior_t, replace = T) |> \n  mutate(w_predicted_t = purrr::map_dbl(p_grid_t, rbinom, n = 1, size = 9))\n\n## plot histogram\nsamples2_t |> \n  ggplot(aes(x = w_predicted_t)) +\n  geom_histogram(binwidth = 1, center = 0, color = \"black\",\n                 fill = \"deepskyblue\", linewidth = 1/10) +\n  scale_x_continuous(\"number of water samples\",\n                     breaks = 0:3 * 3) +\n  scale_y_continuous(\"frequency\") +\n  ggtitle(\"Posterior predictive distribution\") +\n  coord_cartesian(ylim = c(0, 2000)) +\n  theme(panel.grid = ggplot2::element_blank())\n```\n\n::: {.cell-output-display}\n![](03-sampling-the-imaginary_files/figure-html/post-pred-dist-t-1.png){width=672}\n:::\n:::\n\n\n## I STOPPED HERE! (2023-08-01) TO BE CONTINUED {.unnumbered}\n\n## Practice\n\n## Practice with brms\n\n### Tidyverse (and {brms})\n\nWith {**brms**}, we'll fit the primary model of $w=6$ and $n=9$.\n\n#### Fit model with the {brms} package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb3.1 <-\n  brms::brm(data = list(w = 6), \n      family = binomial(link = \"identity\"),\n      w | trials(9) ~ 0 + Intercept,\n      # this is a flat prior\n      brms::prior(beta(1, 1), class = b, lb = 0, ub = 1),\n      iter = 5000, warmup = 1000,\n      seed = 3,\n      file = \"fits/b03.01\")\n```\n:::\n\n\nWe'll learn more about the beta distribution in Chapter 12. But for now,\nhere's the posterior summary for `b_Intercept`, the probability of a\n\"w\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrms::posterior_summary(b3.1)[\"b_Intercept\", ] |> \n  round(digits = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  Estimate Est.Error      Q2.5     Q97.5 \n#>      0.64      0.14      0.34      0.88\n```\n\n\n:::\n:::\n\n\n#### Simulate probability values\n\nI had problems with the following code chunk. See [my postings at Kurz's\nrepo](https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse_2_ed/issues/49).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf <-\n  brms:::fitted.brmsfit(b3.1, \n         summary = F,\n         scale = \"linear\") |> \n  data.frame() |> \n  rlang::set_names(\"p\")\n\nglimpse(f)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Rows: 16,000\n#> Columns: 1\n#> $ p <dbl> 0.6318994, 0.8105015, 0.7677781, 0.7250286, 0.7265799, 0.7376768, 0.…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nf |> \n  ggplot(aes(x = p)) +\n  geom_density(fill = \"deepskyblue\", color = \"deepskyblue\") +\n  annotate(geom = \"text\", x = .08, y = 2.5,\n           label = \"Posterior probability\") +\n  scale_x_continuous(\"probability of water\",\n                     breaks = c(0, .5, 1),\n                     limits = 0:1) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  theme(panel.grid = ggplot2::element_blank())\n```\n\n::: {.cell-output-display}\n![Density plot of the fittet {brms} model](03-sampling-the-imaginary_files/figure-html/fig-brms-model-density-1.png){#fig-brms-model-density width=672}\n:::\n:::\n\n\nThe graphic should look like the top part of Figure 3.6, reproduced as\n@fig-repr-figure-3.6-top-b. (I am not sure if the differences are\nimportant: I have a smaller apex and my curve is more irregular.)\n\n> Much like we did with samples, we can use this distribution of\n> probabilities to predict histograms of $w$ counts. With those in hand,\n> we can make an analogue to the histogram in the bottom panel of Figure\n> 3.6.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3)\nf <-\n  f |> \n  mutate(w2 = rbinom(n(), size = 9,  prob = p))\n\n# the plot\nf |> \n  ggplot(aes(x = w2)) +\n  geom_histogram(binwidth = 1, center = 0, color = \"black\",\n                 fill = \"deepskyblue\", linewidth = 1/10) +\n  scale_x_continuous(\"number of water samples\", breaks = 0:3 * 3) +\n  scale_y_continuous(NULL, breaks = NULL, limits = c(0, 5000)) +\n  ggtitle(\"Posterior predictive distribution\") +\n  coord_cartesian(xlim = c(0, 9)) +\n  theme(panel.grid = ggplot2::element_blank())\n```\n\n::: {.cell-output-display}\n![Simulation to predict posterior distribution](03-sampling-the-imaginary_files/figure-html/fig-sim-pred-values-b-1.png){#fig-sim-pred-values-b width=672}\n:::\n:::\n\n\n## Session info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> R version 4.3.2 (2023-10-31)\n#> Platform: x86_64-apple-darwin20 (64-bit)\n#> Running under: macOS Sonoma 14.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n#> \n#> locale:\n#> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n#> \n#> time zone: Europe/Vienna\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] patchwork_1.1.3     lubridate_1.9.3     forcats_1.0.0      \n#>  [4] stringr_1.5.0       dplyr_1.1.3         purrr_1.0.2        \n#>  [7] readr_2.1.4         tidyr_1.3.0         tibble_3.2.1       \n#> [10] ggplot2_3.4.4       tidyverse_2.0.0     glossary_1.0.0.9000\n#> \n#> loaded via a namespace (and not attached):\n#>   [1] svUnit_1.0.6         shinythemes_1.2.0    splines_4.3.2       \n#>   [4] later_1.3.1          cellranger_1.1.0     brms_2.20.4         \n#>   [7] xts_0.13.1           rpart_4.1.21         lifecycle_1.0.4     \n#>  [10] StanHeaders_2.26.28  processx_3.8.2       lattice_0.22-5      \n#>  [13] MASS_7.3-60          insight_0.19.6       crosstalk_1.2.0     \n#>  [16] ggdist_3.3.0         backports_1.4.1      magrittr_2.0.3      \n#>  [19] rmarkdown_2.25       yaml_2.3.7           httpuv_1.6.12       \n#>  [22] skimr_2.1.5          pkgbuild_1.4.2       gld_2.6.6           \n#>  [25] multcomp_1.4-25      abind_1.4-5          expm_0.999-7        \n#>  [28] tidybayes_3.0.6      TH.data_1.1-2        tensorA_0.36.2      \n#>  [31] sandwich_3.0-2       rmutil_1.1.10        inline_0.3.19       \n#>  [34] spatial_7.3-17       bridgesampling_1.1-2 commonmark_1.9.0    \n#>  [37] codetools_0.2-19     DT_0.30              xml2_1.3.5          \n#>  [40] tidyselect_1.2.0     shape_1.4.6          bayesplot_1.10.0    \n#>  [43] farver_2.1.1         stable_1.1.6         matrixStats_1.1.0   \n#>  [46] stats4_4.3.2         base64enc_0.1-3      jsonlite_1.8.7      \n#>  [49] e1071_1.7-13         ellipsis_0.3.2       survival_3.5-7      \n#>  [52] emmeans_1.8.9        tools_4.3.2          DescTools_0.99.50   \n#>  [55] Rcpp_1.0.11          glue_1.6.2           gridExtra_2.3       \n#>  [58] xfun_0.41            cmdstanr_0.5.3       distributional_0.3.2\n#>  [61] loo_2.6.0            withr_2.5.2          timeSeries_4031.107 \n#>  [64] fastmap_1.1.1        boot_1.3-28.1        fansi_1.0.5         \n#>  [67] shinyjs_2.1.0        callr_3.7.3          digest_0.6.33       \n#>  [70] timechange_0.2.0     R6_2.5.1             mime_0.12           \n#>  [73] estimability_1.4.1   colorspace_2.1-0     gtools_3.9.4        \n#>  [76] markdown_1.11        threejs_0.3.3        modeest_2.4.0       \n#>  [79] utf8_1.2.4           generics_0.1.3       data.table_1.14.8   \n#>  [82] class_7.3-22         prettyunits_1.2.0    httr_1.4.7          \n#>  [85] htmlwidgets_1.6.2    pkgconfig_2.0.3      dygraphs_1.1.1.6    \n#>  [88] gtable_0.3.4         Exact_3.2            timeDate_4022.108   \n#>  [91] htmltools_0.5.7      clue_0.3-65          scales_1.2.1        \n#>  [94] rethinking_2.40      lmom_3.0             posterior_1.5.0     \n#>  [97] knitr_1.45           rstudioapi_0.15.0    tzdb_0.4.0          \n#> [100] reshape2_1.4.4       statip_0.2.3         coda_0.19-4         \n#> [103] checkmate_2.3.0      nlme_3.1-163         curl_5.1.0          \n#> [106] repr_1.1.6           proxy_0.4-27         zoo_1.8-12          \n#> [109] rootSolve_1.8.2.4    parallel_4.3.2       miniUI_0.1.1.1      \n#> [112] fBasics_4032.96      pillar_1.9.0         grid_4.3.2          \n#> [115] vctrs_0.6.4          shinystan_2.6.0      promises_1.2.1      \n#> [118] arrayhelpers_1.1-0   xtable_1.8-4         cluster_2.1.4       \n#> [121] evaluate_0.23        mvtnorm_1.2-3        cli_3.6.1           \n#> [124] compiler_4.3.2       rlang_1.1.2          crayon_1.5.2        \n#> [127] rstantools_2.3.1.1   rversions_2.1.2      labeling_0.4.3      \n#> [130] ps_1.7.5             plyr_1.8.9           stringi_1.7.12      \n#> [133] rstan_2.32.3         QuickJSR_1.0.7       munsell_0.5.0       \n#> [136] colourpicker_1.3.0   Brobdingnag_1.2-9    bayestestR_0.13.1   \n#> [139] V8_4.4.0             Matrix_1.6-2         hms_1.1.3           \n#> [142] stabledist_0.7-1     shiny_1.7.5.1        igraph_1.5.1        \n#> [145] RcppParallel_5.1.7   readxl_1.4.3\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}