{
  "hash": "1033b0495f699f6b59db5c3e0d710f29",
  "result": {
    "markdown": "# Sampling the Imaginary\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: setup\n\nlibrary(tidyverse)\n```\n````\n\n```\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n\n## Vampire Example {.unnumbered}\n\n### Original {.unnumbered}\n\n#### a) Medical Test Scenario with Bayes theorem {.unnumbered}\n\n1.  Suppose there is a blood test that correctly detects vampirism 95%\n    of the time.$Pr(positivetest|vampire) = 0.95$.\n2.  It's a very accurate test, nearly always catching real vampires. It\n    also make mistakes, though, in the form of false positives. One\n    percent of the time, it incorrectly diagnoses normal people as\n    vampires, $Pr(positive test result| mortal) = 0.01$.\n3.  The final bit of information we are told is that vampires are rather\n    rare, being only 0.1% of the population, implying\n    $Pr(vampire) = 0.001$.\n\nSuppose now that someone tests positive for vampirism. What's the\nprobability that he or she is a bloodsucking immortal?\n\nThe correct approach is just to use Bayes' theorem to invert the\nprobability, to compute $Pr(vampire | positive)$.\n\n$$\n\\Pr(\\text{vampire}|\\text{positive}) = \\frac{\\Pr(\\text{positive}|\\text{vampire})\\Pr(\\text{vampire})}{\\Pr(\\text{positive})}.\n$$\n\nwhere $Pr(positive)$ is the average probability of a positive test\nresult, that is,\n\n$$\nPr(positive) = Pr(positive|vampire)Pr(vampire) + Pr(positive|mortal)Pr(1-vampire)\n$$\n\n\n::: {.cell}\n\n````{.cell-code #lst-bayes-scenario lst-cap=\"Calculated with the Bayes formula\"}\n```{{r}}\n#| label: scenario-bayes-theorem-a\n#| attr-source: '#lst-bayes-scenario lst-cap=\"Calculated with the Bayes formula\"'\n\n## R code 3.1\nPr_Positive_Vampire_a <- 0.95\nPr_Positive_Mortal_a <- 0.01\nPr_Vampire_a <- 0.001\nPr_Positive_a <- Pr_Positive_Vampire_a * Pr_Vampire_a +\n  Pr_Positive_Mortal_a * (1 - Pr_Vampire_a)\n(Pr_Vampire_Positive_a <- Pr_Positive_Vampire_a * Pr_Vampire_a / Pr_Positive_a)\n```\n````\n\n```\n#> [1] 0.08683729\n```\n:::\n\n\nThere is only an 8.7% chance that the suspect is actually a vampire.\n\n> Most people find this result counterintuitive. And it's a very\n> important result, because it mimics the structure of many realistic\n> testing contexts, such as HIV and DNA testing, criminal profiling, and\n> even statistical significance testing ... . Whenever the condition of\n> interest is very rare, having a test that finds all the true cases is\n> still no guarantee that a positive result carries much information at\n> all. The reason is that most positive results are false positives,\n> even when all the true positives are detected correctly.\n\n#### b) Medical test scenario with natural frequencies {.unnumbered}\n\n```         \n(1)  In a population of 100,000 people, 100 of them are vampires.\n(2)  Of the 100 who are vampires, 95 of them will test positive for vampirism.\n(3)  Of the 99,900 mortals, 999 of them will test positive for vampirism.\n```\n\nThere are 999 + 95 = 1094 people tested positive. But from these\npeople only 95 / (999 + 95) = 8.6837294 % are actually\nvampires.\n\nOr with a slightly different wording it is still easier to\nunderstand: 1. We can just count up the number of people who test\npositive: $95 + 999 = 1094$. 2. Out of these $1094$ positive tests, $95$\nof them are real vampires, so that implies:\n\n$$\nPR(positive|vampire) = \\frac{95}{1094}\n$$\n\n\n::: {.cell}\n\n````{.cell-code #lst-common-sense-scenario lst-cap=\"Calculated with natural figures instead propabilities\"}\n```{{r}}\n#| label: scenario-common-sense-a\n#| attr-source: '#lst-common-sense-scenario lst-cap=\"Calculated with natural figures instead propabilities\"'\n\n95/1094\n```\n````\n\n```\n#> [1] 0.08683729\n```\n:::\n\n\nThe second presentation of the problem, using counts rather than\nprobabilities, is often called the *frequency format* or *natural\nfrequencies*. It is easier for people to understand because are\nconfronted with count in everyday life. Nobody has ever seen a\nprobability.\n\n::: callout-note\n## Meta remark: Study guide\n\nThis chapter teaches the basic skills for working with samples from the\nposterior distribution. We'll begin to use samples to summarize and\nsimulate model output. The skills learned here will apply to every\nproblem in the remainder of the book, even though the details of the\nmodels and how the samples are produced will vary.\n\nThe chapter exploits the fact that people are better in counts than in\nprobabilities. We will take the probability distributions from the\nprevious chapter and sampling from them to produce counts.\n:::\n\n> The posterior distribution is a probability distribution. And like all\n> probability distributions, we can imagine drawing *samples* from it.\n> The sampled events in this case are parameter values. Most parameters\n> have no exact empirical realization. The Bayesian formalism treats\n> parameter distributions as relative plausibility, not as any physical\n> random process. In any event, randomness is always a property of\n> information, never of the real world. But inside the computer,\n> parameters are just as empirical as the outcome of a coin flip or a\n> die toss or an agricultural experiment. The posterior defines the\n> expected frequency that different parameter values will appear, once\n> we start plucking parameters out of it.\n\nThere are two reasons more to use samples:\n\n1.  First, many scientists are uncomfortable with integral calculus,\n    even though they have strong and valid intuitions about how to\n    summarize data. Working with samples transforms a problem in\n    calculus into a problem in data summary, into a frequency format\n    problem. An integral in a typical Bayesian context is just the total\n    probability in some interval.\n2.  Second, some of the most capable methods of computing the posterior\n    produce nothing but samples. Many of these methods are variants of\n    Markov chain Monte Carlo techniques (MCMC).\n\nDrawing samples from the very simple posterior distribution of the\nglobe-tossing model might seem as overkill but using this technique from\nthe start has educational impact: When you inevitably must fit a model\nto data using MCMC, you will already know how to make sense of the\noutput.\n\n### Tidyverse {.unnumbered}\n\n#### a) Medical Test Scenario with Bayes theorem {.unnumbered}\n\nIf you would like to know the probability someone is a vampire given\nthey test positive to the blood-based vampire test, you compute\n\n$$\nPr(vampire|positive) = \\frac{Pr(positive|vampire) \\times Pr(vampire)} {Pr(positive)}\n$$ This is Bayes theorem.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: scenario-bayes-theorem-b\n\ntibble(pr_positive_vampire_b = .95,\n       pr_positive_mortal_b  = .01,\n       pr_vampire_b          = .001) %>% \n  mutate(pr_positive_b = pr_positive_vampire_b * pr_vampire_b + pr_positive_mortal_b * (1 - pr_vampire_b)) %>% \n  mutate(pr_vampire_positive_b = pr_positive_vampire_b * pr_vampire_b / pr_positive_b) %>% \n  glimpse()\n```\n````\n\n```\n#> Rows: 1\n#> Columns: 5\n#> $ pr_positive_vampire_b <dbl> 0.95\n#> $ pr_positive_mortal_b  <dbl> 0.01\n#> $ pr_vampire_b          <dbl> 0.001\n#> $ pr_positive_b         <dbl> 0.01094\n#> $ pr_vampire_positive_b <dbl> 0.08683729\n```\n:::\n\n\n#### b) Medical test scenario with natural frequencies {.unnumbered}\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: scenario-natural-frequencies\n\ntibble(pr_vampire_b2          = 100 / 100000,\n       pr_positive_vampire_b2 = 95 / 100,\n       pr_positive_mortal_b2  = 999 / 99900) %>% \n  mutate(pr_positive_b2 = 95 + 999) %>% \n  mutate(pr_vampire_positive_b2 = pr_positive_vampire_b2 * 100 / pr_positive_b2) %>% \n  glimpse()\n```\n````\n\n```\n#> Rows: 1\n#> Columns: 5\n#> $ pr_vampire_b2          <dbl> 0.001\n#> $ pr_positive_vampire_b2 <dbl> 0.95\n#> $ pr_positive_mortal_b2  <dbl> 0.01\n#> $ pr_positive_b2         <dbl> 1094\n#> $ pr_vampire_positive_b2 <dbl> 0.08683729\n```\n:::\n\n\n## Sampling from a grid-approximate posterior\n\n### Original\n\n#### Grid approximation\n\nBefore we are going to draw samples from the posterior distribution we\nneed to compute the distribution. Again we are using grid approximation.\n\n\n::: {.cell}\n\n````{.cell-code #lst-grid-approx-a lst-cap=\"Generate the posterior distribution form the globe-tossing example\"}\n```{{r}}\n#| label: grid-approx-a\n#| attr-source: '#lst-grid-approx-a lst-cap=\"Generate the posterior distribution form the globe-tossing example\"'\n\n### R code 3.2 ##########################\n# change prob_b to prior\n# change prob_data to likelihood\n# added variables: n, n_success, n_trials\n\nn_grid_a <- 1000L\nn_success_a <- 6L\nn_trials_a <-  9L\n\n\np_grid_a <- seq(from = 0, to = 1, length.out = n_grid_a)\nprior_a <- rep(1, n_grid_a) # = prior, assumed as uniform distribution\nlikelihood_a <- dbinom(n_success_a, size = n_trials_a, prob = p_grid_a) # = likelihood\nposterior_a <- likelihood_a * prior_a\nposterior_a <- posterior_a / sum(posterior_a)\n```\n````\n:::\n\n\n> Now we wish to draw 10,000 samples from this posterior. Imagine the\n> posterior is a bucket full of parameter values, numbers such as 0.1,\n> 0.7, 0.5, 1, etc. Within the bucket, each value exists in proportion\n> to its posterior probability, such that values near the peak are much\n> more common than those in the tails. We're going to scoop out 10,000\n> values from the bucket. Provided the bucket is well mixed, the\n> resulting samples will have the same proportions as the exact\n> posterior density. Therefore the individual values of *p* will appear\n> in our samples in proportion to the posterior plausibility of each\n> value.\n\n#### Drawing samples\n\n\n::: {.cell}\n\n````{.cell-code #draw-samples-a lst-cap=\"Draw 1000 Samples from the posterior distribution, using `base::set.seed(3)`\"}\n```{{r}}\n#| label: draw-samples-a\n#| attr-source: '#draw-samples-a lst-cap=\"Draw 1000 Samples from the posterior distribution, using `base::set.seed(3)`\"'\n\nn_samples_a <- 1e4\n\nset.seed(3) # <1>\n\n## R code 3.3 ##########################################\nsamples_a <- sample(p_grid_a, prob = posterior_a, \n                    size = n_samples_a, replace = TRUE) # <2>\n```\n````\n:::\n\n\n1.  I have included the `base::set.seed()` command myself to provide\n    reproducibility. With this code line you will get the same results in your sampling\n    process because it is not really a random procedure but the outcome\n    of a complex algorithm that can be configured by the `set.seed()` function.\n2.  The workhorse here is `base::sample`, which randomly pulls values\n    from a vector. The vector in this case is `p_grid_a`, the grid of\n    1000 (1e3) parameter values. The probability of each value is given by\n    `posterior_a`, which we computed with @lst-grid-approx-a.\n    \nTo compare the calculated values with variant b (the tidyverse version), I bound the three vectors with `base::cbind()` together into a matrix and displayed the first six lines with `utils::head()`. Additionally I also displayed the first 10 values of `samples_a` vector.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: display-grid_result_a\n\n# display grid results to compare with variant b\nd_a <- cbind(p_grid_a, prior_a, likelihood_a, posterior_a) \nhead(d_a, 10)\n```\n````\n\n```\n#>          p_grid_a prior_a likelihood_a  posterior_a\n#>  [1,] 0.000000000       1 0.000000e+00 0.000000e+00\n#>  [2,] 0.001001001       1 8.425225e-17 8.433659e-19\n#>  [3,] 0.002002002       1 5.375951e-15 5.381333e-17\n#>  [4,] 0.003003003       1 6.105137e-14 6.111249e-16\n#>  [5,] 0.004004004       1 3.419945e-13 3.423368e-15\n#>  [6,] 0.005005005       1 1.300676e-12 1.301978e-14\n#>  [7,] 0.006006006       1 3.872087e-12 3.875963e-14\n#>  [8,] 0.007007007       1 9.734489e-12 9.744233e-14\n#>  [9,] 0.008008008       1 2.162473e-11 2.164638e-13\n#> [10,] 0.009009009       1 4.370695e-11 4.375070e-13\n```\n:::\n\n\nFurthermore I also displayed the first 10 values of `samples_a` vector.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: display-samples_result_a\n\n# display sample results to compare with variant b\nhead(samples_a, 10)\n```\n````\n\n```\n#>  [1] 0.5645646 0.6516517 0.5475475 0.5905906 0.5955956 0.7877878 0.7267267\n#>  [8] 0.4914915 0.7507508 0.4494494\n```\n:::\n\n\n\n#### Plot samples distribution\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-scatterplot-samples-a\n#| fig-cap: \"Scatterplot of the drawn samples (Version a)\"\n\n## R code 3.4 #########\nplot(samples_a)\n```\n````\n\n::: {.cell-output-display}\n![Scatterplot of the drawn samples (Version a)](03-sampling-the-imaginary_files/figure-html/fig-scatterplot-samples-a-1.png){#fig-scatterplot-samples-a width=672}\n:::\n:::\n\n\nIn @fig-scatterplot-samples-a, it is as if you are flying over the\nposterior distribution, looking down on it. There are many more samples\nfrom the dense region near 0.6 and very few samples below 0.25.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-density-samples-a\n#| fig-cap: \"Density estimate of the drawn samples (Version a)\"\n\n## R code 3.5 #############\nrethinking::dens(samples_a)\n```\n````\n\n::: {.cell-output-display}\n![Density estimate of the drawn samples (Version a)](03-sampling-the-imaginary_files/figure-html/fig-density-samples-a-1.png){#fig-density-samples-a width=672}\n:::\n:::\n\n\nPlot @fig-density-samples-a shows the density estimate computed from our\nsampling process. The estimated density is very similar to ideal\nposterior you computed via grid approximation. If you draw even more\nsamples, maybe 1e5 or 1e6, the density estimate will get more and more\nsimilar to the ideal. This is shown in the tidyverse version @fig-density-samples-b2.\n\n### Tidyverse\n\n#### Grid approximation\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: grid-approx-b\n\n# how many grid points would you like?\nn_grid_b <- 1000L\nn_success_b <- 6L\nn_trials_b  <- 9L\n\n(\n  d_b <-\n  tibble(p_grid_b = seq(from = 0, to = 1, length.out = n_grid_b),\n         # note we're still using a flat uniform prior\n         prior_b  = 1) %>% \n  mutate(likelihood_b = dbinom(n_success_b, size = n_trials_b, prob = p_grid_b)) %>% \n  mutate(posterior_b = (likelihood_b * prior_b) / sum(likelihood_b * prior_b))\n)\n```\n````\n\n```\n#> # A tibble: 1,000 × 4\n#>    p_grid_b prior_b likelihood_b posterior_b\n#>       <dbl>   <dbl>        <dbl>       <dbl>\n#>  1  0             1     0           0       \n#>  2  0.00100       1     8.43e-17    8.43e-19\n#>  3  0.00200       1     5.38e-15    5.38e-17\n#>  4  0.00300       1     6.11e-14    6.11e-16\n#>  5  0.00400       1     3.42e-13    3.42e-15\n#>  6  0.00501       1     1.30e-12    1.30e-14\n#>  7  0.00601       1     3.87e-12    3.88e-14\n#>  8  0.00701       1     9.73e-12    9.74e-14\n#>  9  0.00801       1     2.16e-11    2.16e-13\n#> 10  0.00901       1     4.37e-11    4.38e-13\n#> # ℹ 990 more rows\n```\n:::\n\n\n#### Drawing samples\n\n::: callout-caution\n###### Changing variable names\n\nWe've renamed McElreath's `prob_p` and `prob_data` as `prior_b` and\n`likelihood_b`, respectively. Now we'll use the `dplyr::slice_sample()`\nfunction to sample rows from `d_b`, saving them as `samples_b`.\n\nTo get the same variable name of the sample results in version a and b\nI will change in the following code chunk `p_grid_b` to `samples_b`.\nSo I can compare the vector `samples_a` with the column `samples_b`of the tibble with the same name (`samples_b`). \n\nAdditionally: To see the difference between grid and samples I will add \"_sample\" to all the other variable names. For reasons of consistence I will also change the name of \"prior_b\"\n:::\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: draw-samples-b\n\n# how many samples would you like?\nn_samples_b <- 1e4\n\n# make it reproducible\nset.seed(3)\n\nsamples_b <-\n  d_b %>% \n    slice_sample(n = n_samples_b, weight_by = posterior_b, replace = T)\n\n\n( \n    samples_b <- samples_b |>\n        rename(samples_b = p_grid_b,\n               likelihood_samples_b = likelihood_b,\n               prior_samples_prior_b = prior_b,\n               posterior_samples_b = posterior_b)\n)\n```\n````\n\n```\n#> # A tibble: 10,000 × 4\n#>    samples_b prior_samples_prior_b likelihood_samples_b posterior_samples_b\n#>        <dbl>                 <dbl>                <dbl>               <dbl>\n#>  1     0.565                     1                0.225             0.00225\n#>  2     0.652                     1                0.272             0.00272\n#>  3     0.548                     1                0.210             0.00210\n#>  4     0.591                     1                0.245             0.00245\n#>  5     0.596                     1                0.248             0.00248\n#>  6     0.788                     1                0.192             0.00192\n#>  7     0.727                     1                0.253             0.00253\n#>  8     0.491                     1                0.156             0.00156\n#>  9     0.751                     1                0.233             0.00233\n#> 10     0.449                     1                0.116             0.00116\n#> # ℹ 9,990 more rows\n```\n:::\n\n\nThe column `samples_b` of the tibble with the same name (watch out not to confuse these two objects) is identical with the vector `samples_a`. This `base::identical()` results in different sampling processes was the work of `set.seed(3)`. \n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: test-if-samples-identical\n\nidentical(samples_a, samples_b$samples_b)\n```\n````\n\n```\n#> [1] TRUE\n```\n:::\n\n\n\nWith the `utils::str()` function you will get a result with shorter\nfigures that is better adapted to a small screen.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: str-samples-b\n\nstr(samples_b)\n```\n````\n\n```\n#> tibble [10,000 × 4] (S3: tbl_df/tbl/data.frame)\n#>  $ samples_b            : num [1:10000] 0.565 0.652 0.548 0.591 0.596 ...\n#>  $ prior_samples_prior_b: num [1:10000] 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ likelihood_samples_b : num [1:10000] 0.225 0.272 0.21 0.245 0.248 ...\n#>  $ posterior_samples_b  : num [1:10000] 0.00225 0.00272 0.0021 0.00245 0.00248 ...\n```\n:::\n\nAn alternative of the tidyverse approach is `dplyr::glimpse()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: glimpse-samples-b\n\nglimpse(samples_b)\n```\n````\n\n```\n#> Rows: 10,000\n#> Columns: 4\n#> $ samples_b             <dbl> 0.5645646, 0.6516517, 0.5475475, 0.5905906, 0.59…\n#> $ prior_samples_prior_b <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n#> $ likelihood_samples_b  <dbl> 0.22455994, 0.27190272, 0.20966655, 0.24460869, …\n#> $ posterior_samples_b   <dbl> 0.0022478473, 0.0027217490, 0.0020987643, 0.0024…\n```\n:::\n\n\nNow we can plot the left panel of Figure 3.1 with `ggplot2::geom_point()`. But before we do, we'll need to add a variable numbering the samples.\n\n#### Plot samples distribution\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-scatterplot-samples-b\n#| fig-cap: \"Scatterplot of the drawn samples (Version b)\"\n\nsamples_b %>% \n  mutate(sample_number = 1:n()) %>% \n  \n  ggplot(aes(x = sample_number, y = samples_b)) +\n  geom_point(alpha = 1/10) +\n  scale_y_continuous(\"proportion of water (p)\", limits = c(0, 1)) +\n  xlab(\"sample number\")\n```\n````\n\n::: {.cell-output-display}\n![Scatterplot of the drawn samples (Version b)](03-sampling-the-imaginary_files/figure-html/fig-scatterplot-samples-b-1.png){#fig-scatterplot-samples-b width=672}\n:::\n:::\n\n\nWe'll make the density in the right panel with `ggplot2::geom_density()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-density-samples-b\n#| fig-cap: \"Density estimate of the drawn samples (Version b)\"\n\nsamples_b %>% \n  ggplot(aes(x = samples_b)) +\n  geom_density(fill = \"grey\") +\n  scale_x_continuous(\"proportion of water (p)\", limits = c(0, 1))\n```\n````\n\n::: {.cell-output-display}\n![Density estimate of the drawn samples (Version b)](03-sampling-the-imaginary_files/figure-html/fig-density-samples-b-1.png){#fig-density-samples-b width=672}\n:::\n:::\n\n\nCompare this somewhat smoother @fig-density-samples-b with @fig-density-samples-a.\n\nIf we keep increasing the number of samples we will get a better\napproximation to the ideal posterior distribution we have computed via\ngrid approximation. Here's what it looks like with `1e6`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-density-samples-b2\n#| fig-cap: \"Density estimate of 1e6 drawn samples (Version b)\"\n\nset.seed(3)\n\nd_b %>% \n  slice_sample(n = 1e6, weight_by = posterior_b, replace = T) %>% \n  ggplot(aes(x = p_grid_b)) +\n  geom_density(fill = \"grey\") +\n  scale_x_continuous(\"proportion of water (p)\", limits = c(0, 1))\n```\n````\n\n::: {.cell-output-display}\n![Density estimate of 1e6 drawn samples (Version b)](03-sampling-the-imaginary_files/figure-html/fig-density-samples-b2-1.png){#fig-density-samples-b2 width=672}\n:::\n:::\n\n\n## Sampling to Summarize\n\n### Three questions asked {.unnumbered}\n\nAll we have done so far is crudely replicate the posterior density we\nhad already computed in the previous chapter. Now it is time to use\nthese samples to describe and understand the posterior.\n\nThe first step in understanding the posterior distribution is to\nsummarize it. Exactly how it is summarized depends upon your purpose.\nBut common questions include:\n\n-   How much posterior probability lies below some parameter value?\n-   How much posterior probability lies between two parameter values?\n-   Which parameter value marks the lower 5% of the posterior\n    probability?\n-   Which range of parameter values contains 90% of the posterior\n    probability?\n-   Which parameter value has highest posterior probability?\n\nThe above list of questions can be divided into three inquiries:\n\n1.  Questions about intervals of defined boundaries.\n2.  Questions about intervals of defined probability mass.\n3.  Questions about point estimates.\n\n### Intervals of Defined Boundaries\n\n#### Original\n\n##### Grid approach\n\nFor instance: What is the probability that the proportion of water is\nless than 0.5?\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: grid-boundaries-a\n\n## R code 3.6\n# add up posterior probability where p < 0.5\nsum(posterior_a[p_grid_a < 0.5])\n```\n````\n\n```\n#> [1] 0.1718746\n```\n:::\n\n\nAbout 17% of the posterior probability is below 0.5. Couldn't be easier.\n\n##### Sampling approach\n\nBut this easy calculation based on grid approximation is often no\npractical when there are more parameters. So let's try the sampling\napproach:\n\nTo use the samples from the posterior you have to add up all of the\nsamples below 0.5, but also divide the resulting count by the total\nnumber of samples. In other words, find the frequency of parameter\nvalues below 0.5:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: sample-boundaries-0.5-a\n\n## R code 3.7\n(p_boundary_a <- sum(samples_a < 0.5) / 1e4)\n```\n````\n\n```\n#> [1] 0.1629\n```\n:::\n\n\n::: callout-caution\n###### Attention: Different values\n\nIn comparison with the value in the original book (0.1726) our value of\n0.1629 is different. \n17%.\n\nThe reason for the difference is that you can't get the same values in\nsampling processes. This is the nature of randomness. And McElreath did not include the set.sedd() function for (exact) reproducibility. What additionally\nhappened is that our `set.seed()`\\` value of 3 results in a somewhat\nuntypical sampling distribution. I will demonstrate this with additional\nthree samples with different `set.seed()`\\` values.\n:::\n\n##### Different sampling distributions\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: different-sample-distributions\n\n# four examples with different seeds\nset.seed(42)\nsamples_a2 <- sample(p_grid_a, prob = posterior_a, size = 1e4, replace = TRUE)\nset.seed(123)\nsamples_a3 <- sample(p_grid_a, prob = posterior_a, size = 1e4, replace = TRUE)\nset.seed(1000)\nsamples_a4 <- sample(p_grid_a, prob = posterior_a, size = 1e4, replace = TRUE)\nset.seed(33)\nsamples_a5 <- sample(p_grid_a, prob = posterior_a, size = 1e4, replace = TRUE)\n\n(p_boundary_a2 <- sum(samples_a2 < 0.5) / 1e4)\n(p_boundary_a3 <- sum(samples_a3 < 0.5) / 1e4)\n(p_boundary_a4 <- sum(samples_a4 < 0.5) / 1e4)\n(p_boundary_a5 <- sum(samples_a5 < 0.5) / 1e4)\n\n# without setting a seed (not reproducible)\nset.seed(0)\nsamples_a6 <- sample(p_grid_a, prob = posterior_a, size = 1e4, replace = TRUE)\nsamples_a7 <- sample(p_grid_a, prob = posterior_a, size = 1e4, replace = TRUE)\n(p_boundary_a6 <- sum(samples_a6 < 0.5) / 1e4)\n(p_boundary_a7 <- sum(samples_a7 < 0.5) / 1e4)\n```\n````\n\n```\n#> [1] 0.1695\n#> [1] 0.1631\n#> [1] 0.1765\n#> [1] 0.1778\n#> [1] 0.1696\n#> [1] 0.1711\n```\n:::\n\n\nAlthough the second figure is near our \"bad\" result, all sampling\nprocedures with the chosen different `base::set.seed() values` return\nbetter values (nearer the true value of 0.1718746) as our sampling\nprocedure fixed with `base::set.seed(3)`. The last two values are done\nwithout setting a `set.seed()` value so my values should differ than\nyours.\n\nUsing the same approach, you can ask how much posterior probability lies\nbetween 0.5 and 0.75:\n\n\n::: {.cell}\n\n````{.cell-code #sample-boundaries2-a lst-cap=\"Find the frequency of parameter values below 0.5 with `base::set.seed(3)`\"}\n```{{r}}\n#| label: sample-boundaries-0.5-0.75-a\n#| attr-source: '#sample-boundaries2-a lst-cap=\"Find the frequency of parameter values below 0.5 with `base::set.seed(3)`\"'\n#|\n## R code 3.8\n(p_boundary_a8 <- sum(samples_a > 0.5 & samples_a < 0.75) / 1e4)\n```\n````\n\n```\n#> [1] 0.6061\n```\n:::\n\n\n#### Tidyverse\n\n##### Grid approach\n\n> To get the proportion of water less than some value of `p_grid_b` within\n> the {**tidyverse}**, you might first `filter()` by that value and then\n> take the `sum()` within `summarise()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: grid-boundaries-b\n\n# add up posterior probability where p < 0.5\nd_b |> filter(p_grid_b < 0.5) |> \n    summarize(sum = sum(posterior_b))\n```\n````\n\n```\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.172\n```\n:::\n\n\n##### Sampling approach\n\nIf what you want a frequency based on filtering by `samples_b`, then\nyou might use `n()` within `summarise()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: samples-boundaries-b\n\n# add up all posterior probabilities of samples under .5\nsamples_b |> \n    filter(samples_b < .5) |> \n    summarize(sum = n() / n_samples_b)\n```\n````\n\n```\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.163\n```\n:::\n\n\nA more explicit approach for the same computation is to follow up\n`count()` with `mutate()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: samples-boundaries-b2\n\nsamples_b |> \n    count(samples_b < .5) |> \n    mutate(probability = n / sum(n))\n```\n````\n\n```\n#> # A tibble: 2 × 3\n#>   `samples_b < 0.5`     n probability\n#>   <lgl>             <int>       <dbl>\n#> 1 FALSE              8371       0.837\n#> 2 TRUE               1629       0.163\n```\n:::\n\n\nAn even trickier approach for the same is to insert the logical\nstatement `p_grid < .5` within the `mean()` function.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: samples-boundaries-b3\n\nsamples_b |> \n    summarize(sum = mean(samples_b < .5))\n```\n````\n\n```\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.163\n```\n:::\n\n\nTo determine the posterior probability between 0.5 and 0.75, you can use\n`&` within `filter()`. Just multiply that result by 100 to get the value in percent.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: samples-boundaries-b4\n\nsamples_b |> \n    filter(samples_b > .5 & samples_b < .75) |> \n    summarize(sum = n() / n_samples_b)\n```\n````\n\n```\n#> # A tibble: 1 × 1\n#>     sum\n#>   <dbl>\n#> 1 0.606\n```\n:::\n\n\nAnd, of course, you can do that with our `mean()` trick, too.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: samples-boundaries-b5\n\nsamples_b %>%\n  summarise(percent = 100 * mean(samples_b > .5 & samples_b < .75))\n```\n````\n\n```\n#> # A tibble: 1 × 1\n#>   percent\n#>     <dbl>\n#> 1    60.6\n```\n:::\n\n\n\n##### Plot interval of defined boundaries\n\nTo produce Figure 3.2 of the book we apply following code lines:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-upper-part-3.2\n#| fig-cap: \"Upper part of SR2 Figure 3.2: Posterior distribution produced with {**tidyverse**} tools: Left: The blue area is the posterior probability below a parameter value of 0.5. Right: The posterior probability between 0.5 and 0.75.\"\n\n# upper left panel\np1 <-\n  samples_b %>% \n  ggplot(aes(x = samples_b, y = posterior_samples_b)) +\n  geom_line() +\n  geom_area(data = samples_b %>% filter(samples_b < .5), fill = \"blue\") +\n  labs(x = \"proportion of water (p)\",\n       y = \"density\")\n\n# upper right panel\np2 <- \n  samples_b %>% \n  ggplot(aes(x = samples_b, y = posterior_samples_b)) +\n  geom_line() +\n  geom_area(data = samples_b %>% filter(samples_b > .5 & samples_b < .75), fill = \"blue\") +\n  labs(x = \"proportion of water (p)\",\n       y = \"density\")\n\nlibrary(patchwork)\np1 + p2\n```\n````\n\n::: {.cell-output-display}\n![Upper part of SR2 Figure 3.2: Posterior distribution produced with {**tidyverse**} tools: Left: The blue area is the posterior probability below a parameter value of 0.5. Right: The posterior probability between 0.5 and 0.75.](03-sampling-the-imaginary_files/figure-html/fig-upper-part-3.2-1.png){#fig-upper-part-3.2 width=672}\n:::\n:::\n\n\n### Intervals of Defined Probability Mass\n\n#### Original\n\n##### Quantiles\n\n> Reporting an interval of defined mass is usually known as a\n> **CONFIDENCE INTERVAL**. An interval of posterior probability, such as\n> the ones we are working with, may instead be called a **CREDIBLE\n> INTERVAL**.\n\n> We're going to call it a **COMPATIBILITY INTERVAL** instead, in order\n> to avoid the unwarranted implications of \"confidence\" and\n> \"credibility.\" What the interval indicates is a range of parameter\n> values compatible with the model and data. The model and data\n> themselves may not inspire confidence, in which case the interval will\n> not either.\n\n> For this type of interval, it is easier to find the answer by using\n> samples from the posterior than by using a grid approximation. Suppose\n> for example you want to know the boundaries of the lower 80% posterior\n> probability. You know this interval starts at $p = 0$. To find out\n> where it stops, think of the samples as data and ask where the 80th\n> percentile lies:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: samples-quantile-a\n\n## R code 3.9\nquantile(samples_a, 0.8)\n```\n````\n\n```\n#>       80% \n#> 0.7627628\n```\n:::\n\n\nSimilarly, the middle 80% interval lies between the 10th percentile and\nthe 90th percentile. These boundaries are found using the same approach:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: sample-quantile-a2\n\n## R code 3.10\nquantile(samples_a, c(0.1, 0.9))\n```\n````\n\n```\n#>       10%       90% \n#> 0.4514515 0.8148148\n```\n:::\n\n\nIntervals of this sort, which assign equal probability mass to each\ntail, are very common in the scientific literature. We'll call them\n**PERCENTILE INTERVALS** (PI). These intervals do a good job of\ncommunicating the shape of a distribution, as long as the distribution\nisn't too asymmetrical. But in terms of describing the shape of the\nposterior distribution---which is really all these intervals are asked\nto do---the percentile interval can be misleading.\n\nConsider the posterior distribution and different intervals in\n@fig-skewed-dist-a. This posterior is consistent with observing three\nwaters in three tosses and a uniform (flat) prior. It is highly skewed,\nhaving its maximum value at the boundary, $p = 1$. You can compute it,\nvia grid approximation.\n\n##### Skewed distribution\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-skewed-dist-a\n#| fig-cap: \"Skewed posterior distribution observing three waters in three tosses and a uniform (flat) prior. It is highly skewed, having its maximum value at the boundary where p equals 1.\"\n\n## R code 3.11\np_grid_skewed_a <- seq(from = 0, to = 1, length.out = 1000)\nprior_skewed_a <- rep(1, 1000)\nlikelihood_skewed_a <- dbinom(3, size = 3, prob = p_grid_skewed_a)\nposterior_skewed_a <- likelihood_skewed_a * prior_skewed_a\nposterior_skewed_a <- posterior_skewed_a / sum(posterior_skewed_a)\n\nset.seed(3) # added to make sampling distribution reproducible (pb)\nsamples_skewed_a <- sample(p_grid_skewed_a, size = 1e4, replace = TRUE, prob = posterior_skewed_a)\n\n\n\n# added to show the skewed posterior distribution (pb)\nrethinking::dens(samples_skewed_a)\n```\n````\n\n::: {.cell-output-display}\n![Skewed posterior distribution observing three waters in three tosses and a uniform (flat) prior. It is highly skewed, having its maximum value at the boundary where p equals 1.](03-sampling-the-imaginary_files/figure-html/fig-skewed-dist-a-1.png){#fig-skewed-dist-a width=672}\n:::\n:::\n\n\n##### Percentile (compatibility) Intervall (PI)\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: rethinking-PI-a\n\n## R code 3.12\nrethinking::PI(samples_skewed_a, prob = 0.5)\n```\n````\n\n```\n#>       25%       75% \n#> 0.7087087 0.9349349\n```\n:::\n\n\nThe Percentile compatibility Interval (PI) of `prob = 0.5` assigns 25%\nof the probability mass above and below the interval. So it provides the\ncentral 50% probability.\n\nIt is just a shorthand for the base R `stats::quantile()` function:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: quantiles-PI-a\n\nquantile(samples_skewed_a, prob = c(.25, .75))\n```\n````\n\n```\n#>       25%       75% \n#> 0.7087087 0.9349349\n```\n:::\n\n\n> This \\[percentile compability\\] interval assigns 25% of the\n> probability mass above and below the interval. So it provides the\n> central 50% probability. But in this example, it ends up excluding the\n> most probable parameter values, near $p = 1$. So in terms of\n> describing the shape of the posterior distribution---which is really\n> all these intervals are asked to do---the percentile interval can be\n> misleading.\n\nTo see how it works we make another PI of `prob = 0.6`. We divide always\nthe percentage by 2 and subtract it from 50% respectively add this value\nto 50%. The result is the probability mass between 20-80%.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: rethinking-PI-a2\n\nrethinking::PI(samples_skewed_a, prob = 0.6)\n```\n````\n\n```\n#>       20%       80% \n#> 0.6706707 0.9481481\n```\n:::\n\n\nBut in these examples, we end up excluding the most probable parameter\nvalues, near $p = 1$. So in terms of describing the shape of the\nposterior distribution---which is really all these intervals are asked\nto do---the percentile interval can be misleading.\n\n##### Highest Posterior Density Interval (HPDI)\n\n> \\[In contrast, to PI the HPDI (HIGHEST POSTERIOR DENSITY INTERVAL)\\]\n> displays the narrowest interval containing the specified probability\n> mass. If you think about it, there must be an infinite number of\n> posterior intervals with the same mass. But if you want an interval\n> that best represents the parameter values most consistent with the\n> data, then you want the densest of these intervals. That's what the\n> HPDI is. Compute it from the samples with HPDI (also part of\n> rethinking):\n\n\n::: {.cell}\n\n````{.cell-code #lst-rethinking-HPDI-a lst-cap=\"Compute the HPDI from the samples distribution\"}\n```{{r}}\n#| label: rethinking-HPDI-a\n#| attr-source: '#lst-rethinking-HPDI-a lst-cap=\"Compute the HPDI from the samples distribution\"'\n\n## R code 3.13\nrethinking::HPDI(samples_skewed_a, prob = 0.5)\n```\n````\n\n```\n#>      |0.5      0.5| \n#> 0.8418418 0.9989990\n```\n:::\n\n\nThis interval captures the parameters with highest posterior\nprobability, as well as being noticeably narrower: 0.18 in width rather\nthan 0.28 for the percentile interval resp. 0.16 and 0.23 in the\noriginal book version.\n\nSo the HPDI has some advantages over the PI. But in most cases, these\ntwo types of interval are very similar. They only look so different in\nthis case because the posterior distribution is highly skewed. If we\ninstead used samples from the posterior distribution for six waters in\nnine tosses, these intervals would be nearly identical. Try it for\nyourself, using different probability masses, such as prob=0.8 and\nprob=0.95.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: PI-HPDI-in-sym-dist\n\nrethinking::PI(samples_a, prob = 0.8)\nrethinking::HPDI(samples_a, prob = 0.8)\n\nrethinking::PI(samples_a, prob = 0.95)\nrethinking::HPDI(samples_a, prob = 0.95)\n```\n````\n\n```\n#>       10%       90% \n#> 0.4514515 0.8148148 \n#>      |0.8      0.8| \n#> 0.4874875 0.8448448 \n#>        3%       98% \n#> 0.3493493 0.8788789 \n#>     |0.95     0.95| \n#> 0.3703704 0.8938939\n```\n:::\n\n\n##### Difference between PI and HDPI\n\n> When the posterior is bell shaped, it hardly matters which type of\n> interval you use. Remember, we're not launching rockets or calibrating\n> atom smashers, so fetishizing precision to the 5th decimal place will\n> not improve your science.\n\n> The HPDI also has some disadvantages. HPDI is more computationally\n> intensive than PI and suffers from greater simulation variance, which\n> is a fancy way of saying that it is sensitive to how many samples you\n> draw from the posterior. It is also harder to understand and many\n> scientific audiences will not appreciate its features, while they will\n> immediately understand a percentile interval, as ordinary non-Bayesian\n> intervals are typically interpreted (incorrectly) as percentile\n> intervals (although see the Rethinking box below).\n\n> Overall, if the choice of interval type makes a big difference, then\n> you shouldn't be using intervals to summarize the posterior. Remember,\n> the entire posterior distribution is the Bayesian \"estimate.\" It\n> summarizes the relative plausibilities of each possible value of the\n> parameter. Intervals of the distribution are just helpful for\n> summarizing it. If choice of interval leads to different inferences,\n> then you'd be better off just plotting the entire posterior\n> distribution.\n\n##### Intervall mass of 95?\n\n> The most common interval mass in the natural and social sciences is\n> the 95% interval. This interval leaves 5% of the probability outside,\n> corresponding to a 5% chance of the parameter not lying within the\n> interval (although see below). This customary interval also reflects\n> the customary threshold for statistical significance, which is 5% or p\n> \\< 0.05.\n\nIt is just a convention, there are no analytical reasons why you should\nchoose exactly this interval. But convenience is not a serious\ncriterion. So what to do instead?\n\n> If you are trying to say that an interval doesn't include some value,\n> then you might use the widest interval that excludes the value. Often,\n> all compatibility intervals do is communicate the shape of a\n> distribution. In that case, a series of nested intervals may be more\n> useful than any one interval. For example, why not present 67%, 89%,\n> and 97% intervals, along with the median? Why these values? No reason.\n> They are prime numbers, which makes them easy to remember. But all\n> that matters is they be spaced enough to illustrate the shape of the\n> posterior. And these values avoid 95%, since conventional 95%\n> intervals encourage many readers to conduct unconscious hypothesis\n> tests.\n\n##### Defined boundaries and probabilty mass\n\nThe difference between intervals of defined boundaries and intervals of\ndefined probability mass is that in the first case we ask for a\n**probability of frequencies** whereas in the second case we calculate a\nspecified **amount of posterior probability**. As result from the first\nquestion we get the percentage of the probability whereas the result of\nthe second question is the probability value of the percentage of\nfrequencies looked for.\n\nThe boundary intervals are grounded on the prob values ($0-1$) and\nresults in the percentage of the probability whereas the probability\nmass intervals focus on the percentage of probabilities ($0-100$%) and\nresults in probability values.\n\n#### Tidyverse\n\n##### Quantiles\n\nSince we saved our `samples_b` samples within the well-named\n`samples_b` tibble, we'll have to index with `$` within\n`stats::quantile()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: sample-quantile-b\n\n(q80 <- quantile(samples_b$samples_b, probs = .8))\n```\n````\n\n```\n#>       80% \n#> 0.7627628\n```\n:::\n\n\nFor an alternative approach, we could `dplyr::select()` the `samples_b`\nvector, extract it from the tibble with `dplyr::pull()`, and then pump\nit into `stats::quantile()`.\n\n> `pull()` is similar to `$`. It's mostly useful because it looks a\n> little nicer in pipes, it also works with remote data frames, and it\n> can optionally name the output.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: sample-quantile-b2\n\nsamples_b |> \n    pull(samples_b) |> \n    quantile(probs = .8)\n    \n```\n````\n\n```\n#>       80% \n#> 0.7627628\n```\n:::\n\n\nWe might also use `stats::quantile()` within `dplyr::summarise()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: sample-quantile-b3\n\nsamples_b |> \n    summarize(q80_2 = quantile(samples_b, probs = .8))\n```\n````\n\n```\n#> # A tibble: 1 × 1\n#>   q80_2\n#>   <dbl>\n#> 1 0.763\n```\n:::\n\n\nHere's the `summarise()` approach with two probabilities.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: sample-quantile-b4\n\nsamples_b |> \n    summarize(q10 = quantile(samples_b, probs = .1),\n              q90 = quantile(samples_b, probs = .9))\n    \n```\n````\n\n```\n#> # A tibble: 1 × 2\n#>     q10   q90\n#>   <dbl> <dbl>\n#> 1 0.451 0.815\n```\n:::\n\n\nYou can also use the vector feature of R to summarize different\nquantiles with one line. But Kurz's version is in the meanwhile\ndeprecated:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: sample-quantile-b5\n\nsamples_b |> \n    summarize(q10_90 = quantile(samples_b, probs = c(.1, .9)))\n```\n````\n\n```\n#> Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\n#> dplyr 1.1.0.\n#> ℹ Please use `reframe()` instead.\n#> ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n#>   always returns an ungrouped data frame and adjust accordingly.\n#> # A tibble: 2 × 1\n#>   q10_90\n#>    <dbl>\n#> 1  0.451\n#> 2  0.815\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: sample-quantile-b6\n\nsamples_b |> \n    reframe(q10_90 = quantile(samples_b, probs = c(.1, .9)))\n```\n````\n\n```\n#> # A tibble: 2 × 1\n#>   q10_90\n#>    <dbl>\n#> 1  0.451\n#> 2  0.815\n```\n:::\n\n\nFrom the help file of `dplyr::reframe()`:\n\n> While `summarise()` requires that each argument returns a single\n> value, and `mutate()` requires that each argument returns the same\n> number of rows as the input, `reframe()` is a more general workhorse\n> with no requirements on the number of rows returned per group.\n>\n> `reframe()` creates a new data frame by applying functions to columns\n> of an existing data frame. It is most similar to `summarise()`, with\n> two big differences:\n>\n> -   `reframe()` can return an arbitrary number of rows per group,\n>     while `summarise()` reduces each group down to a single row.\n> -   `reframe()` always returns an ungrouped data frame, while\n>     `summarise()` might return a grouped or rowwise data frame,\n>     depending on the scenario.\n>\n> We expect that you'll use `summarise()` much more often than\n> `reframe()`, but `reframe()` can be particularly helpful when you need\n> to apply a complex function that doesn't return a single summary\n> value.\n\nSee also the appropriate [section in the blog\npost](https://www.tidyverse.org/blog/2023/02/dplyr-1-1-0-pick-reframe-arrange/#reframe)\nabout changes in {**dplyr**} 1.1.0. The name `reframe()` is in\naccordance with `tibble::enframe()` and `tibble::deframe()`:\n\n-   `enframe()`: Takes a vector, returns a data frame\n-   `deframe()`: Takes a data frame, returns a vector\n-   `reframe()`: Takes a data frame, returns a data frame\n\n> The functions of the tidyverse approach typically returns a data\n> frame. But sometimes you just want your values in a numeric vector for\n> the sake of quick indexing. In that case, base R `stats::quantile()`\n> shines:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: sample-quantile-b7\n\n(q10_q90 = quantile(samples_b$samples_b, probs = c(.1, .9)))\n```\n````\n\n```\n#>       10%       90% \n#> 0.4514515 0.8148148\n```\n:::\n\n\n##### Plot intervals of defined mass\n\nNow we have our cutoff values saved as `q80`, respectively `q10` and\n`q90`, we're ready to make the bottom panels of Figure 3.2.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: figure-3-2-lower-part\n\np1 <-\n  samples_b %>% \n  ggplot(aes(x = samples_b, y = posterior_samples_b)) +\n  geom_line() +\n  geom_area(data = samples_b %>% filter(samples_b < q80), fill = \"blue\") +\n  annotate(geom = \"text\",\n           x = .25, y = .0025,\n           label = \"lower 80%\") +\n  labs(x = \"proportion of water (p)\",\n       y = \"density\")\n\n# upper right panel\np2 <- \n  samples_b %>% \n  ggplot(aes(x = samples_b, y = posterior_samples_b)) +\n  geom_line() +\n  geom_area(data = samples_b %>% filter(samples_b > q10_q90[[1]] & samples_b < q10_q90[[2]]), fill = \"blue\") +\n  annotate(geom = \"text\",\n           x = .25, y = .0025,\n           label = \"middle 80%\") +\n  labs(x = \"proportion of water (p)\",\n       y = \"density\")\n\nlibrary(patchwork)\np1 + p2\n```\n````\n\n::: {.cell-output-display}\n![](03-sampling-the-imaginary_files/figure-html/figure-3-2-lower-part-1.png){width=672}\n:::\n:::\n\n\n##### Skewed distribution\n\nAgain we will demonstrate the misleading character of Pecentile\nIntervals (PIs) with a very skewed distribution.\n\nWe've already defined `p_grid_b` and `prior_b` within `d_b`, above. Here\nwe'll reuse them and create a new tibble by updating all the columns\nwith the skewed parameters.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: samples-skewed-dist\n\nn_samples_skewed_b <- 1e4\nn_success_skewed_b <- 3\nn_trials_skewed_b  <- 3\n\nd_skewed_b <-\ntibble(p_grid_skewed_b = seq(from = 0, to = 1, length.out = n_samples_skewed_b),\n     # note we're still using a flat uniform prior\n     prior_skewed_b  = 1) %>% \nmutate(likelihood_skewed_b = dbinom(n_success_skewed_b, size = n_trials_skewed_b, prob = p_grid_skewed_b)) %>% \nmutate(posterior_skewed_b = (likelihood_skewed_b * prior_skewed_b) / sum(likelihood_skewed_b * prior_skewed_b))\n\n# make the next part reproducible\nset.seed(3)\n\n# here's our new samples tibble\n(\n  samples_skewed_b <-\n    d_skewed_b %>% \n    slice_sample(n = n_samples_skewed_b, weight_by = posterior_skewed_b, replace = T)\n)\n```\n````\n\n```\n#> # A tibble: 10,000 × 4\n#>    p_grid_skewed_b prior_skewed_b likelihood_skewed_b posterior_skewed_b\n#>              <dbl>          <dbl>               <dbl>              <dbl>\n#>  1           0.874              1               0.669          0.000267 \n#>  2           0.830              1               0.572          0.000229 \n#>  3           0.684              1               0.320          0.000128 \n#>  4           0.903              1               0.735          0.000294 \n#>  5           0.750              1               0.423          0.000169 \n#>  6           0.989              1               0.968          0.000387 \n#>  7           0.875              1               0.670          0.000268 \n#>  8           0.522              1               0.143          0.0000570\n#>  9           0.967              1               0.903          0.000361 \n#> 10           0.967              1               0.903          0.000361 \n#> # ℹ 9,990 more rows\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: skewed-dist-b\n\n\n# here we update the `dbinom()` parameters \n# for values for a skewed distribution\n# assuming three trials results in 3 W (Water)\nn_success_skewed_b <- 3\nn_trials_skewed_b  <- 3\n\n# update `d_b` to d_skewed_b\nd_skewed_b <-\n  d_b %>% \n  mutate(likelihood_skewed_b = dbinom(n_success_skewed_b, size = n_trials_skewed_b, prob = p_grid_b)) %>% \n  mutate(posterior_skewed_b  = (likelihood_skewed_b * prior_b) / sum(likelihood_skewed_b * prior_b))\n\n# make the next part reproducible\nset.seed(3)\n\n# here's our new samples tibble\n(\n    samples_skewed_b <- \n        d_skewed_b %>% \n        slice_sample(n = n_samples_skewed_b, weight_by = posterior_skewed_b, replace = T) |> \n        rename(p_skewed_b = p_grid_b,\n               prior_skewed_b = prior_b)\n)\n\n# added to see the skewed distribution\nsamples_skewed_b %>% \n  ggplot(aes(x = p_skewed_b, y = posterior_skewed_b)) +\n  geom_line()\n```\n````\n\n```\n#> # A tibble: 10,000 × 6\n#>    p_skewed_b prior_skewed_b likelihood_b posterior_b likelihood_skewed_b\n#>         <dbl>          <dbl>        <dbl>       <dbl>               <dbl>\n#>  1      0.717              1    0.259     0.00259                  0.368 \n#>  2      0.652              1    0.272     0.00272                  0.277 \n#>  3      0.548              1    0.210     0.00210                  0.164 \n#>  4      1                  1    0         0                        1     \n#>  5      0.991              1    0.0000582 0.000000582              0.973 \n#>  6      0.788              1    0.192     0.00192                  0.489 \n#>  7      0.940              1    0.0125    0.000126                 0.830 \n#>  8      0.817              1    0.153     0.00154                  0.545 \n#>  9      0.955              1    0.00582   0.0000583                0.871 \n#> 10      0.449              1    0.116     0.00116                  0.0908\n#> # ℹ 9,990 more rows\n#> # ℹ 1 more variable: posterior_skewed_b <dbl>\n```\n\n::: {.cell-output-display}\n![](03-sampling-the-imaginary_files/figure-html/skewed-dist-b-1.png){width=672}\n:::\n:::\n\n\n##### Reconsideration\n\nTo see the difference how the skewed distribution is different to the\nFigure 3.2 lower part, I will draw the appropriate figure here myself.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: figure-3.2-skewed-lower-part\n\np1 <-\n  samples_skewed_b %>% \n  ggplot(aes(x = p_skewed_b, y = posterior_skewed_b)) +\n  geom_line() +\n  geom_area(data = samples_skewed_b %>% filter(p_skewed_b < q80), fill = \"blue\") +\n  annotate(geom = \"text\",\n           x = .25, y = .0025,\n           label = \"lower 80%\") +\n  labs(x = \"proportion of water (p)\",\n       y = \"density\")\n\n# upper right panel\np2 <- \n  samples_skewed_b %>% \n  ggplot(aes(x = p_skewed_b, y = posterior_skewed_b)) +\n  geom_line() +\n  geom_area(data = samples_skewed_b %>% filter(p_skewed_b > q10_q90[[1]] & p_skewed_b < q10_q90[[2]]), fill = \"blue\") +\n  annotate(geom = \"text\",\n           x = .25, y = .0025,\n           label = \"middle 80%\") +\n  labs(x = \"proportion of water (p)\",\n       y = \"density\")\n\nlibrary(patchwork)\np1 + p2\n```\n````\n\n::: {.cell-output-display}\n![](03-sampling-the-imaginary_files/figure-html/figure-3.2-skewed-lower-part-1.png){width=672}\n:::\n:::\n\n\n##### Introducing tidybayes\n\nThe [{**tidybayes**}](https://mjskay.github.io/tidybayes/) package\noffers an array of convenience functions for summarizing Bayesian\nmodels. For an introduction using {**tidybayes**} with {**brms**} see\n[Extracting and visualizing tidy draws from {**brms**}\nmodels](https://mjskay.github.io/tidybayes/articles/tidy-brms.html).\n\n> {**tidybayes**} is an R package that aims to make it easy to integrate\n> popular Bayesian modeling methods into a tidy data + ggplot workflow.\n> It builds on top of (and re-exports) several functions for visualizing\n> uncertainty from its sister package,\n> [{**ggdist**}](https://mjskay.github.io/ggdist/).\n\nI had difficulties to use Kurz's functions because there was an\n[overhaul in the naming\nscheme](https://mjskay.github.io/tidybayes/reference/tidybayes-deprecated.html)\nof {**tidybayes**} version 1.0 and a deprecation of horizontal shortcut\ngeoms and stats in {**tidybayes**} 2.1. Because {**tidybayes**}\nintegrates function of the sister package {**ggdist**} the [function\ndescriptions and references of\n{**ggdist**}](https://mjskay.github.io/ggdist/reference/index.html) are\nalso important to consult.\n\nFor the following parts the section on [Point Summaries and\nIntervals](https://mjskay.github.io/tidybayes/articles/tidy-brms.html#point-summaries-and-intervals)\nand the reference on [Point and interval summaries for tidy data frames\nof draws from\ndistributions](https://mjskay.github.io/ggdist/reference/point_interval.html)\nare especially important.\n\nThe {**tidybayes**} package contains a [family of\nfunctions](https://mjskay.github.io/tidybayes/articles/tidy-brms.html#point-summaries-and-intervals)\nthat make it easy to summarize a distribution with a measure of central\ntendency accompanied by intervals. With `tidybayes::median_qi()`, we\nwill ask for the median and quantile-based intervals --- just like we've\nbeen doing with `stats::quantile()`.\n\n::: callout-caution\nAlthough Kurz uses the `samples` data frame I cannot reproduce it with\n`samples_b` data frame, because has changed it values recently to the\nskewed sampling version. To get the same results as Kurz I have to use\nin my naming scheme the `skewed` version.\n:::\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: median-quantile-interval\n\ntidybayes::median_qi(samples_skewed_b$p_skewed_b, .width = .5)\n```\n````\n\n```\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.8428428 0.7087087 0.9349349    0.5 median        qi\n```\n:::\n\n\nNote how the `.width` argument within `tidybayes::median_qi()` worked\nthe same way the `prob` argument did within `rethinking::PI()`. With\n`.width = .5`, we indicated we wanted a quantile-based 50% interval,\nwhich was returned in the `ymin` and `ymax` columns.\n\nThe {**tidybayes**} framework makes it easy to request multiple types of\nintervals. In the following code chunk we'll request 50%, 80%, and 99%\nintervals.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: multiple-intervals\n\ntidybayes::median_qi(samples_skewed_b$p_skewed_b, .width = c(.5, .8, .99))\n```\n````\n\n```\n#>           y      ymin      ymax .width .point .interval\n#> 1 0.8428428 0.7087087 0.9349349   0.50 median        qi\n#> 2 0.8428428 0.5705706 0.9749750   0.80 median        qi\n#> 3 0.8428428 0.2562563 0.9989990   0.99 median        qi\n```\n:::\n\n\n> The .width column in the output indexed which line presented which\n> interval. The value in the y column remained constant across rows.\n> That's because that column listed the measure of central tendency, the\n> median in this case.\n\n> Now let's use the `rethinking::HPDI()` function to return 50% highest\n> posterior density intervals (HPDIs).\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: rethinking-HPDI-b\n\n\nrethinking::HPDI(samples_skewed_b$p_skewed_b, prob = .5)\n```\n````\n\n```\n#>      |0.5      0.5| \n#> 0.8418418 0.9989990\n```\n:::\n\n\n::: callout-note\nMy results (0.8428428 and 1.0000000) are slightly different from the\noutput in Kurz's version (0.8418418, 0.9989990). I assume that these\ndifferences are rounding errors. This happened although I had used the\n`set.seed(3)` value for the Original and Tidyverse variants. TODO: CHECK\nTHIS OUT IN MORE DETAILS.\n:::\n\n> The reason I introduce {**tidybayes**} now is that the functions of\n> the {**brms**} package only support percentile-based intervals of the\n> type we computed with `quantile()` and `median_qi()`. But\n> {**tidybayes**} also supports HPDIs.\n\n::: callout-warning\nThe line `mode_hdi(samples$p_grid, .width = .5)` in Kurz's version is\nnot correct.\n\nThe correct code line is: `mode_hdci(samples$p_grid, .width = .5)`\n\n> `hdi` yields the highest-density interval(s) (also known as the\n> highest posterior density interval). Note: If the distribution is\n> multimodal, `hdi` may return multiple intervals for each probability\n> level (these will be spread over rows). You may wish to use `hdci` ...\n> instead if you want a single highest-density interval, with the caveat\n> that when the distribution is multimodal `hdci` is not a\n> highest-density interval. (See [Point and interval summaries for tidy\n> data frames of draws from\n> distributions](https://mjskay.github.io/ggdist/reference/point_interval.html))\n\nI have therefore changed my version from `tidybayes::mode_hci` to\n`tidybayes::mode_hdci` .\n:::\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: tidyverse-HPDI-b\n\ntidybayes::mode_hdci(samples_skewed_b$p_skewed_b, .width = .5)\n\n```\n````\n\n```\n#>           y      ymin     ymax .width .point .interval\n#> 1 0.9995616 0.8418418 0.998999    0.5   mode      hdci\n```\n:::\n\n\nThis time we used the mode as the measure of central tendency. With this\nfamily of {**tidybayes**} functions, you specify the measure of central\ntendency in the prefix (i.e., mean, median, or mode) and then the type\nof interval you'd like (i.e., `qi()` or `hdci()`).\n\nIf all you want are the intervals without the measure of central\ntendency or all that other technical information, {**tidybayes**} also\noffers the handy `qi()` and `hdi()` functions.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: tidybayes-qi-skewed-dist\n\ntidybayes::qi(samples_skewed_b$p_skewed_b, .width = .5)\n```\n````\n\n```\n#>           [,1]      [,2]\n#> [1,] 0.7087087 0.9349349\n```\n:::\n\n\nThe `qi()` function worked for me and results in the same values as in the Kurz's version. But with `hdi()` I get an error message in the skewed version. (Tt worked in the normal version.)\ncompletely different result:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: tidybayes-hdi-skewed-dist-error\n#| error: true\n\n# skewed version: 3 toss -> 3 Water (Success)\ntidybayes::hdi(samples_skewed_b$p_skewed_b, na.rm = TRUE, .width = .5)\n```\n````\n\n```\n#> Error in quantile.default(dist_y, probs = 1 - .width): missing values and NaN's not allowed if 'na.rm' is FALSE\n```\n\n````{.cell-code}\n```{{r}}\n#| label: tidybayes-hdi-skewed-dist-error\n#| error: true\n\n\n# original version: 9 toss -> 6 Water (Success)\ntidybayes::hdi(samples_b$samples_b, na.rm = TRUE, .width = .5)\n```\n````\n\n```\n#>           [,1]      [,2]\n#> [1,] 0.5685686 0.7597598\n```\n:::\n\n\nTo work correctly I am calling always `hdci()` instead of `hdi()`:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: tidybayes-hdci-skewed-dist\n\ntidybayes::hdci(samples_skewed_b$p_skewed_b, .width = .5)\n```\n````\n\n```\n#>           [,1]     [,2]\n#> [1,] 0.8418418 0.998999\n```\n:::\n\nThese are the same values as in Kurz's version. \n\n\n::: callout-warning\n###### Error with `tidybayes::hdi()`\n\nIn the skewed version `tidybayes::hdi()` does not work for me in the skewed version. I do not know why this is the case. But if I used `tidybayes::hdci()` I've got the same result as Kurz.\n:::\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: figure-3.3\n\n# left panel\np1 <-\n  samples_skewed_b %>% \n  ggplot(aes(x = p_skewed_b, y = posterior_skewed_b)) +\n  # check out our sweet `qi()` indexing\n  geom_area(data = samples_skewed_b %>% \n              filter(p_skewed_b >\n                tidybayes::qi(samples_skewed_b$p_skewed_b, .width = .5)[1] & \n                     p_skewed_b <\n                tidybayes::qi(samples_skewed_b$p_skewed_b, .width = .5)[2]),\n                fill = \"blue\") +\n  geom_line() +\n  labs(subtitle = \"50% Percentile Interval\",\n       x = \"proportion of water (p)\",\n       y = \"density\")\n\n# right panel\np2 <-\n  samples_skewed_b %>% \n  ggplot(aes(x = p_skewed_b, y = posterior_skewed_b)) +\n  geom_area(data = . %>% \n              filter(p_skewed_b > \n                 tidybayes::hdci(samples_skewed_b$p_skewed_b, .width = .5)[1] & \n                       p_skewed_b < \n                 tidybayes::hdci(samples_skewed_b$p_skewed_b, .width = .5)[2]),\n                 fill = \"blue\") +\n  geom_line() +\n  labs(subtitle = \"50% HPDI\",\n       x = \"proportion of water (p)\",\n       y = \"density\")\n\n# combine!\nlibrary(patchwork)\np1 | p2\n```\n````\n\n::: {.cell-output-display}\n![](03-sampling-the-imaginary_files/figure-html/figure-3.3-1.png){width=672}\n:::\n:::\n\n\nAgain I had to change Kurz's version for the correct result: Instead of\n`tidybayes::hci()` one must use `tidybayes::hdci()` for the right hand plot.\n\nComparing the two panels of the plot you can see that in contrast to the 50% HPDI the 50% of PI does not include the highest probability value.\n\n##### Dots and the Pipe\n\n> In the geom_area() line for the HPDI plot, did you notice how we\n> replaced `data = samples_skewed_b` with `data = .`? When using the\n> pipe (i.e., `%>%`), you can use the `.` as a placeholder for the\n> original data object. It's an odd and handy trick to know about.\n\n(We could have made this change in both parts (p1 and p2) of the graph.\nThe only condition is that you have used the full name of the data frame\nallready in the same piped statement.)\n\nLearn more of the [pipe function %\\>% of the {**magrittr**}\npackage](https://magrittr.tidyverse.org/reference/pipe.html) and about\nthe [base R native forward pipe\noperator](https://stat.ethz.ch/R-manual/R-devel/library/base/html/pipeOp.html).\n\nThe native pipe is available starting with R 4.1.0. It is constructed\nwith `|` followed by `>` resulting in the symbol `|>` to differentiate\nit from the {**magrittr**} pipe (%\\>%). To understand the details of the\ndifferences of `%>%` and the native R pipe `|>` read this elaborated\n[blog article by Isabella\nVelásquez](https://ivelasq.rbind.io/blog/understanding-the-r-pipe/index.html),\nan employee of [Posit](https://posit.co/) (formerly RStudio).\n\n##### Difference between PI and HPDI\n\nPI and HPDI are only very different if you have a very skewed\ndistribution. Otherwise they are pretty similar. Let's check this\nassertion:\n\n::: callout-note\nIn this file we have named the variables in the version of the data frame of 6`W` with 9 trials different than the variables of the version of 3`W` with 3 trials. Therefore we do not need (re)calculate (= update) the simulation as in Kurz's version.\n\nFurthermore besides `tidybayes::mean_qi()` I will use `tidybayes::mean_hdi()` and `tidybayes::mean_hdci()`.\n:::\n\n\nTry out my own variable names:\n\na) Results rounded\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: intervals-6-9-not-skewed-rounded\n\nbind_rows(tidybayes::mean_hdci(samples_b$samples_b, .width = c(.8, .95)),\n          tidybayes::mean_hdi(samples_b$samples_b, .width = c(.8, .95)),\n          tidybayes::mean_qi(samples_b$samples_b,  .width = c(.8, .95))) %>% \n  select(.width, .interval, ymin:ymax) %>% \n  arrange(.width) %>% \n  mutate_if(is.double, round, digits = 2)\n```\n````\n\n```\n#>   .width .interval ymin ymax\n#> 1   0.80      hdci 0.48 0.84\n#> 2   0.80       hdi 0.48 0.84\n#> 3   0.80        qi 0.45 0.81\n#> 4   0.95      hdci 0.37 0.90\n#> 5   0.95       hdi 0.37 0.90\n#> 6   0.95        qi 0.35 0.88\n```\n:::\n\n\nSampling from a somewhat Gaussian distribution shows that there are absolut no differences between `tidybayes::mean_hdci()` and `tidybayes::mean_hdi()`.\n\nThere are two differences to Kurz's version: \n1. `ymin` of 0.80 `hdi` is in my version 0.48 and not 0.49. \n2. `ymax` of 0.95 `hdi` is in my version 0.90 and not 0.89.\n\nI believe that this (very small) differences are rounding errors. But not rounding errors in the result values but during the complex `hdi` calculations as the following not rounded display of values demonstrate:\n\nb) Results not rounded\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: intervals-6-9-not-skewed-not-rounded\n\nbind_rows(tidybayes::mean_hdci(samples_b$samples_b, .width = c(.8, .95)),\n          tidybayes::mean_hdi(samples_b$samples_b, .width = c(.8, .95)),\n          tidybayes::mean_qi(samples_b$samples_b,  .width = c(.8, .95))) %>% \n  select(.width, .interval, ymin:ymax) %>% \n  arrange(.width)\n```\n````\n\n```\n#>   .width .interval      ymin      ymax\n#> 1   0.80      hdci 0.4814815 0.8398398\n#> 2   0.80       hdi 0.4814815 0.8398398\n#> 3   0.80        qi 0.4514515 0.8148148\n#> 4   0.95      hdci 0.3723724 0.8958959\n#> 5   0.95       hdi 0.3723724 0.8958959\n#> 6   0.95        qi 0.3493493 0.8788789\n```\n:::\n\nBut these small differences are not important. In McElreath words:\n> Remember, we’re not launching rockets or calibrating atom smashers, so fetishizing precision to the 5th decimal place will not improve your science.\n\nThe same is true of the small differences between `qi` and `hdi`. They difference is only 2 resp. 3 percent. \n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: intervals-3-9-skewed-version\n\nbind_rows(tidybayes::mean_hdci(samples_skewed_b$p_skewed_b, .width = c(.8, .95)),\n          tidybayes::mean_qi(samples_skewed_b$p_skewed_b,  .width = c(.8, .95))) %>% \n  select(.width, .interval, ymin:ymax) %>% \n  arrange(.width) %>% \n  mutate_if(is.double, round, digits = 2)\n```\n````\n\n```\n#>   .width .interval ymin ymax\n#> 1   0.80      hdci 0.67 1.00\n#> 2   0.80        qi 0.57 0.97\n#> 3   0.95      hdci 0.48 1.00\n#> 4   0.95        qi 0.40 0.99\n```\n:::\n\nThe skewed version shows bigger differences of 10% resp. 8% between `mean_hdci()` and `mean_qi()`. (This calculation is missing in Kurz's version.)\n\nBecause of the disadvantages of HPDI (more computationally intensive, greater simulation variance and harder to understand) we’ll primarily stick to the PI-based intervals.\n\n\n### Point Estimates\n\n#### Original\n\n> The third and final common summary task for the posterior is to produce point estimates of some kind. Given the entire posterior distribution, what value should you report? This seems like an innocent question, but it is difficult to answer. **The Bayesian parameter estimate is precisely the entire posterior distribution, which is not a single number, but instead a function that maps each unique parameter value onto a plausibility value.** So really the most important thing to note is that you don’t have to choose a point estimate. It’s hardly ever necessary and often harmful. It discards information. (emphasis is mine, pb)\n\nBut if you must do it … we will take again the globe tossing experiment in which we observe 3 waters out of 3 tosses, e.g. the very skewed distribution.\n\n##### Calcualte MAP\n\n> First, it is very common for scientists to report the parameter value with highest posterior probability, a _maximum a posteriori_ (MAP) estimate.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: calculate-skewed-MAP-grid-a\n\n### actually the grid is not skewed. I should change the names accordingly.\n\n## R code 3.14\np_grid_skewed_a[which.max(posterior_skewed_a)]\n```\n````\n\n```\n#> [1] 1\n```\n:::\n\nOr if you instead have samples from the posterior, you can still approximate the same point:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: calculate-skewed-MAP-samples-a\n\n## R code 3.15\nrethinking::chainmode(samples_skewed_a, adj = 0.01)\n```\n````\n\n```\n#> [1] 0.9938226\n```\n:::\n\n\n##### Calculate measures of central tendency\n\nBut why is the MAP, the mode, so interesting? Why not report the posterior mean or median?\n\n\n::: {.cell}\n\n````{.cell-code #lst-mean-median-skewed-samples lst-cap=\"Posterior mean and median of the skewed distribution (all three draws are `W`)\"}\n```{{r}}\n#| label: mean-median-skewed-samples-a\n#| attr-source: '#lst-mean-median-skewed-samples lst-cap=\"Posterior mean and median of the skewed distribution (all three draws are `W`)\"'\n\n## R code 3.16\nmean(samples_skewed_a)\nmedian(samples_skewed_a)\n```\n````\n\n```\n#> [1] 0.8027632\n#> [1] 0.8428428\n```\n:::\n\n\n##### Plot postponend\n\nThe graphical representation as shown in Figure 3.4 will be calculated in the tidyverse version of this section. See: @fig-minimum-loss-b for the left panel and @fig-minimum-loss2-b for the right panel of Figure 3.4.\n\n> These are also point estimates, and they also summarize the posterior. But all three—the mode (MAP), mean, and median—are different in this case. How can we choose?\n\n##### Loss function\n\nOne principled way to go beyond using the entire posterior as the estimate is to choose a **LOSS FUNCTION**. A loss function is a rule that tells you the cost associated with using any particular point estimate. While statisticians and game theorists have long been interested in loss functions, and how Bayesian inference supports them, scientists hardly ever use them explicitly. The key insight is that _different loss functions imply different point estimates_.\n\n> Calculating expected loss for any given decision means using the posterior to average over our uncertainty in the true value. Of course we don’t know the true value, in most cases. But if we are going to use our model’s information about the parameter, that means using the entire posterior distribution. So suppose we decide $p = 0.5$ will be our decision. Then the expected loss will be:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: loss-expected-0.5-a\n\n## R code 3.17\nsum(posterior_skewed_a * abs(0.5 - p_grid_skewed_a))\n```\n````\n\n```\n#> [1] 0.3128752\n```\n:::\n\n> All the code above does is compute the weighted average loss, where each loss is weighted by its corresponding posterior probability. There’s a trick for repeating this calculation for every possible decision, using the function sapply.\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: loss-function-a\n\n## R code 3.18\nloss_a <- sapply(p_grid_skewed_a, function(d) sum(posterior_skewed_a * abs(d - p_grid_skewed_a)))\nhead(loss_a)\n```\n````\n\n```\n#> [1] 0.8004001 0.7993991 0.7983981 0.7973971 0.7963961 0.7953951\n```\n:::\n\n\n> Now the symbol `loss_a` contains a list of loss values, one for each possible decision, corresponding the values in `p_grid_skewed_a`. From here, it’s easy to find the parameter value that minimizes the loss:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: minimize-loss-a\n\n## R code 3.19\np_grid_skewed_a[which.min(loss_a)]\n```\n````\n\n```\n#> [1] 0.8408408\n```\n:::\n\n> And this is actually the posterior median, the parameter value that splits the posterior density such that half of the mass is above it and half below it. \n\nWe have already calculated the posterior median in @lst-mean-median-skewed-samples. Because of sampling variation it is not identical but pretty close (0.8428428 vs. 0.8408408).\n\n**Learnings**: \n\n> In order to decide upon a point estimate, a single-value summary of the posterior distribution, we need to pick a loss function. Different loss functions nominate different point estimates. The two most common examples are the absolute loss as above, which leads to the median as the point estimate, and the quadratic loss $(d - p)^{2}$, which leads to the posterior mean `(mean(samples))` as the point estimate.\n\n> When the posterior distribution is symmetrical and normal-looking, then the median and mean converge to the same point, which relaxes some anxiety we might have about choosing a loss function. For the original globe tossing data (6 waters in 9 tosses), for example, the mean and median are barely different.\n\n**Comparison of mean & median** with globe tossing data (6 waters in 9 tosses) versus (3 waters in 3 tosses):\n\n6/9: Mean = 0.6400664 Median = 0.6486486\n3/3: Mean = 0.8027632 Median = 0.8428428\n\n::: callout-important\nInstead of deciding what parameter to report for summarizing the posterior distribution it is usually better to communicate as much as you can about the posterior distribution, as well as the data and the model itself, so that others can build upon your work. \n\nThis advice is also valid if you just want to accept or not to accept an hypothesis. Because the challenge then is to say what the relevant costs and benefits would be, in terms of the knowledge gained or lost.\n:::\n\n\n#### Tidyverse\n\n##### Calculate MAP\n\nTo get the MAP of the skewed version (three tosses with thre `W`) we have to `arrange()` our `d_b` tibble in descending order by posterior. Then we will see the corresponding p_grid_b value for its MAP estimate.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: calculate-skewed-MAP-grid-b\n\nsamples_skewed_b %>% \n  arrange(desc(posterior_skewed_b))\n```\n````\n\n```\n#> # A tibble: 10,000 × 6\n#>    p_skewed_b prior_skewed_b likelihood_b posterior_b likelihood_skewed_b\n#>         <dbl>          <dbl>        <dbl>       <dbl>               <dbl>\n#>  1          1              1            0           0                   1\n#>  2          1              1            0           0                   1\n#>  3          1              1            0           0                   1\n#>  4          1              1            0           0                   1\n#>  5          1              1            0           0                   1\n#>  6          1              1            0           0                   1\n#>  7          1              1            0           0                   1\n#>  8          1              1            0           0                   1\n#>  9          1              1            0           0                   1\n#> 10          1              1            0           0                   1\n#> # ℹ 9,990 more rows\n#> # ℹ 1 more variable: posterior_skewed_b <dbl>\n```\n:::\n\nTo emphasize it, we can use slice() to select the top row. The MAP value is the column `posterior_skewed_b`.\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: calculate-skewed-MAP-grid2-b\n\nsamples_skewed_b %>% \n  arrange(desc(posterior_skewed_b)) |> \n  slice(1)\n```\n````\n\n```\n#> # A tibble: 1 × 6\n#>   p_skewed_b prior_skewed_b likelihood_b posterior_b likelihood_skewed_b\n#>        <dbl>          <dbl>        <dbl>       <dbl>               <dbl>\n#> 1          1              1            0           0                   1\n#> # ℹ 1 more variable: posterior_skewed_b <dbl>\n```\n:::\n\n\n##### Calculate measures of central tendency\n\nWe can get the mode with `mode_hdci()` or `mode_qi()`\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: tidybayes-mode-qi-and-hdci\n\nsamples_skewed_b %>% tidybayes::mode_qi(p_skewed_b)\nsamples_skewed_b %>% tidybayes::mode_hdci(p_skewed_b)\n```\n````\n\n```\n#> # A tibble: 1 × 6\n#>   p_skewed_b .lower .upper .width .point .interval\n#>        <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1       1.00  0.399  0.994   0.95 mode   qi       \n#> # A tibble: 1 × 6\n#>   p_skewed_b .lower .upper .width .point .interval\n#>        <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n#> 1       1.00  0.475      1   0.95 mode   hdci\n```\n:::\n\n\nThose returned a lot of output in addition to the mode. If all you want is the mode itself, you can just use `tidybayes::Mode()`.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: tidybayes-mode\n\ntidybayes::Mode(samples_skewed_b$p_skewed_b)\n```\n````\n\n```\n#> [1] 0.9995616\n```\n:::\n\nMedians and means are typical measures of central tendency, too.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: tidybayes-mean-and-median\n\nsamples_skewed_b %>% \n  summarise(mean   = mean(p_skewed_b),\n            median = median(p_skewed_b))\n```\n````\n\n```\n#> # A tibble: 1 × 2\n#>    mean median\n#>   <dbl>  <dbl>\n#> 1 0.803  0.843\n```\n:::\n\n\n##### Plot left panel of figure 3.4\n\n1. Bundle the three types of estimates into a tibble\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: bundle-skewed-point-estimates\n\n(\n  point_estimates_b <-\n  bind_rows(samples_skewed_b %>% tidybayes::mean_qi(p_skewed_b),\n            samples_skewed_b %>% tidybayes::median_qi(p_skewed_b),\n            samples_skewed_b %>% tidybayes::mode_qi(p_skewed_b)) %>% \n  select(p_skewed_b, .point) %>% \n  # these last two columns will help us annotate  \n  mutate(x = p_skewed_b + c(-.03, .03, -.03),\n         y = c(.0005, .0012, .002))\n)\n```\n````\n\n```\n#> # A tibble: 3 × 4\n#>   p_skewed_b .point     x      y\n#>        <dbl> <chr>  <dbl>  <dbl>\n#> 1      0.803 mean   0.773 0.0005\n#> 2      0.843 median 0.873 0.0012\n#> 3      1.00  mode   0.970 0.002\n```\n:::\n\nPlotting the results:\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-skewed-point-estimates_b\n#| fig-cap: \"Posterior distribution (blue) after observing 3 water in 3 tosses of the globe. Vertical lines show the locations of the mode, median, and mean. Each point implies a different loss function.\"\n\nsamples_skewed_b %>% \n  ggplot(aes(x = p_skewed_b)) +\n  geom_area(aes(y = posterior_skewed_b),\n            fill = \"deepskyblue\") +\n  geom_vline(xintercept = point_estimates_b$p_skewed_b) +\n  geom_text(data = point_estimates_b,\n            aes(x = x, y = y, label = .point),\n            angle = 90) +\n  labs(x = \"proportion of water (p)\",\n       y = \"density\") +\n  theme(panel.grid = element_blank())\n```\n````\n\n::: {.cell-output-display}\n![Posterior distribution (blue) after observing 3 water in 3 tosses of the globe. Vertical lines show the locations of the mode, median, and mean. Each point implies a different loss function.](03-sampling-the-imaginary_files/figure-html/fig-skewed-point-estimates_b-1.png){#fig-skewed-point-estimates_b width=672}\n:::\n:::\n\nIn contrast the other distribution with 6 successes by 9 trials (tosses):\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-sym-point-estimates_b\n#| fig-cap: \"Point estimates in the almost symmetrical distribution of 6 successes (`W`) in 9 tosses.\"\n\n(\n    point_estimates_b <-\n      bind_rows(samples_b %>% tidybayes::mean_qi(samples_b),\n                samples_b %>% tidybayes::median_qi(samples_b),\n                samples_b %>% tidybayes::mode_qi(samples_b)) %>% \n      select(samples_b, .point) %>% \n      # these last two columns will help us annotate  \n      mutate(x = samples_b + c(-.03, .03, -.03),\n             y = c(.0005, .0012, .002))\n)\n\nsamples_b %>% \n  ggplot(aes(x = samples_b)) +\n  geom_area(aes(y = posterior_samples_b),\n            fill = \"deepskyblue\") +\n  geom_vline(xintercept = point_estimates_b$samples_b) +\n  geom_text(data = point_estimates_b,\n            aes(x = x, y = y, label = .point),\n            angle = 90) +\n  labs(x = \"proportion of water (p)\",\n       y = \"density\") +\n  theme(panel.grid = element_blank())\n```\n````\n\n```\n#> # A tibble: 3 × 4\n#>   samples_b .point     x      y\n#>       <dbl> <chr>  <dbl>  <dbl>\n#> 1     0.640 mean   0.610 0.0005\n#> 2     0.649 median 0.679 0.0012\n#> 3     0.651 mode   0.621 0.002\n```\n\n::: {.cell-output-display}\n![Point estimates in the almost symmetrical distribution of 6 successes (`W`) in 9 tosses.](03-sampling-the-imaginary_files/figure-html/fig-sym-point-estimates_b-1.png){#fig-sym-point-estimates_b width=672}\n:::\n:::\n\n##### Loss function\n\nLet $p$ be the proportion of the Earth covered by water and $d$ be our guess. If McElreath pays us $100 if we guess exactly right but subtracts money from the prize proportional to how far off we are, then our loss is proportional to $d - p$. If we decide $d = .5$, we can compute our expected loss.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: loss-epected-0.5-b\n\nd_skewed_b |> \n    summarise(`expected loss` = sum(posterior_skewed_b * abs(0.5 - p_grid_b)))\n```\n````\n\n```\n#> # A tibble: 1 × 1\n#>   `expected loss`\n#>             <dbl>\n#> 1           0.313\n```\n:::\n\n\nThe `map()` family of the [{**purrr**} package](https://purrr.tidyverse.org/) is the tidyverse alternative to the family of `apply()` functions from the base R framework. You can learn more about how to use the `map()` family on different places:\n\n- [Purrr reference](https://purrr.tidyverse.org/reference/map.html): Apply a function to each element of a vector\n- [Purrr tutorial](https://jennybc.github.io/purrr-tutorial/ls01_map-name-position-shortcuts.html): Introduction to map(): extract elements\n- [University of Virginia Library](https://data.library.virginia.edu/getting-started-with-the-purrr-package-in-r/): Getting Started with the purrr Package in R\n\nCalculate loss function\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: loss-function-b\n\nmake_loss_b <- function(our_d) {\n  d_skewed_b %>% \n    mutate(loss_b = posterior_skewed_b * abs(our_d - p_grid_b)) %>% \n    summarise(weighted_average_loss_b = sum(loss_b))\n}\n\n(\n  l_b <-\n  d_skewed_b %>% \n  select(p_grid_b) %>% \n  rename(decision_b = p_grid_b) %>% \n  mutate(weighted_average_loss_b = purrr::map(decision_b, make_loss_b)) %>% \n  unnest(weighted_average_loss_b) \n)\n```\n````\n\n```\n#> # A tibble: 1,000 × 2\n#>    decision_b weighted_average_loss_b\n#>         <dbl>                   <dbl>\n#>  1    0                         0.800\n#>  2    0.00100                   0.799\n#>  3    0.00200                   0.798\n#>  4    0.00300                   0.797\n#>  5    0.00400                   0.796\n#>  6    0.00501                   0.795\n#>  7    0.00601                   0.794\n#>  8    0.00701                   0.793\n#>  9    0.00801                   0.792\n#> 10    0.00901                   0.791\n#> # ℹ 990 more rows\n```\n:::\n\n\nCalculate the minimum loss\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: minimize-loss-b\n\n# this will help us find the x and y coordinates for the minimum value\n(\n    min_loss_b <-\n      l_b %>% \n      filter(weighted_average_loss_b == min(weighted_average_loss_b)) %>% \n      as.numeric()\n)\n```\n````\n\n```\n#> [1] 0.8408408 0.1273465\n```\n:::\n\n\nNow we’re ready for the right panel of Figure 3.4.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-minimum-loss-b\n#| fig-cap: \"Expected loss under the rule that loss is proportional to absolute distance of decision (horizontal axis) from the true value. The point marks the value of `p` that minimizes the expected loss, the posterior median.\"\n\nl_b %>%   \n  ggplot(aes(x = decision_b, y = weighted_average_loss_b)) +\n  geom_area(fill = \"deepskyblue\") +\n  geom_vline(xintercept = min_loss_b[1], color = \"black\", linetype = 3) +\n  geom_hline(yintercept = min_loss_b[2], color = \"black\", linetype = 3) +\n  ylab(\"expected proportional loss\") +\n  theme(panel.grid = element_blank())\n```\n````\n\n::: {.cell-output-display}\n![Expected loss under the rule that loss is proportional to absolute distance of decision (horizontal axis) from the true value. The point marks the value of `p` that minimizes the expected loss, the posterior median.](03-sampling-the-imaginary_files/figure-html/fig-minimum-loss-b-1.png){#fig-minimum-loss-b width=672}\n:::\n:::\n\n\nWe saved the exact minimum value as `min_loss_b[1]`, which is 0.8408408. Within sampling error, this is the posterior median as depicted by our samples.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: posterior-skewed-median_b\n\nsamples_skewed_b %>% \n  summarise(posterior_median_b = median(p_skewed_b))\n```\n````\n\n```\n#> # A tibble: 1 × 1\n#>   posterior_median_b\n#>                <dbl>\n#> 1              0.843\n```\n:::\n\n\nThe quadratic loss $(d−p)^{2}$ suggests we should use the mean instead. Let’s investigate.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: fig-minimum-loss2-b\n#| fig-cap: \"Expected loss under the rule that loss is quadratic to the distance of decision (horizontal axis) from the true value. The point marks the value of `p` that minimizes the expected loss, the posterior mean\"\n\n# amend our loss function\n\nmake_loss2_b <- function(our_d2) {\n  d_skewed_b %>% \n    mutate(loss2_b = posterior_skewed_b * (our_d2 - p_grid_b)^2) %>% \n    summarise(weighted_average_loss2_b = sum(loss2_b))\n}\n\n\n# remake our `l` data\nl2_b <-\n  d_skewed_b %>% \n  select(p_grid_b) %>% \n  rename(decision2_b = p_grid_b) %>% \n  mutate(weighted_average_loss2_b = purrr::map(decision2_b, make_loss2_b)) %>% \n  unnest(weighted_average_loss2_b)\n\n# update to the new minimum loss coordinates\n\n(\n    min_loss2_b <-\n      l2_b %>% \n      filter(weighted_average_loss2_b == min(weighted_average_loss2_b)) %>% \n      as.numeric()\n)\n\n# update the plot\nl2_b %>%   \n  ggplot(aes(x = decision2_b, y = weighted_average_loss2_b)) +\n  geom_area(fill = \"deepskyblue\") +\n  geom_vline(xintercept = min_loss2_b[1], color = \"black\", linetype = 3) +\n  geom_hline(yintercept = min_loss2_b[2], color = \"black\", linetype = 3) +\n  ylab(\"expected proportional loss\") +\n  theme(panel.grid = element_blank())\n```\n````\n\n```\n#> [1] 0.80080080 0.02669345\n```\n\n::: {.cell-output-display}\n![Expected loss under the rule that loss is quadratic to the distance of decision (horizontal axis) from the true value. The point marks the value of `p` that minimizes the expected loss, the posterior mean](03-sampling-the-imaginary_files/figure-html/fig-minimum-loss2-b-1.png){#fig-minimum-loss2-b width=672}\n:::\n:::\n\nBased on quadratic loss $(d−p)^{2}$, the exact minimum value is 0.8008008. Within sampling error, this is the posterior mean of our samples.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: posterior-skewed-mean_b\n\nsamples_skewed_b %>% \n  summarise(posterior_mean_b = mean(p_skewed_b))\n```\n````\n\n```\n#> # A tibble: 1 × 1\n#>   posterior_mean_b\n#>              <dbl>\n#> 1            0.803\n```\n:::\n\n\n## I STOPPED HERE! (2023-07-29)\n",
    "supporting": [
      "03-sampling-the-imaginary_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}