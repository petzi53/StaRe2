{
  "hash": "76a263f2372dd975082e8643c06925b5",
  "result": {
    "markdown": "# 4b: Geocentric Models\n\n## 4.0b Why Normal Distributions Are Normal\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: setup\n\nlibrary(tidyverse)\n```\n````\n\n```\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n````{.cell-code}\n```{{r}}\n#| label: setup\n\nlibrary(skimr)\n```\n````\n:::\n\n\n**What follows is my own approach/trial:**\n\n> Suppose you and a thousand of your closest friends line up on the\n> halfway line of a soccer field (football pitch). Each of you has a\n> coin in your hand. At the sound of the whistle, you begin flipping the\n> coins. Each time a coin comes up heads, that person moves one step\n> towards the left-hand goal. Each time a coin comes up tails, that\n> person moves one step towards the right-hand goal. Each person flips\n> the coin 16 times, follows the implied moves, and then stands still.\n> Now we measure the distance of each person from the halfway line. Can\n> you predict what proportion of the thousand people who are standing on\n> the halfway line? How about the proportion 5 yards left of the\n> line?Showing that there's nothing special about the underlying coin\n> flip:\n\n> Assume ... that each step is different from all the others, a random\n> distance between zero and one ~~yard~~ meter. Thus a coin is flipped,\n> a distance between zero and one ~~yard~~ meter is taken in the\n> indicated direction, and the process repeats. To simulate this, we\n> generate for each person a list of 16 random numbers between −1 and 1.\n> These are the individual steps. Then we add these steps together to\n> get the position after 16 steps. Then we need to replicate this\n> procedure 1000 times.\n\nTo show how these assumptions turn out I will reflect on every little\nstep:\n\n1.  [**Binomial\n    distribution**](https://en.wikipedia.org/wiki/Binomial_distribution):\n    We are assuming that the experiment uses a fair coin and that the\n    coin is caught in the air to prevent biases that a skilled coin\n    flipper could produce. Under this assumption each of the 16 flips\n    (starting with the first flip to the 16th flip) has the same\n    probability of 0.5. This is the essential characteristic of the\n    [bernoulli\n    distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution)\n    a special case of the binomial distribution.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: bernoulli-dist\nset.seed(4)\nrbinom(16, 1, .5)\n```\n````\n\n```\n#>  [1] 1 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0\n```\n:::\n\n\n`1` means a step to the right and `0` is a step to the left (or vice\nversa).\n\n2.  [Uniform\n    distribution](https://en.wikipedia.org/wiki/Continuous_uniform_distribution):\n    To show that the binary event of coin tossing is not necessary for\n    the result of a normal distribution, we assume that each step\n    measures a random distance between 0 and 1 meter. Under this\n    assumption each of the 16 flips has still the same probability of\n    0.5 but the resulting step is randomly distributed. This\n    characteristics is caught by the uniform distribution.\n\n::: callout-important\n## Uniform distribution\n\nThe [uniform\ndistribution](https://www.statology.org/uniform-distribution/) is a\nprobability distribution in which every value between an interval from\n*a* to *b* is equally likely to occur. (see: [5 Real Life Examples of\nthe Uniform\nDistribution](https://www.statology.org/uniform-distribution-real-life-examples/))\n:::\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: uniform-dist-one-person\n\n\nset.seed(4)\none_person_tbl <- as_tibble_col(runif(16, -1, 1), \n                                column_name = \"position\")\none_person_tbl\n```\n````\n\n```\n#> # A tibble: 16 × 1\n#>    position\n#>       <dbl>\n#>  1   0.172 \n#>  2  -0.982 \n#>  3  -0.413 \n#>  4  -0.445 \n#>  5   0.627 \n#>  6  -0.479 \n#>  7   0.449 \n#>  8   0.812 \n#>  9   0.898 \n#> 10  -0.854 \n#> 11   0.509 \n#> 12  -0.428 \n#> 13  -0.800 \n#> 14   0.908 \n#> 15  -0.169 \n#> 16  -0.0898\n```\n:::\n\n\nThe figures are the step sizes in centimeter to the right (positive\nvalues) or to the left.(negative values) --- or vice versa.\n\n3.  **Summarize step distances**: To get the end position after 16 coin\n    flips and the following randomly distributed step sizes to the left\n    or right, we have to summarize all 16 steps (increments).\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: result-one-person\n\nset.seed(4)\n\n# a one-liner, including the uniform distribution\nsum(runif(16, -1, 1))\n\n# taking the column of the stored tibble\nsum(one_person_tbl$position)\n```\n````\n\n```\n#> [1] -0.2838943\n#> [1] -0.2838943\n```\n:::\n\n\nWe assume the a negative value is a step to the left than the position\nof the one (first) person is after 16 coin tosses and the following 16\nsteps 28 centimeter to the left. This is the same result as for the\nfirst value for the `a` version.\n\n4.  **Store all step values and accumulate the result**\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: one-person-experiment\n\nset.seed(4)\n\n\nexp_1 <- as_tibble_col(runif(16, -1, 1), column_name = \"deviation\") |> \n    mutate(person = rep(1, 16),\n           n = 1:n(), \n           .before = \"deviation\") |> \n    add_row(person = 1, n = 0, deviation = 0.0, .before = 1) |> \n    mutate(position = cumsum(deviation))\nexp_1\n```\n````\n\n```\n#> # A tibble: 17 × 4\n#>    person     n deviation position\n#>     <dbl> <dbl>     <dbl>    <dbl>\n#>  1      1     0    0        0     \n#>  2      1     1    0.172    0.172 \n#>  3      1     2   -0.982   -0.811 \n#>  4      1     3   -0.413   -1.22  \n#>  5      1     4   -0.445   -1.67  \n#>  6      1     5    0.627   -1.04  \n#>  7      1     6   -0.479   -1.52  \n#>  8      1     7    0.449   -1.07  \n#>  9      1     8    0.812   -0.259 \n#> 10      1     9    0.898    0.639 \n#> 11      1    10   -0.854   -0.215 \n#> 12      1    11    0.509    0.294 \n#> 13      1    12   -0.428   -0.134 \n#> 14      1    13   -0.800   -0.933 \n#> 15      1    14    0.908   -0.0253\n#> 16      1    15   -0.169   -0.194 \n#> 17      1    16   -0.0898  -0.284\n```\n:::\n\n\nAfter I compared with the Kurz version, I noticed that I have to include\nthe start position (= zero) as well. This means that there are 17 states\nnot 16.\n\n5.  **Show graph for all 16 positions**\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: one-person-graph\n\nggplot(data = exp_1, mapping = aes(n, position)) +\n    geom_path(colour = \"red\") +\n    geom_step(colour = \"blue\")\n```\n````\n\n::: {.cell-output-display}\n![](04b-geocentric-models_files/figure-html/one-person-graph-1.png){width=672}\n:::\n:::\n\n\nThere are two possible display modes: `geom_line()` / `geom_path()` and\n`geom_step()`. I think McElreath used the line variant but it seems to\nme that the step mode represents the experiment better.\n\n6.  **Replicate 1000 times**: Now we have to replicate the experiment\n    for one person 1000 times.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: sim-step-experiment-b\n\n# we set the seed to make the results of `runif()` reproducible.\nset.seed(4)\n\npos_b <- \n  # make data with 3 people, 16 steps each with a starting point of `step_b == 0` (i.e., 17 rows per person)\n  crossing(person = 1:3,\n           step = 0:16) |>  \n  # for all steps above `step == 0` simulate a `deviation`\n  mutate(deviation = \n             map_dbl(step, ~if_else(. == 0, 0, runif(1, -1, 1)))) |> \n # after grouping by `person`, compute the cumulative sum of the deviations, then `ungroup()`\n  group_by(person) %>%\n  mutate(position = cumsum(deviation)) %>% \n  ungroup() \nglimpse(pos_b)\n```\n````\n\n```\n#> Rows: 51\n#> Columns: 4\n#> $ person    <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, …\n#> $ step      <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 0,…\n#> $ deviation <dbl> 0.00000000, -0.98210841, -0.41252078, -0.44525008, 0.6271484…\n#> $ position  <dbl> 0.0000000, -0.9821084, -1.3946292, -1.8398793, -1.2127308, -…\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: plot-experiment\n\nggplot(data = pos_b, \n       aes(x = step, y = position, group = person)) +\n  geom_vline(xintercept = c(4, 8, 16), linetype = 2) +\n  geom_line(aes(color = person < 2, alpha  = person < 2)) +\n  scale_color_manual(values = c(\"skyblue4\", \"black\")) +\n  scale_alpha_manual(values = c(1/5, 1)) +\n  scale_x_continuous(\"step number\", breaks = 0:4 * 4) +\n  theme(legend.position = \"none\")\n```\n````\n\n::: {.cell-output-display}\n![](04b-geocentric-models_files/figure-html/plot-experiment-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: thousand-persons-graph\n#| eval: false\n\n# set seed to replicate the result\nset.seed(4)\n\nstep_exp <- function() {\n    exp <- as_tibble_col(runif(16, -1, 1), \n                         column_name = \"stepsize\") |> \n        mutate(n = 1:16, cum_step = cumsum(stepsize))\n    p <- ggplot(data = exp, mapping = aes(n, cum_step)) +\n        geom_line(colour = \"red\")\n}\n\nplot_exp <- 1:7 |> \n    map(step_exp)\nplot_exp[[7]]\n\n```\n````\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: my-sim-step-experiment\n#| eval: false\n\n# set seed to replicate the result\nset.seed(4)\n\n(\n    exp_1000 <- as_tibble_col(runif(16, -1, 1), column_name = \"stepsize\") |> \n        mutate(n = 1:n(),\n                cum_step = cumsum(stepsize))\n)\n\npos_b <- as_tibble(replicate(1000, sum(runif(16, -1, 1))))\npos_b\nggplot(data = (pos_b), aes(value)) +\n    geom_histogram()\n```\n````\n:::\n\n\n## 4.1b Normal by Adding\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: normal-by-adding\n\n# we set the seed to make the results of `runif()` reproducible.\nset.seed(4)\n\npos <- \n  # make data with 100 people, 16 steps each with a starting point of `step == 0` (i.e., 17 rows per person)\n  crossing(person = 1:100,\n           step   = 0:16) %>% \n  # for all steps above `step == 0` simulate a `deviation`\n  mutate(deviation = map_dbl(step, ~if_else(. == 0, 0, runif(1, -1, 1)))) %>% \n  # after grouping by `person`, compute the cumulative sum of the deviations, then `ungroup()`\n  group_by(person) %>%\n  mutate(position = cumsum(deviation)) %>% \n  ungroup() \n```\n````\n:::\n\n\n## 4.3b Gaussian Model of Height\n\n### 4.3.1b The data\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: load-howell-data-b\n\nlibrary(rethinking)\n```\n````\n\n```\n#> Loading required package: rstan\n#> Loading required package: StanHeaders\n#> \n#> rstan version 2.26.22 (Stan version 2.26.1)\n#> For execution on a local, multicore CPU with excess RAM we recommend calling\n#> options(mc.cores = parallel::detectCores()).\n#> To avoid recompilation of unchanged Stan programs, we recommend calling\n#> rstan_options(auto_write = TRUE)\n#> For within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\n#> change `threads_per_chain` option:\n#> rstan_options(threads_per_chain = 1)\n#> \n#> Attaching package: 'rstan'\n#> The following object is masked from 'package:tidyr':\n#> \n#>     extract\n#> Loading required package: cmdstanr\n#> This is cmdstanr version 0.5.3\n#> - CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n#> - CmdStan path: /Users/petzi/.cmdstan/cmdstan-2.32.2\n#> - CmdStan version: 2.32.2\n#> Loading required package: parallel\n#> rethinking (Version 2.31)\n#> \n#> Attaching package: 'rethinking'\n#> The following object is masked from 'package:rstan':\n#> \n#>     stan\n#> The following object is masked from 'package:purrr':\n#> \n#>     map\n#> The following object is masked from 'package:stats':\n#> \n#>     rstudent\n```\n\n````{.cell-code}\n```{{r}}\n#| label: load-howell-data-b\n\n\ndata(Howell1)\nd_b <- Howell1\n```\n````\n:::\n\n\nIn contrast to the bmrs-version I have chosen two different approaches:\n\n1.  Instead of detaching the **`rethinking`** package I am trying to use\n    the **`conflicted`** package. I am still not sure if this will work\n    all the way through the book, but I think that it could be a better\n    approach. Especially as I am using all the time the **`rethinking`**\n    and **`brms`** packages in parallel.\n2.  Kurz states that the **`brms`** package does not have a function\n    like `precis()` from the rethinking packages. He suggests to use as\n    a partly replacement `summary()` and then to use **`ggplot2`** or\n    the [`histospark()`\n    function](https://github.com/hadley/precis/blob/master/R/histospark.R)\n    from another approach to summarize (**`precis`**) data by Hadley\n    Wickham. Although this is an interesting approach I think the the\n    **`skimr`** package is better suited for a replacement. It conforms\n    to the tidyverse approach and has tiny histograms included as in the\n    `rethinking::precis()` function. Although it shows different p\n    values (0, 25, 50, 75, 100) instead of 5,5 and 94,5% I believe it is\n    configurable. But here I will not delve into **`skimr`** to verify\n    this assumption as this is not necessary to understand the content\n    of SR2.\n\n::: callout-warning\n## Function conflicts\n\nMy first change (to use the **`conflicted`** package instead `unload()`\ndid not work. I believe that the reason was that I used the\n**`rethinking`** package in the `setup` chunk. Therefore I will go with\nthe Kurz version (= detaching **`rethinking`**).\n:::\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: unload-rethinking\n\nrm(Howell1)\ndetach(package:rethinking, unload = T)\nlibrary(brms)\n```\n````\n\n```\n#> Loading required package: Rcpp\n#> Loading 'brms' package (version 2.20.0). Useful instructions\n#> can be found by typing help('brms'). A more detailed introduction\n#> to the package is available through vignette('brms_overview').\n#> \n#> Attaching package: 'brms'\n#> The following object is masked from 'package:rstan':\n#> \n#>     loo\n#> The following object is masked from 'package:stats':\n#> \n#>     ar\n```\n:::\n\n\n#### **4.3.1.1b Show the data**\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: show-howell-data-b\n\nglimpse(d_b)\nsummary(d_b)\nskim(d_b)\n```\n````\n\n```\n#> Rows: 544\n#> Columns: 4\n#> $ height <dbl> 151.7650, 139.7000, 136.5250, 156.8450, 145.4150, 163.8300, 149…\n#> $ weight <dbl> 47.82561, 36.48581, 31.86484, 53.04191, 41.27687, 62.99259, 38.…\n#> $ age    <dbl> 63.0, 63.0, 65.0, 41.0, 51.0, 35.0, 32.0, 27.0, 19.0, 54.0, 47.…\n#> $ male   <int> 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, …\n#>      height           weight            age             male       \n#>  Min.   : 53.98   Min.   : 4.252   Min.   : 0.00   Min.   :0.0000  \n#>  1st Qu.:125.09   1st Qu.:22.008   1st Qu.:12.00   1st Qu.:0.0000  \n#>  Median :148.59   Median :40.058   Median :27.00   Median :0.0000  \n#>  Mean   :138.26   Mean   :35.611   Mean   :29.34   Mean   :0.4724  \n#>  3rd Qu.:157.48   3rd Qu.:47.209   3rd Qu.:43.00   3rd Qu.:1.0000  \n#>  Max.   :179.07   Max.   :62.993   Max.   :88.00   Max.   :1.0000\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |d_b  |\n|Number of rows           |544  |\n|Number of columns        |4    |\n|_______________________  |     |\n|Column type frequency:   |     |\n|numeric                  |4    |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|    sd|    p0|    p25|    p50|    p75|   p100|hist  |\n|:-------------|---------:|-------------:|------:|-----:|-----:|------:|------:|------:|------:|:-----|\n|height        |         0|             1| 138.26| 27.60| 53.98| 125.10| 148.59| 157.48| 179.07|▁▂▂▇▇ |\n|weight        |         0|             1|  35.61| 14.72|  4.25|  22.01|  40.06|  47.21|  62.99|▃▂▃▇▂ |\n|age           |         0|             1|  29.34| 20.75|  0.00|  12.00|  27.00|  43.00|  88.00|▇▆▅▂▁ |\n|male          |         0|             1|   0.47|  0.50|  0.00|   0.00|   0.00|   1.00|   1.00|▇▁▁▁▇ |\n:::\n:::\n\n\n#### 4.3.1.2b Select the height data of adults\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: select-height-adults-b\n\nd_b |> \n    select(height) |> \n    glimpse() # as tidyverse equivalent of `str()`\n\nd2_b <- \n    d_b |> \n    filter(age >= 18)\n\nd2_b |> \n    count()\n```\n````\n\n```\n#> Rows: 544\n#> Columns: 1\n#> $ height <dbl> 151.7650, 139.7000, 136.5250, 156.8450, 145.4150, 163.8300, 149…\n#>     n\n#> 1 352\n```\n:::\n\n\n::: callout-caution\n## Identical?\n\nUsing `identical(d2_a, d2_b)` produces `FALSE` and\n`all.equal(d2_a, d2_b) results in \"Attributes: < Component \"row.names\": Mean relative difference: 0.2990893 >\". But the deprecated`**dplyr**`-version all_equal(d2_a, d2_b)`\n`returns`TRUE`.`\n:::\n\n### 4.3.2b The Model\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: plot-mean-prior-b\n\np1 <-\n  tibble(x = seq(from = 100, to = 250, by = .1)) %>% \n  \n  ggplot(aes(x = x, y = dnorm(x, mean = 178, sd = 20))) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(from = 100, to = 250, by = 25)) +\n  labs(title = \"mu ~ dnorm(178, 20)\",\n       y = \"density\")\n\np1\n```\n````\n\n::: {.cell-output-display}\n![](04b-geocentric-models_files/figure-html/plot-mean-prior-b-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: plot-sigma-prior-b\n\np2 <-\n  tibble(x = seq(from = -10, to = 60, by = .1)) %>%\n  \n  ggplot(aes(x = x, y = dunif(x, min = 0, max = 50))) +\n  geom_line() +\n  scale_x_continuous(breaks = c(0, 50)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  ggtitle(\"sigma ~ dunif(0, 50)\")\n\np2\n```\n````\n\n::: {.cell-output-display}\n![](04b-geocentric-models_files/figure-html/plot-sigma-prior-b-1.png){width=672}\n:::\n:::\n\n\nI will not reproduce the code for all the converting steps to the\ntidyverse approach but I am going to mention the most important\ndifferences:\n\n-   Instead of `base::grid_expand()` use `tidyr::crossing()`\n-   Instead of `base::sapply()` use `purr::map2()`\n\nThe produced tibble contains data frames in its cells, so that we have\nto use the `unnest()` function to expand the list-column containing data\nframes into rows and columns.\n\n-   Instead of `rethinking::contour_xyz()` use `geom_contour()`\n-   Instead of `rethinking::image_xyz()` use `geom_raster()`\n\n### 4.3.5b Finding the posterior distribution\n\n> In the text, McElreath indexed his models with names like `m4.1`. I\n> will largely follow that convention, but will replace the *m* with a\n> *b* to stand for the **`brms`** package.\n\nHere's how to fit the first model for this chapter.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: using-brms\n\nb4.1 <- \n  brm(data = d2_b, \n      family = gaussian,\n      height ~ 1,\n      prior = c(prior(normal(178, 20), class = Intercept),\n                prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4,\n      file = \"brms-fits/b04.01\")\n\nplot(b4.1)\n```\n````\n\n::: {.cell-output-display}\n![](04b-geocentric-models_files/figure-html/using-brms-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: detailled-diganostic\n#| eval: false\n\nlaunch_shinystan(b4.1)\n\n```\n````\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: print-summary\n\nprint(b4.1)\n```\n````\n\n```\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 \n#>    Data: d2_b (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   154.60      0.41   153.81   155.42 1.00     2763     2635\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     7.77      0.29     7.21     8.39 1.00     3400     2561\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: stan-like-summary\n\nb4.1$fit\n```\n````\n\n```\n#> Inference for Stan model: c15b5eff11977bdf1e57f4eae6c83f17.\n#> 4 chains, each with iter=2000; warmup=1000; thin=1; \n#> post-warmup draws per chain=1000, total post-warmup draws=4000.\n#> \n#>                 mean se_mean   sd     2.5%      25%      50%      75%    97.5%\n#> b_Intercept   154.60    0.01 0.41   153.81   154.31   154.59   154.88   155.42\n#> sigma           7.77    0.01 0.29     7.21     7.57     7.76     7.97     8.39\n#> lprior         -8.51    0.00 0.02    -8.56    -8.53    -8.51    -8.50    -8.46\n#> lp__        -1227.04    0.02 0.97 -1229.63 -1227.44 -1226.75 -1226.33 -1226.06\n#>             n_eff Rhat\n#> b_Intercept  2778    1\n#> sigma        3404    1\n#> lprior       2773    1\n#> lp__         1798    1\n#> \n#> Samples were drawn using NUTS(diag_e) at Thu Jun 29 13:13:25 2023.\n#> For each parameter, n_eff is a crude measure of effective sample size,\n#> and Rhat is the potential scale reduction factor on split chains (at \n#> convergence, Rhat=1).\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: interval-89\n\nsummary(b4.1, prob = .89)\n```\n````\n\n```\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 \n#>    Data: d2_b (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   154.60      0.41   153.94   155.25 1.00     2763     2635\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     7.77      0.29     7.33     8.26 1.00     3400     2561\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: narrow-prior\n\nb4.2 <- \n  brm(data = d2_b, \n      family = gaussian,\n      height ~ 1,\n      prior = c(prior(normal(178, 0.1), class = Intercept),\n                prior(uniform(0, 50), class = sigma, ub = 50)),\n      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n      seed = 4,\n      file = \"brms-fits/b04.02\")\n\nplot(b4.2, widths = c(1, 2))\n```\n````\n\n::: {.cell-output-display}\n![](04b-geocentric-models_files/figure-html/narrow-prior-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: summary-narrow-prior\n\nsummary(b4.2)\n```\n````\n\n```\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: height ~ 1 \n#>    Data: d2_b (Number of observations: 352) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept   177.86      0.11   177.66   178.07 1.00     2721     2586\n#> \n#> Family Specific Parameters: \n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma    24.60      0.91    22.87    26.47 1.00     3400     2729\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| label: compare-summaries\n\nrbind(summary(b4.1)$fixed,\n      summary(b4.2)$fixed)\n```\n````\n\n```\n#>            Estimate Est.Error l-95% CI u-95% CI     Rhat Bulk_ESS Tail_ESS\n#> Intercept  154.5959 0.4144632 153.8123 155.4221 1.000708 2762.982 2635.159\n#> Intercept1 177.8647 0.1052528 177.6577 178.0705 1.001224 2720.796 2586.491\n```\n:::\n",
    "supporting": [
      "04b-geocentric-models_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}