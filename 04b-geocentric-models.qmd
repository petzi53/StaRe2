# 04b: Geocentric Models

## 4.0b Why Normal Distributions Are Normal

```{r}
#| label: setup

library(tidyverse)
library(skimr)

```

**What follows is my own approach/trial:**

> Suppose you and a thousand of your closest friends line up on the
> halfway line of a soccer field (football pitch). Each of you has a
> coin in your hand. At the sound of the whistle, you begin flipping the
> coins. Each time a coin comes up heads, that person moves one step
> towards the left-hand goal. Each time a coin comes up tails, that
> person moves one step towards the right-hand goal. Each person flips
> the coin 16 times, follows the implied moves, and then stands still.
> Now we measure the distance of each person from the halfway line. Can
> you predict what proportion of the thousand people who are standing on
> the halfway line? How about the proportion 5 yards left of the
> line?Showing that there's nothing special about the underlying coin
> flip:

> Assume ... that each step is different from all the others, a random
> distance between zero and one ~~yard~~ meter. Thus a coin is flipped,
> a distance between zero and one ~~yard~~ meter is taken in the
> indicated direction, and the process repeats. To simulate this, we
> generate for each person a list of 16 random numbers between âˆ’1 and 1.
> These are the individual steps. Then we add these steps together to
> get the position after 16 steps. Then we need to replicate this
> procedure 1000 times.

To show how these assumptions turn out I will reflect on every little
step:

1.  [**Binomial
    distribution**](https://en.wikipedia.org/wiki/Binomial_distribution):
    We are assuming that the experiment uses a fair coin and that the
    coin is caught in the air to prevent biases that a skilled coin
    flipper could produce. Under this assumption each of the 16 flips
    (starting with the first flip to the 16th flip) has the same
    probability of 0.5. This is the essential characteristic of the
    [bernoulli
    distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution)
    a special case of the binomial distribution.

```{r}
#| label: bernoulli-dist
set.seed(4)
rbinom(16, 1, .5)
```

`1` means a step to the right and `0` is a step to the left (or vice
versa).

2.  [Uniform
    distribution](https://en.wikipedia.org/wiki/Continuous_uniform_distribution):
    To show that the binary event of coin tossing is not necessary for
    the result of a normal distribution, we assume that each step
    measures a random distance between 0 and 1 meter. Under this
    assumption each of the 16 flips has still the same probability of
    0.5 but the resulting step is randomly distributed. This
    characteristics is caught by the uniform distribution.

::: callout-important
## Uniform distribution

The [uniform
distribution](https://www.statology.org/uniform-distribution/) is a
probability distribution in which every value between an interval from
*a* to *b* is equally likely to occur. (see: [5 Real Life Examples of
the Uniform
Distribution](https://www.statology.org/uniform-distribution-real-life-examples/))
:::

```{r}
#| label: uniform-dist-one-person


set.seed(4)
one_person_tbl <- as_tibble_col(runif(16, -1, 1), 
                                column_name = "position")
one_person_tbl
```

The figures are the step sizes in centimeter to the right (positive
values) or to the left.(negative values) --- or vice versa.

3.  **Summarize step distances**: To get the end position after 16 coin
    flips and the following randomly distributed step sizes to the left
    or right, we have to summarize all 16 steps (increments).

```{r}
#| label: result-one-person

set.seed(4)

# a one-liner, including the uniform distribution
sum(runif(16, -1, 1))

# taking the column of the stored tibble
sum(one_person_tbl$position)
```

We assume the a negative value is a step to the left than the position
of the one (first) person is after 16 coin tosses and the following 16
steps 28 centimeter to the left. This is the same result as for the
first value for the `a` version.

4.  **Store all step values and accumulate the result**

```{r}
#| label: one-person-experiment

set.seed(4)


exp_1 <- as_tibble_col(runif(16, -1, 1), column_name = "deviation") |> 
    mutate(person = rep(1, 16),
           n = 1:n(), 
           .before = "deviation") |> 
    add_row(person = 1, n = 0, deviation = 0.0, .before = 1) |> 
    mutate(position = cumsum(deviation))
exp_1

```

After I compared with the Kurz version, I noticed that I have to include
the start position (= zero) as well. This means that there are 17 states
not 16.

5.  **Show graph for all 16 positions**

```{r}
#| label: one-person-graph

ggplot(data = exp_1, mapping = aes(n, position)) +
    geom_path(colour = "red") +
    geom_step(colour = "blue")

```

There are two possible display modes: `geom_line()` / `geom_path()` and
`geom_step()`. I think McElreath used the line variant but it seems to
me that the step mode represents the experiment better.

6.  **Replicate 1000 times**: Now we have to replicate the experiment
    for one person 1000 times.

```{r}
#| label: sim-step-experiment-b

# we set the seed to make the results of `runif()` reproducible.
set.seed(4)

pos_b <- 
  # make data with 3 people, 16 steps each with a starting point of `step_b == 0` (i.e., 17 rows per person)
  crossing(person = 1:3,
           step = 0:16) |>  
  # for all steps above `step == 0` simulate a `deviation`
  mutate(deviation = 
             map_dbl(step, ~if_else(. == 0, 0, runif(1, -1, 1)))) |> 
 # after grouping by `person`, compute the cumulative sum of the deviations, then `ungroup()`
  group_by(person) %>%
  mutate(position = cumsum(deviation)) %>% 
  ungroup() 
glimpse(pos_b)
```

```{r}
#| label: plot-experiment

ggplot(data = pos_b, 
       aes(x = step, y = position, group = person)) +
  geom_vline(xintercept = c(4, 8, 16), linetype = 2) +
  geom_line(aes(color = person < 2, alpha  = person < 2)) +
  scale_color_manual(values = c("skyblue4", "black")) +
  scale_alpha_manual(values = c(1/5, 1)) +
  scale_x_continuous("step number", breaks = 0:4 * 4) +
  theme(legend.position = "none")
```

```{r}
#| label: thousand-persons-graph
#| eval: false

# set seed to replicate the result
set.seed(4)

step_exp <- function() {
    exp <- as_tibble_col(runif(16, -1, 1), 
                         column_name = "stepsize") |> 
        mutate(n = 1:16, cum_step = cumsum(stepsize))
    p <- ggplot(data = exp, mapping = aes(n, cum_step)) +
        geom_line(colour = "red")
}

plot_exp <- 1:7 |> 
    map(step_exp)
plot_exp[[7]]

```

```{r}
#| label: my-sim-step-experiment
#| eval: false

# set seed to replicate the result
set.seed(4)

(
    exp_1000 <- as_tibble_col(runif(16, -1, 1), column_name = "stepsize") |> 
        mutate(n = 1:n(),
                cum_step = cumsum(stepsize))
)

pos_b <- as_tibble(replicate(1000, sum(runif(16, -1, 1))))
pos_b
ggplot(data = (pos_b), aes(value)) +
    geom_histogram()
```

## 4.1b Normal by Adding

```{r}
#| label: normal-by-adding

# we set the seed to make the results of `runif()` reproducible.
set.seed(4)

pos <- 
  # make data with 100 people, 16 steps each with a starting point of `step == 0` (i.e., 17 rows per person)
  crossing(person = 1:100,
           step   = 0:16) %>% 
  # for all steps above `step == 0` simulate a `deviation`
  mutate(deviation = map_dbl(step, ~if_else(. == 0, 0, runif(1, -1, 1)))) %>% 
  # after grouping by `person`, compute the cumulative sum of the deviations, then `ungroup()`
  group_by(person) %>%
  mutate(position = cumsum(deviation)) %>% 
  ungroup() 

```

## 4.3b Gaussian Model of Height

### 4.3.1b The data

```{r}
#| label: load-howell-data-b

library(rethinking)

data(Howell1)
d_b <- Howell1
```

In contrast to the bmrs-version I have chosen two different approaches:

1.  Instead of detaching the **`rethinking`** package I am trying to use
    the **`conflicted`** package. I am still not sure if this will work
    all the way through the book, but I think that it could be a better
    approach. Especially as I am using all the time the **`rethinking`**
    and **`brms`** packages in parallel.
2.  Kurz states that the **`brms`** package does not have a function
    like `precis()` from the rethinking packages. He suggests to use as
    a partly replacement `summary()` and then to use **`ggplot2`** or
    the [`histospark()`
    function](https://github.com/hadley/precis/blob/master/R/histospark.R)
    from another approach to summarize (**`precis`**) data by Hadley
    Wickham. Although this is an interesting approach I think the the
    **`skimr`** package is better suited for a replacement. It conforms
    to the tidyverse approach and has tiny histograms included as in the
    `rethinking::precis()` function. Although it shows different p
    values (0, 25, 50, 75, 100) instead of 5,5 and 94,5% I believe it is
    configurable. But here I will not delve into **`skimr`** to verify
    this assumption as this is not necessary to understand the content
    of SR2.

::: callout-warning
## Function conflicts

My first change (to use the **`conflicted`** package instead `unload()`
did not work. I believe that the reason was that I used the
**`rethinking`** package in the `setup` chunk. Therefore I will go with
the Kurz version (= detaching **`rethinking`**).
:::

```{r}
#| label: unload-rethinking

rm(Howell1)
detach(package:rethinking, unload = T)
library(brms)

```

#### **4.3.1.1b Show the data**

```{r}
#| label: show-howell-data-b

glimpse(d_b)
summary(d_b)
skim(d_b)

```

#### 4.3.1.2b Select the height data of adults

```{r}
#| label: select-height-adults-b

d_b |> 
    select(height) |> 
    glimpse() # as tidyverse equivalent of `str()`

d2_b <- 
    d_b |> 
    filter(age >= 18)

d2_b |> 
    count()

```

::: callout-caution
## Identical?

Using `identical(d2_a, d2_b)` produces `FALSE` and
`all.equal(d2_a, d2_b) results in "Attributes: < Component "row.names": Mean relative difference: 0.2990893 >". But the deprecated`**dplyr**`-version all_equal(d2_a, d2_b)`
`returns`TRUE`.`
:::

### 4.3.2b The Model

```{r}
#| label: plot-mean-prior-b

p1 <-
  tibble(x = seq(from = 100, to = 250, by = .1)) %>% 
  
  ggplot(aes(x = x, y = dnorm(x, mean = 178, sd = 20))) +
  geom_line() +
  scale_x_continuous(breaks = seq(from = 100, to = 250, by = 25)) +
  labs(title = "mu ~ dnorm(178, 20)",
       y = "density")

p1

```

```{r}
#| label: plot-sigma-prior-b

p2 <-
  tibble(x = seq(from = -10, to = 60, by = .1)) %>%
  
  ggplot(aes(x = x, y = dunif(x, min = 0, max = 50))) +
  geom_line() +
  scale_x_continuous(breaks = c(0, 50)) +
  scale_y_continuous(NULL, breaks = NULL) +
  ggtitle("sigma ~ dunif(0, 50)")

p2

```

I will not reproduce the code for all the converting steps to the
tidyverse approach but I am going to mention the most important
differences:

-   Instead of `base::grid_expand()` use `tidyr::crossing()`
-   Instead of `base::sapply()` use `purr::map2()`

The produced tibble contains data frames in its cells, so that we have
to use the `unnest()` function to expand the list-column containing data
frames into rows and columns.

-   Instead of `rethinking::contour_xyz()` use `geom_contour()`
-   Instead of `rethinking::image_xyz()` use `geom_raster()`

### 4.3.5b Finding the posterior distribution

> In the text, McElreath indexed his models with names like `m4.1`. I
> will largely follow that convention, but will replace the *m* with a
> *b* to stand for the **`brms`** package.

Here's how to fit the first model for this chapter.

```{r}
#| label: using-brms

b4.1 <- 
  brm(data = d2_b, 
      family = gaussian,
      height ~ 1,
      prior = c(prior(normal(178, 20), class = Intercept),
                prior(uniform(0, 50), class = sigma, ub = 50)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 4,
      file = "brms-fits/b04.01")

plot(b4.1)
```

```{r}
#| label: detailled-diganostic
#| eval: false

launch_shinystan(b4.1)

```

```{r}
#| label: print-summary

print(b4.1)

```

```{r}
#| label: stan-like-summary

b4.1$fit
```

```{r}
#| label: interval-89

summary(b4.1, prob = .89)

```

```{r}
#| label: narrow-prior

b4.2 <- 
  brm(data = d2_b, 
      family = gaussian,
      height ~ 1,
      prior = c(prior(normal(178, 0.1), class = Intercept),
                prior(uniform(0, 50), class = sigma, ub = 50)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 4,
      file = "brms-fits/b04.02")

plot(b4.2, widths = c(1, 2))

```

```{r}
#| label: summary-narrow-prior

summary(b4.2)

```

```{r}
#| label: compare-summaries

rbind(summary(b4.1)$fixed,
      summary(b4.2)$fixed)

```
